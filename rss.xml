













    
        
    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    












<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"  xml:lang="en-us"  xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        
            

            
                
            

            
                <link href="https://hockenworks.com/" rel="self" type="text/html"/>
            
        
            

            

            
                <link href="https://hockenworks.com/rss.xml" rel="alternate" type="application/rss+xml"/>
            
        

        

        

        <description>Recent content</description>

        
            <language>en-us</language>
        

        
            <lastBuildDate>2025-06-29 00:00:00 +0000 UTC</lastBuildDate>
        

        <link>https://hockenworks.com/</link>

        

        <title>hockenworks</title>

        

        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>The advent of general coding AI assistants almost immediately changed how I think about hiring and interviews.</p>
<p>In the software engineering world, this mindset shift was psychologically easy for me, because I&rsquo;ve always had a bias against the types of coding questions that AI can now answer near-perfectly. And they also happen to be the kind of questions I personally do badly at - the ones requiring troves of knowledge or rote memory of specific language capabilities, libraries, and syntax. It is not so psychologically easy for everyone, especially those who have developed a core skill set of running or passing &ldquo;leetcode-style&rdquo; interviews. Even before AI, the only types of coding questions I would personally ask were things that simply evaluate whether a candidate is lying or not about whether they can code at all, which was and still is surprisingly common. I have interviewed people that list bullet points like 7 years of Java experience but can&rsquo;t pass a fizz-buzz like question, and this was a question I gave out on paper with a closed door and no significant time pressure.</p>
<p>So, when LLMs that could remember any syntax or attribute of any programming language perfectly were released, not only was I excited - I immediately saw that a huge chunk of the programming questions I and many I know have asked in interviews were essentially irrelevant now, not only because people could cheat on interviews, at least virtually, but because this knowledge simply lost much of its value overnight.</p>
<p>Over a few conversations with friends and colleagues I began to explore the idea of what this meant generally for the interview process. There are just lots of questions that we ask in every field, it turns out, that are mostly solved by LLMs today. These models have memorized most useful information that lets them ace simple interviewing questions across fields, even if the original intent of the question was to test for experience.</p>
<h2 id="the-build">The Build</h2>
<p>In the summer of 2022 my ideas and conversations on this topic had gotten to the point where I really just needed to test my hypothesis: LLMs and continuous audio transcription could let someone with no knowledge answer many interview questions correctly. My initial thought was that an app like this must already exist. But after searching for apps on the app stores that did what I was thinking of, to my surprise, I found none did.</p>
<p>I&rsquo;m still not sure if this was a legal thing at the time, or if it&rsquo;s hard to get apps that continuously transcribe audio published, but as of 2025 apps like this definitely exist. Some of them have gotten famous and one has gotten its creator expelled from an Ivy League for revealing that he used it to ace interviews with some top tech companies. Link for the curious here:</p>
<p><a href="https://cluely.com/">https://cluely.com/</a></p>
<p>But, in mid 2023, these apps were apparently not a thing, so I decided to make a prototype.</p>
<p>My basic requirements were simply something that could continuously transcribe words being spoken in a meeting or over a call, group them up into meaningfully long chunks, and then send those chunks with some overlap to two different AI passes:</p>
<ol>
<li>An AI pass that would try to make meaningful questions out of the transcribed potential gibberish</li>
<li>An AI pass that would answer those questions</li>
</ol>
<p>My tech stack for this was a little weird, but I know Unity well and I don&rsquo;t know other ways of deploying native mobile apps as well, and this definitely needed to be a mobile app if it was going to sit on the phone and continuously transcribe audio. Web has all kinds of restrictions on its APIs and I hadn&rsquo;t made a web app like this anyways.</p>
<p>This was surprisingly easy to achieve, even in 2023. I ran into a few hiccups mainly around continuous audio transcription, but for an app I wasn&rsquo;t going to publish and that I was directly putting onto my own Android device, I got around these difficulties by simply starting up a new audio transcription thread every time one closed.</p>
<div style="display: flex; align-items: center; justify-content: center; gap: 10px; margin-bottom: 1rem;">
    





























    



    



    





    







    



    























<img  alt="the UI"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/make-us-smarter.jpg"   style="height: auto; max-width: 200px"   >


    
        <span style="font-style: italic;">Super barebones UI just showing the continuously auto-transcribed words, questions derived from those words, and answers to those questions.  This particular screen was grabbed long after my API key had expired and is only here to show the basic output of the app, transcription building continuously in the background and detected questions and answers in the foreground.</span>
    
</div>

<p>And the results were surprisingly compelling. Of course I was using some of the very first versions of GPT-4 and AI is still not perfect, but the main result of this was that occasionally questions were picked up that were not actually implied by the meeting audio, and occasionally real questions were missed. The part that I knew was going to work did indeed work incredibly well: when I simulated some fizz-buzz style questions and there were no major audio transcription issues, the second question-answering AI nailed them and was able to put a succinct script to answer the question on screen within a few seconds.</p>
<p>There was clearly more work to be done on UI and also the flow between the AI passes, and more agentic APIs of today could definitely do this all more seamlessly.</p>
<p>But for me, my question was answered: My hunch was right and we should definitely not be asking questions about basic constructs of programming languages or simple scripts in interviews anymore.</p>
<p>I open-sourced the project which is a pretty small Unity build, and it&rsquo;s a Unity version from a couple of years ago now, but anyone is welcome to look through and modify the code any way they want:</p>
<p><a href="https://github.com/hockenmaier/make-us-smarter">https://github.com/hockenmaier/make-us-smarter</a></p>
<h2 id="interviewing-mitigations">Interviewing Mitigations</h2>
<p>This whole experience has led me to an interview approach that I think is infallible (for now). And it doesn&rsquo;t require sending someone home with a project or any of the stuff that great candidates often don&rsquo;t even consider. I heard about a version of this technique on Twitter, so can&rsquo;t take credit here:</p>
<p>First: ask candidates to bring some code they have written, regardless of language or framework. Then simply walk through it with them in the interview. asking them questions about why they made certain decisions and trying to guide the conversation to parts that are technically interesting. It only takes 15 minutes or so, and it usually gets much better conversation going than sample interview questions do. This leans on the fact that you need an interviewer who can mostly understand most programming projects, but it cannot be faked with any LLM assistance. LLM-written code is typically pretty obvious: much better commented and differently organized than most humans would write. But even if the code was very sneakily written AI code the person didn&rsquo;t actually contribute to, then having a human go through and explain the parts they thought were clever defeats the purpose of cheating with AI anyway.</p>
<p>This is just a little tidbit of a technique that works well today, if the goal is to assess coding skills. Of course, it leaves some obvious lingering questions about what we are evaluating and why. I hope no one out there that I know is using these apps to cheat on interviews, but we all need to be wise to the fact that it is trivially easy to do so in 2025, and we should shift focus to testing for the qualities that actually matter in the era of AI - or at the very least techniques that prevent the types of cheating possible today.</p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2025-06-29:/my-experiments-with-ai-cheating/</guid>

                
                    <link>https://hockenworks.com/my-experiments-with-ai-cheating/</link>
                

                
                    <pubDate>Sun, 29 Jun 2025 00:00:00 UTC</pubDate>
                

                
                    <title>My Experiments with AI Cheating</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>&ldquo;The Flapper&rdquo; is a project that spawned out of a simple VR movement mechanic test that I had in my head for a while, which turned out to be surprisingly fun! The idea is to flap your arms to fly - wrapped up as a multiplayer battle to really get people moving.</p>
<p>In order to start working on this game, because there was so much standard VR code that I had to write for <a href="/treekeepers-vr">Treekeepers</a>, I decided to make a sort of engine out of the Treekeepers codebase and work off of that rather than start from scratch. That let me tie in some of the nice associated graphics, music and sound effects I had made, and a bunch of other helper functions and tools I use for things like the camera following around the character, how I deal with collisions, a bunch of netcode, etc.</p>
<p>You can see my more detailed post about that engine here: <a href="/treekeepers-engine">Treekeepers Engine</a></p>
<h2 id="core-mechanic--gameplay">Core Mechanic &amp; Gameplay</h2>
<p>Most of the start of this game was just tuning the movement mechanic, which borrowed from some physics realities and some elements I made up to make flapping feel good. But, the essential idea was that each arm generates unique thrust in the direction it moves with an exponential applied to its speed. It&rsquo;s hard to describe any native VR mechanic with words and videos only, but to me and the folks I demoed it to, it felt &ldquo;right&rdquo; for how flying should work if you did it by flapping your arms - and that feeling is based in the physical reality of wing-powered flight. I had a ton of fun just jetting around the obstacle courses I made for myself.</p>
<p>My idea for this other than just the mechanic was to make a sort of gorilla tag-esque multiplayer game where players would fly around and try to pop each other&rsquo;s balloons in an NES balloon fight {link} style. Ideally something like 15 to 20 people would be in a lobby flying around and trying to pop each other.</p>
<p>Like gorilla tag I didn&rsquo;t want anyone to have to &ldquo;sit out&rdquo; of the game, so it&rsquo;s essentially a deathmatch where the player who pops the most balloons wins, and is also visible who&rsquo;s winning, because they also gain the balloons that they pop. In some playtests players would have 20 or 30 balloons on their heads. This was my clever idea of adding a built-in rubber-band effect to the gameplay as well, since having more balloons over your head made you a bigger target to pop. The gameplay worked well - but I never quite got the game to a place with netcode and networking engine where multiplayer felt seamless enough.</p>
<p>Here’s a video of one of the later states of the game, where I have it fully networked and am testing with friends, though it still has a few bugs here:</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/Vxn8rDOZ7dU?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<h2 id="today">Today</h2>
<p>I stopped working on this project after about 3 months. It turned out that flying alone with this mechanic was very compelling (and also a great workout!) but the networking engine I had used for Treekeepers, Photon, was not up to the task for how low latency a competitive game needed to be. Treekeepers was four-player co-op so Photon was just fine.</p>
<p>In the future I might pick this one back up (or maybe have an AI agent pick it up for me depending on how that goes) using <a href="https://spacetimedb.com/">space-time DB</a> which looks like a great solution for this type of game that doesn&rsquo;t require a whole ton of cloud programming and setup</p>
<p>I haven&rsquo;t made a build of this game public yet due to its unfinished and multiplayer nature - it&rsquo;s not set up with a usable server other than for testing. If I receive interest in playing it from enough people, I&rsquo;ll go back in and package up the single player parts as a tech demo and put a download here.</p>
<p>I learned a lot from this project, both in terms of game code organization and game mechanic design, and I still think it&rsquo;s a great concept. I hope this movement mechanic becomes the basis for a full game in the future and with any luck with the direction software development AI is going I might get that opportunity sooner vs later. About 3 weeks from now, I will be releasing an article on the modern state of AI software development, including a deep dive on some of the latest tools for web and game development, so stay tuned!</p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2025-06-23:/the-flapper/</guid>

                
                    <link>https://hockenworks.com/the-flapper/</link>
                

                
                    <pubDate>Mon, 23 Jun 2025 00:00:00 UTC</pubDate>
                

                
                    <title>The Flapper - A Physical VR Multiplayer Game</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I have long been of the mind that LLMs and their evolutions are truly thinking, and that they are on their way to solving all of the intellectual tasks that humans can solve today.</p>
<p>To me, it is just too uncanny that the technology that seems to have made the final jump to some degree of competence in tasks that require what is commonly understood as &ldquo;thinking&rdquo; or &ldquo;understanding&rdquo;, after a long string of attempts and architectures that fail these tasks, is a type of neural network. It would be much easier to argue away transformer models as non-thinking stochastic parrots if we had happened to have had success with any other architecture than the one that was designed to mimic our own brains and the neurons firing off to one another within them. It&rsquo;s just too weird. They are shaped like us, they sound like us in a lot of ways, and it&rsquo;s obvious they are thinking something like us too.</p>
<p>I am not saying they are as good as us yet, though, for a few small reasons and one big one.</p>
<h2 id="the-limitations">The Limitations</h2>
<p>Current frontier &ldquo;thinking&rdquo; models are not AGI in the modern definition. They can&rsquo;t do every task humans can do intellectually (IE without a body, which I will get to) for several reasons:</p>
<ol>
<li>
<p>Looping/Recursive reasoning:
This was a huge problem for early transformers that had to output in one shot, and the examples were obvious. This one has been essentially solved via thinking models like o1, and now o3, gemini and grok thinking models, and many more. That was a huge unlock and a huge boon for applications like programming where there is lots of nested recursion of logic that has to occur to find a reasonable solution.</p>
</li>
<li>
<p>Memory and context:
Context windows get larger all the time, but this limitation still is not solved. Just adding a bunch of tokens into a context window doesn&rsquo;t get you much when 2 million token models lose coherence after about the first 40,000 - which they do, and which every programmer working with anything but a tiny codebase intuitively understands. But this one too will largely be solved soon, if not through architectures that actually update their weights, it&rsquo;ll be solved through nuanced memory systems that people are actively developing on top of thinking models.</p>
</li>
<li>
<p>Size:
This is basic, but most of the models we can interact with today are still working with an order of magnitude fewer neural synapses than human brains. It could very easily be that, even with the other problems solved, we just need bigger electronic brains to match the size of our meat ones. It certainly <em>feels</em> like some of the ways LLMs fail today sort of come down to &ldquo;not enough horsepower&rdquo; types of issues.</p>
</li>
<li>
<p><strong>Vision</strong>:
And this one might sound funny to someone that is paying attention to AI in particular, because GPT-4 with vision launched something like 2 years ago now. And it has been impressive for a long time, able to do things like identify what objects are in an image, where an image is from, etc: things most humans can&rsquo;t do glancing at an image, that seem super-human.</p>
<p>But the vision itself is not “good” vision. It cannot really pick out small important details, and it still behaves in many ways like vision recognition models have for years now. Now that we have a model that has both thinking and image input and editing at every step, the o3 and o4-mini series that recently released, we can really start to see the limitations in vision. Let me take you through 2 examples that represent the 2 types of failure modes that result from these not having true image understanding, yet.</p>
<p>My thesis today is that this is the key limitation that is not going to be overcome &ldquo;by default,&rdquo; but that it will be overcome.</p>
</li>
</ol>
<h2 id="proof-the-vision-is-not-there-yet">Proof the Vision is Not There Yet</h2>
<p>Each release from the major providers steadily knocks away my intelligence tests, which I admit are mostly programming oriented, but the ones that they can never really dent are the spatial reasoning ones - where a model really has to think about images in its head or use an image provided for detailed work.</p>
<h3 id="simple-3d-modeling-with-frontier-ai-models">Simple 3D Modeling with Frontier AI Models</h3>
<p>Every major model release, <a href="/3d-modeling-with-ai">I test what models can do with OpenSCAD</a>. I won’t get technical about it here, but OpenSCAD is a CAD program (Computer Aided Design - think 3D modeling for engineers, not the artistic kind) that is defined entirely through a programming language vs the typical mouse strokes and key presses that software like SolidWorks or AutoCAD depend on.</p>
<p>This makes OpenSCAD the perfect test platform for a model that inputs and outputs text primarily. I can describe a 3D model I want, and the model can output text that renders into a 3D model.</p>
<p>As amazing as LLMs are at scripting in normal programming languages, they have never been good at OpenSCAD. See my link above for GPT-3.5 and GPT-4 trying to model an incredibly simple object. That acorn was about as complex as GPT-4 could get without really falling down.</p>
<p>Here is OpenAI&rsquo;s o3’s attempt to make a standard 2x4 Lego Brick:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="an OpenSCAD render"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/o3-lego.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">o3&#39;s model left, real Lego brick right</span>
    
</div>

<p>This was the easiest object I tested, and o3 does a decently good job. It grabbed the correct dimensions online and, using its inherent training data of what a 2x4 Lego block is, applied those dimensions into a mostly coherent object. It has one major flaw, which you can see on the underside as I have the image rotated - it drew two lines through two of the cylinders. My guess is that this is its interpretation of the supports in the middle of the actual Lego brick, that connect but don&rsquo;t run through the center cylinder.</p>
<p>Now for a harder test: a simple engineering part that&rsquo;s definitely not in its training data, because it is my own design. I printed this for a robotics project more than a decade ago, and had it sitting around in my 3D printer storage drawer.</p>
<p>It&rsquo;s a bit of a weird part - a pinion with a smooth section and an 11-tooth gear of equal diameter, and a hole in the center with a slightly raised wall. This is the kind of part that an engineer well versed in AutoCAD or SolidWorks can produce in just a few minutes, but which requires attention to detail and a conceptual model of how parts fit together.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="an OpenSCAD render"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/o3-pinion.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">o3&#39;s model left, real part right</span>
    
</div>

<p>This is where you can see how these models fall apart. o3 immediately gets that it&rsquo;s a pinion, that it has a hole in the middle, and that it has a smooth section on the bottom and a gear on top. But the execution is nowhere close to workable, from most major to least (in my opinion):</p>
<ul>
<li>There are two gears (unknown as to why or if this is intentional, o3 explained one as a &ldquo;grooved ring&rdquo; - whatever that means)</li>
<li>The gear teeth are concave - whereas the rounded sharp tooth shape is clear in the image</li>
<li>There are 10 teeth, not eleven - which seems trivial, but it&rsquo;s indicative of a real flaw that messes up all complex models I throw at AI - where LLMs make an assumption like what number of teeth is &ldquo;likely,&rdquo; rather than looking at the image in detail and counting them.</li>
<li>There is clearly an attempt at the raised wall around the top hole, but it&rsquo;s far too big.</li>
<li>The height of the smooth base section and gear sections are equal in the real part, but o3 makes the gear more than 3x thicker than the base.</li>
</ul>
<h3 id="map-reading">Map Reading</h3>
<p>Here&rsquo;s another great example of what I mean when I say that frontier models have bad vision.</p>
<p>I recently gave this question to the latest thinking image model, o3: &ldquo;Here&rsquo;s an image from Google Maps of the block I live on between the avenues of Burbank, Hazeltine, Oxnard, and Van Nuys. What is the longest continuous loop I can walk within the neighborhood without crossing my path or touching one of the avenues? This square is 1/2 mi on each side&rdquo;</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="the uploaded map"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/o3-struggle-map-new.png"   style="height: auto; max-width: 400px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">The image uploaded with this query</span>
    
</div>

<p>O3 thinks for 4 minutes about this question, zooming in to various parts of the map countless times to form the route. And then it fails on the first step, suggesting starting at Tiara and Stansbury, which do not intersect on the map. Any person looking at this image could tell that is true in just a few seconds.</p>
<p>This is what I mean when I say these things have bad vision - and this is the best model from the lab I think has the best vision. Vision is not about being able to identify millions of different objects, <a href="https://www.image-net.org/">ImageNet-style</a>. It&rsquo;s about seeing the detail and paying attention to the right thing. Here in this map, that means looking roughly at the lines representing Stansbury and Tiara, looking at where they would intersect, and seeing they do not.</p>
<p> </p>
<p>Though getting AI models to read maps and create 3D models from code may not be on everyone&rsquo;s rubric, any UX developer that has worked with a frontier AI knows what I&rsquo;m saying intuitively. This is likely just as true for any role heavily leaning on visual information. There is a difference between generating some Tailwind code that spits out a standard UI and getting to the level of complexity that the AI starts to need to look at screenshots in detail and know the relative position and orientation of components, or see small details. They just.. don&rsquo;t do that yet.</p>
<h3 id="non-frontier-ai-models">Non-Frontier AI Models</h3>
<p>A common retort to this argument might be &ldquo;Well Brian, you&rsquo;re using the wrong type of model.&rdquo;</p>
<p>But believe me, I try essentially everything I can get my hands on, and like non-LLM AI models in other domains, other than being incredibly limited in application, these models are simply not good at vision, either. Here&rsquo;s an image of a 3D model generated by Zoo CAD, a company doing text and image to 3D, which was, when I printed it back in January at least, state of the art in this domain:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="My Flipper Zero and 3D Printed Clone"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/flipper-3d.jpg"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">My Flipper Zero (left) and its 3d-printed clone (right)</span>
    
</div>

<p>The input to the model was a picture I took of my <a href="https://flipperzero.one/">Flipper Zero hacking toy</a>. The 3D print on the right is of the 3D model it produced, with the only modification on my part being to scale it.</p>
<p>I have long awaited an easy way to &ldquo;3D scan&rdquo; parts from the real world into software. This would make so many of my DIY printing jobs around the house much easier - and it gets us one step closer to the dream of teleportation.</p>
<p>And I was impressed when I first saw this output - it was one of the best of my attempts with this AI tool. Feature-wise, it did a pretty good job of capturing the main facets of my Flipper Zero. But it&rsquo;s just too obviously not good enough: dimensions are all wrong, there is hallucinated symmetry all over the place, and small details are missed everywhere. One of the reasons I printed this model was just to get a real feel for how similar it is to the Flipper when scaled correctly, and it just becomes obvious that this is not a useful technology yet when you hold both of them in your hands.</p>
<p>My prediction is that frontier models will get there before purpose-trained models like the one that cloned my Flipper Zero. This has been the reality across most other domains of AI. Now that we have general-purpose AI models that have started to encapsulate a working, if not complete, conceptual model of the world, they are starting to outperform all of the smaller purpose-built models of the last decade.</p>
<p>And this will be good for the general capability of the AI industry: It&rsquo;s a much better outcome to have a few general-purpose models that can do fine visual work, that can be prompted and orchestrated by people working in different domains, than it is to need an AI lab or startup to train a specific model for every task. It&rsquo;s the same reason I believe humanoid robots are going to win over purpose-built ones in the long run: We can&rsquo;t predict what users will want their robots to do, and our world is built for humans to operate in it - therefore the most capable robots will be shaped generally like humans.</p>
<p>So how will frontier models get good at visual tasks, if they have such bad vision right now? I think the answer to that question also involves humanoids.</p>
<h2 id="the-humanoids">The Humanoids</h2>
<p>What I think is going on in these examples of frontier model vision failures is that we have a limitation in training data (duh!) - but that isn&rsquo;t because there aren&rsquo;t a lot of images and videos on the internet, it&rsquo;s because there is so much more information in the average image than there is in the average chunk of text, and a lot more of that information is irrelevant to any given question.</p>
<p>When I say that we have a limitation on training data, I&rsquo;m not in the typical camp of &ldquo;well, then transformer neural nets are obviously stupid because I was able to understand this thing without training on terabytes of data from the internet&rdquo;. This has always been a bad take because the average human trains on petabytes, not terabytes of data, and that data is streamed into their brains mostly in the form of images. I am also not in the camp of thinking that this means that the data &ldquo;just doesn&rsquo;t exist&rdquo; to get these models to AGI in the visual dimension. It so clearly does exist, and it exists so abundantly that a unique image stream can be sent to each of the billions of human brains, and they all learn the same principles that let them immediately identify the mistake that the cutting-edge thinking vision model made after 4 minutes of rigor.</p>
<p>Not only does the data exist: We never actually had a data problem in AI in the first place. We have an instruction problem. That doesn&rsquo;t mean model architecture or data massaging really, it means that we need to plug our models into the real world where all the data streams exist. I believe this will come first in the form of robots with cameras on them, the first of which is happening en masse via Tesla full self-driving AI, and I&rsquo;m sure those vision neural nets are quite insanely capable compared to what we see in the consumer transformer vision models. But the real leap probably comes when we get to humanoid robots walking around collecting and learning from vision data every day - and learning from actions they take in the real world.</p>
<p>If you’ve ever tried to get concrete actions to take based on a vision-transformer’s outputs, you will know it’s hard. I never posted about it, but I did a small project with a friend a year or two ago, trying to get automated QA working on web software, and we failed in a lot of different ways. I am very impressed that the big labs are starting to crack <a href="https://docs.anthropic.com/en/docs/agents-and-tools/computer-use">computer use</a> - because getting an LLM to give specific coordinates or elements to click on is the same type of challenge I was testing above. But it&rsquo;s no wonder these computer use applications are still very inaccurate.</p>
<p>Letting transformer-based agents control robots will be a much harder problem of a similar type. Not only does it require attention to detail, but now the images are in 3D, they come at you many times per second, and actions need to be produced as quickly. But my prediction is that we will brute force this, and it will work &ldquo;well enough&rdquo; for enthusiasts and niche industrial use cases to benefit from humanoid robots. And that&rsquo;s the takeoff point for true vision, as we all intuitively understand it. Releasing humanoids at scale (and cars, to some extent) are when we really unleash the datastream that&rsquo;s needed to get models that can see as well as you or I can. This is probably one reason why many AI companies and labs are pushing them so hard - they also understand the data they collect will be more valuable than the money paid for the first units.</p>
<p>Once we have a few hundred thousand humanoids roaming around early adopters&rsquo; houses, we will start to see AI models that can use OpenSCAD and Google Maps. And, conveniently, that&rsquo;s also the missing capability that will make the humanoids really useful. We have interesting years ahead of us.</p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2025-06-16:/vision-is-the-last-hurdle-before-agi/</guid>

                
                    <link>https://hockenworks.com/vision-is-the-last-hurdle-before-agi/</link>
                

                
                    <pubDate>Mon, 16 Jun 2025 00:00:00 UTC</pubDate>
                

                
                    <title>Vision is the last hurdle before AGI</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I&rsquo;m <a href="/about-me">Brian Hockenmaier</a>, and this site is full of things I build and write about. I love making games and things with VR and AI. And I love DIY projects, especially ones involving programming, engineering and 3D modeling. Some of this has been cross or back-posted from my <a href="https://www.thingiverse.com/hockenmaier/designs">thingiverse</a>, <a href="https://github.com/hockenmaier">github</a>, <a href="https://www.linkedin.com/in/hockenmaier/">linkedin</a>, and other places, but it all lives here permanently.</p>
<p>This is an evolution of <a href="old-site/index.html">my previous site last updated in 2022, which I still keep inside this one</a> for posterity and for the AIs of the future to know more about me. I like it not because of the content as much as because it was a fully custom js and html site with no framework&hellip; and I think it&rsquo;s sort of fun and funny that it was like this.</p>
<p>All work and opinions here are my own, not my employer&rsquo;s.</p>
<h1 id="why-im-making-it">Why I&rsquo;m making it</h1>
<p>I&rsquo;m creating this website in 2025 after starting a family as well as my first full-time role in AI. It&rsquo;s an effort to clean up my website&rsquo;s focus, move several disparate collections into one place, and emphasize what I truly care about. I wanted it to be easier to add content, CMS style, and I wanted a space to occasionally post written content, too.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="the hockenworks homepage"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/hockenworks.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">This webpage, if you hadn&#39;t noticed</span>
    
</div>

<p>A big reason I&rsquo;m doing this now is that, after listening to the Dwarkesh podcast with Gwern, I was convinced I really should have more of a record for future AIs to learn about me. I really don’t have a social media presence, nor do I want one, and over the years I have had a lot of projects and writing that I have unnecessarily kept private. AGI or not, there are non-artificial intelligences that may be interested one day. Talking to you, Alice :) When I started this website, your cousin Lily kept asking where you were and didn&rsquo;t seem to get the concept that you currently occupied the same space as Kaitlin.</p>
<p>I love some of the 2010s era blogs, and though mine is not going to be nearly as longform, nearly as focused on prose, or nearly as articulate, two of the sites I&rsquo;m trying to take inspiration from are <a href="https://slatestarcodex.com/about/">Slate Star Codex</a> and <a href="https://gwern.net/about">Gwern&rsquo;s website</a> which are definitely advising on style here. Other than the fact that mine is also a game.</p>
<hr>
<h1 id="etymology-of-hockenworks">Etymology of &ldquo;hockenworks&rdquo;</h1>
<p><strong>Hockenmaier</strong> is a great name. I&rsquo;ve always loved it. Not just because it’s unique and has my favorite number of letters, but because of its meaning, at least my family’s “folk-etymology” for it.</p>
<p>You have:</p>
<blockquote>
<p><strong>Hocken</strong></p>
</blockquote>
<p>Which can roughly translate to “sitting down, squatting, settling, idling”.</p>
<p>And then you have:</p>
<blockquote>
<p><strong>Maier</strong></p>
</blockquote>
<p>Which has many different spellings, and ours has southern German roots, but all &ldquo;Meyer&rdquo; names come from the latin root &ldquo;maior&rdquo; meaning steward, administrator, or more generally &ldquo;worker&rdquo;</p>
<p>My family often puts these two ideas together as &ldquo;Lazy Worker,&rdquo; which is very on-brand for our sense of humor, but I think it&rsquo;s not just funny, but true.</p>
<p>“Lazy Worker” is perfect for someone who wants to get a lot done, especially in software engineering. We only have so many hours, and the best lives are lived restricting the number of hours spent on work that isn&rsquo;t done with people you love. So you better be efficient about it. You better be lazy. There are <a href="https://blog.codinghorror.com/how-to-be-lazy-dumb-and-successful/?utm_source=chatgpt.com">many</a> <a href="https://xkcd.com/1205/?utm_source=chatgpt.com">correct</a> <a href="https://thethreevirtues.com/">takes</a> out there on the value of being lazy when programming.</p>
<p>Now that we are starting to have AI, it&rsquo;s even better. A lazy worker like myself will not only avoid unnecessary work, but will delegate all that can be delegated to the new AI workers that are multiplying in our computers. That makes the &ldquo;steward&rdquo; connotation of &ldquo;Maier&rdquo; all the more fitting.</p>
<p>I&rsquo;m proud to be the lazy worker, and this site is all about sharing my lazy works. My <em>hockenworks</em>.</p>
<hr>
<h1 id="ball-machine---the-game">Ball Machine - The Game</h1>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="A ball machine"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/bubble4.gif"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">The Ball Machine</span>
    
</div>

<p>Most blogs and personal websites are a bit boring. I think that is because most professionals consider what they do &ldquo;for work&rdquo; a bit boring by its nature, and don&rsquo;t necessarily make a concerted effort to have fun with it.</p>
<p>I have always tried to be the opposite, and with kids coming I am trying to make a bigger effort than ever to have fun whatever I&rsquo;m doing. Which is often working, in some way or another.</p>
<p>So for my website, I wanted it to be intentionally fun. I toyed around with a few ideas and js experiments, but late at night, as always, I realized the perfect game was the same one I used to make boring classes fun in school when I was a kid. That game consisted of the book of graph paper I always kept with me, plus a pencil, a ruler, and a protractor. I was a bit obsessed with physics simulation at the time. My favorite game in church growing up, where I was often daydreaming and looking at the huge arched ceiling, was to imagine a laser coming out of my line of sight and bouncing off of every surface in the room, to see where it would end up. This graph paper game I played was similar.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="balls everywhere"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/this-website-ball-machine-1.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">Some of my early playtests got pretty chaotic</span>
    
</div>

<p>I would start by making a &ldquo;spawn point&rdquo; usually near the top left of the page, where balls would start falling. I would draw out the path of these balls a few inches from each other along their path with &ldquo;speed lines&rdquo; to denote which way they were going, and how fast. Then I would add platforms, trampolines, loops, curves, &ldquo;booster&rdquo; acceleration zones, jumps, machines that would disassemble and reassemble balls, and so many other things - usually something new each sheet of paper - and I would end up with a Rube Goldberg machine of balls flying all around the sheet. The only goal was to fill the sheet with more ridiculous paths.</p>
<p>I started calling the sheets my &ldquo;ball machines&rdquo;. I wish I still had some of these drawings. I remember them being quite intricate.. I must have reserved English class for them.</p>
<p>So, to honor kid Brian, I am making my website a permanent ball machine. I hope you have fun with it and see all there is to unlock!</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="balls everywhere"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/waves2.gif"   style="height: auto; max-width: 300px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">Even on the limited phone version, you can create some productive chaos</span>
    
</div>

<h2 id="how-its-made">How it&rsquo;s made</h2>
<p>I don&rsquo;t typically make complicated things like this with JavaScript. So when I found the perfect physics engine for the game - <a href="https://brm.io/matter-js/">matter.js</a> - I knew I would need help from our new little assistants. And though this game is a bit too structured to call it &ldquo;vibe coded&rdquo; - at times, it was close.</p>
<p>I ended up making my own tool called <a href="/context-caddy">Context Caddy</a> to help me with it. Part of the reason I leaned so hard into this is because I&rsquo;m always trying to push the limits of current AI, and I hadn&rsquo;t built a game since the GPT-4 days (I&rsquo;ll post about that soon). The new thinking models are truly a step above GPT-4 (this was mostly done with o3 and its minis) but they&rsquo;re still way too eager to write duplicate code, and they still don&rsquo;t &ldquo;get&rdquo; the structure of your project a lot of the time, especially with visual and physical things like this. Still, they were a great help here.</p>
<p>This game is made extra complicated by the fact that it runs on top of <a href="https://gohugo.io/">Hugo</a>, which is the static site generator behind the &ldquo;content&rdquo; part of this site. This probably doubled or tripled the effort of making this game. But, the balls in the &ldquo;ball machines&rdquo; of my youth would interact with my text notes and drawings, so this ball machine needed to do so as well.</p>
<p>There is quite a bit going on under the hood to make these two very distinct types of development projects work in tandem, and for both of them to work well. The Ball Machine would love to eat up all of the resources and make the site content unresponsive, and the content was quite a lot to dynamically build physical bodies and colliders around. I like the end result. But I like it a lot better on desktop, where the two can really interact, so I think you should play it on a real computer with a mouse.</p>
<h2 id="how-to-play">How to Play</h2>
<span
  style="
    float: left;
    width: 150px;
    margin: 0 1rem 1rem 0;
    display: inline-block;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="ball chute"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/ball-chute-hatch-1.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
  <span style="display: block; font-style: italic; margin-top: 0.5rem">
    This tube creates balls every time you click it
  </span>
  
</span>

<p>The ball machine on this site is a gamified version of my graph paper drawings as a kid. Each time you load a page, you&rsquo;ll see a little pneumatic delivery tube on the top right of the screen.</p>
<p>When you spawn your first ball, you&rsquo;ll see a few things appear. First - you&rsquo;ll find a goal     <span
  style="
    display: inline-block;
    width: 40px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="the goal"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/goal.png"   style="height: auto; max-width: 40px; width: 100%"   >

 
</span>
 somewhere randomly on the page. Find a way to get the balls you spawn into that goal. But there is a bit of a trick - balls start out being worth 1 coin and accumulate another coin in value every two seconds. So, the longer you can keep balls around, the more they will be worth when going into the goals, and this might get more and more challenging as your drawings take up more of the screen and balls start bouncing off of each other.</p>
<p><strong>Keep Clicking!</strong></p>
<p>It&rsquo;s <a href="https://en.wikipedia.org/wiki/Incremental_game">a clicker game</a> - start by manually clicking the pneumatic delivery tube to spawn balls, but as you accumulate coins you&rsquo;ll be able to unlock different drawables and things that will let you accumulate more coins faster. If it feels like it&rsquo;s taking a while to make coins and unlock things, try playing around more with how the balls interact with the content, and use all of the tools you can draw. The site also works across multiple pages. And if all else fails&hellip; just give it time. This is a clicker game after all, so waiting is always a strategy! There is plenty to read while you wait.</p>
<p>It works best when you&rsquo;re on desktop, working on one tab at a time.</p>
<p> </p>
<blockquote>
<p>Quick Disclaimer: This game is designed for big screens, ideally desktop computers. If you must play on a phone, try landscape mode!</p>
</blockquote>
<h3 id="controls">Controls</h3>
<p><span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/line-mode.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>

<span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="curved line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/curve-mode.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>

<span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="compactor toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/compactor-mode.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>
</p>
<p>To start drawing your ball machine, you need to <kbd>Left Click</kbd> or <kbd>Tap</kbd> one of these drawable toggles in the main UI (top left of the screen)</p>
<p>When you have a drawable tool toggled on, you won&rsquo;t be able to click other links on the site. You&rsquo;ll see this visually indicated when you choose them. Unselect the currently selected tool in order to see it</p>
<p>Every drawable item (lines, launchers, and more) uses the following mechanics:</p>
<p> </p>
<h4 id="drawing-on-desktop">Drawing on Desktop</h4>
<p><strong>Spawn Balls:</strong> <kbd>Left Click</kbd> on the pneumatic spawner tube</p>
<p><strong>Draw Objects:</strong> <kbd>Left Click</kbd> and drag to see a preview, then <kbd>Left Click </kbd> to place</p>
<ul>
<li>Some drawables have a second action, like curved lines, that is previewed after the second click and confirmed with a third click</li>
</ul>
<p><strong>Cancel Drawing</strong> After you&rsquo;ve started a line or other drawing but before you&rsquo;ve clicked again to confirm, <kbd>Right Click</kbd> to cancel it.</p>
<p><strong>Delete Objects:</strong> Hover over a drawn item and <kbd>Right Click</kbd> to delete it, getting 50% of your money back</p>
<p> </p>
<h4 id="drawing-on-mobile">Drawing on Mobile</h4>
<p><span
  style="
    color: #ff0040;
    font-family: 'Arial Black', Arial, sans-serif;
    font-size: 20px;
  "
>
   Mobile Scroll Lock Warning:
</span>
 On Mobile, scrolling the page is blocked while you&rsquo;re drawing to allow you to draw lines in any direction.</p>
<p>You will need to untoggle your selected tool before you can scroll or click links.</p>
<p>If your phone has gesture controls to reload, go back or forward, or other browser things, you should disable them if you really want to play on your phone. Or, just play on desktop!</p>
<p><strong>Spawn Balls:</strong> <kbd>Tap</kbd> on the pneumatic spawner tube</p>
<p><strong>Draw Objects:</strong> <kbd>Touch and Drag</kbd> to see a preview, then <kbd>Release</kbd> to place</p>
<ul>
<li>Some drawables have a second action, like curved lines, that is previewed and confirmed on the next touch-and-drag.</li>
</ul>
<p><strong>Cancel Drawing</strong> After you&rsquo;ve started a line or other drawing but before you&rsquo;ve released to confirm, go back to where you started and release around there to cancel it. The threshold to cancel is within 25 pixels of where you started.</p>
<p><strong>Delete Objects:</strong> <kbd>Tap and hold</kbd> an object to delete it, getting 50% of your money back. You will see it pulse before it deletes.</p>
<p> </p>
<h4 id="the-auto-clicker">The Auto-Clicker</h4>
<span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="auto clicker"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/auto-clicker.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>

<p>This is the autoclicker button that lets you pay to auto-spawn balls.</p>
<p><kbd>Left Click</kbd> or <kbd>Tap</kbd> to buy the first auto-clicker, or upgrade it.</p>
<p><kbd>Right Click</kbd> on desktop or <kbd>Tap and hold</kbd> on mobile to refund and downgrade it to the previous click frequency.</p>
<p> </p>
<h3 id="money--other-hints">Money &amp; Other Hints</h3>
<p>You&rsquo;ll quickly find ways to lengthen your Rube-Goldberg Machines and build up value before you send balls into the goal. Your money is displayed on the coin counter next to the ball spawner.</p>
<p> </p>
<p><span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="dotted line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/everything-has-a-price.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>
<strong>Everything has a price!</strong></p>
<p>If you can&rsquo;t draw an item, you probably can&rsquo;t afford it. You&rsquo;ll see your coin counter flash red in the UI when this happens.</p>
<p><span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="dotted line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/dotted-line-mode.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>
<strong>You get what you pay for&hellip;</strong></p>
<p>If you ever find yourself out of money, these dotted lines are free. They are not saved permanently like other lines and they go away after 50 balls hit them.</p>
<p> </p>
<p>❌ A couple of things to watch out for when building ball machines:</p>
<ul>
<li>Balls have to be moving at all times. If they sit still for too long, they are considered dead and will poof out of existence.</li>
<li>This applies to balls hitting the goal, too. If your balls aren&rsquo;t moving much when they hit the target, they won&rsquo;t go in.
So keep your balls moving!</li>
</ul>
<p>😵 If you have a good run going, but it descends into chaos, it can be hard to recover. That&rsquo;s what the <kbd>Erase Balls</kbd> button above the draw tools is for!</p>
<p> </p>
<p>Each post on this site will be a slightly different randomized game! Try making ball machines on multiple pages at once. Your work will be saved in realtime, and you can make money even on pages you&rsquo;re not currently playing on.</p>
<p><span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="dotted line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/page-revenue.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>
 These counters display how much <strong>sustainable</strong> coin revenue per second you&rsquo;re making on this page, and how much other pages you&rsquo;re not currently working on are contributing. Any balls that are spawned automatically and continuously travel through your contraption to hit the goal will be averaged into the top amount. When you visit other pages, you will keep making this money - that&rsquo;s what the &ldquo;Other Pages&rdquo; revenue displays.</p>
<p>Your progress is saved to your device because your contraptions will be highly dependent on the screen size the site renders to.</p>
<p>The game works a bit differently on desktop and mobile, and the best experience is really on desktop - so try on a computer if you can! If on mobile, flip to landscape.</p>
<h3 id="the-end-of-the-game">The End of the Game</h3>
<p>Right now, the Ball Machine doesn&rsquo;t end, but you will be surprised the amount of money you can make across the whole site! Eventually, there will be other ways to spend coins on this site and potentially &ldquo;beat&rdquo; the ball machine. The late game items change the game in very interesting ways! I hope you make some fun machines on my website.</p>
<p>You&rsquo;ll know you&rsquo;ve done about all there is to do by tracking the achievements below!</p>
<h4 id="achievements">Achievements</h4>
<div id="achievements-list"></div>
<script>
document.addEventListener('DOMContentLoaded', function(){
  var container = document.getElementById('achievements-list');
  if(!container){ console.error('Achievements container missing'); return; }
  try {
    var defs = (window.App && App.Achievements && App.Achievements.defs) || [];
    var unlocked = JSON.parse(localStorage.getItem('game.achievementsUnlocked') || '{}');
    var yes = 'https:\/\/hockenworks.com\/images\/achievement-yes.png';
    var no = 'https:\/\/hockenworks.com\/images\/achievement-no.png';
    if(!defs.length){
      console.warn('No achievements definitions found');
    }
    defs.forEach(function(a){
      var row = document.createElement('div');
      var img = document.createElement('img');
      var got = unlocked[a.id];
      img.src = got ? yes : no;
      img.alt = got ? 'Unlocked' : 'Locked';
      img.style.width = '16px';
      img.style.height = '16px';
      img.style.marginRight = '4px';
      row.appendChild(img);
      var b = document.createElement('b');
      b.textContent = a.name;
      row.appendChild(b);
      if(got){
        row.appendChild(document.createTextNode(' – ' + a.desc));
      }
      container.appendChild(row);
    });
    if (location.hash && location.hash.includes('achievements')) {
      var anchor = document.getElementById('achievements');
      if (anchor) {
        setTimeout(function(){ anchor.scrollIntoView(); }, 50);
      }
    }
  } catch(e){
    console.error('Failed to render achievements', e);
    container.textContent = 'Error loading achievements.';
  }
});
</script>

<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<h3 id="resetting-the-game">Resetting the Game</h3>
<span
  style="
    color: #ff0040;
    font-family: 'Arial Black', Arial, sans-serif;
    font-size: 20px;
  "
>
   WARNING! Don't navigate to the below page unless you're sure you want to reset the ball machine game
</span>

<p>Resetting will erase all of your drawings on all pages and reset your goal locations, unlocks, coins and everything else.</p>
<p>If you are thinking about doing this because you want to try on another device, you don&rsquo;t need to, because progress is already saved to your device. The only reason to do this is to have a fresh start on this device.</p>
<p>Navigate <a href="/reset-ball-machine">here</a> and click reset to do that.</p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2025-05-28:/this-website/</guid>

                
                    <link>https://hockenworks.com/this-website/</link>
                

                
                    <pubDate>Wed, 28 May 2025 00:00:00 UTC</pubDate>
                

                
                    <title>This Website</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>Here&rsquo;s a peek at my first major board game creation!</p>
<p>I&rsquo;ve made a few clones or slight enhancements of games I like before like <a href="/nope-game">Nope</a> and <a href="/hocken-pocket-blokus">Hocken-Pocket-Blokus</a>, but Bloom or Bust is my first attempt at something of my own design with very high production quality.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Image description"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/bloom-or-bust-characters.jpg"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">The Cast</span>
    
</div>

<p>This is a risk-taking game where players compete to take over a tree with their specific type of fruit. Trees and bees are becoming a recurring theme in my games!</p>
<p>All parts of this game are hand-designed by me, mostly in VR with a tool called Gravity Sketch, blender, and one of my favorite programmer&rsquo;s 3D tools called OpenSCAD.</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/bloom-or-bust-7.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/bloom-or-bust-4.jpg"    >

</div>
</div>

<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/bloom-or-bust-3.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/bloom-or-bust-8.jpg"    >

</div>
</div>

<p>Of all my models, this one takes most advantage of my multicolor BambuLab printer. All parts including the custom box which cleverly incorporates the instructions and game board itself are printed in BambuLab Matte PLA, which in my opinion is the most beautiful way to print.</p>
<p>Production is batched with 80 to 150 of each fruit or bee on a build plate, with overall production heavily limited by the game board and latching box each requiring a separate print.</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/bloom-or-bust-2.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/bloom-or-bust-9.jpg"    >

</div>
</div>

<p>I have looked into outsourcing production of this game so that I can actually distribute it, but that has not happened yet. Its design is totally dependent on multicolor 3D printing, and most print farms would require nearly $30 just to produce it, let alone shipping it and any margin. Injection molding is an option but also gets expensive with this level of detailed color, and requires remodeling in several significant ways. It still might happen. Or I might put it out on a site that lets people buy the model and print it themselves.</p>
<p>I&rsquo;ll post in the future about how I decide to distribute this. If you really want to buy one now, contact me - but as of now I need to charge about $100 for a set.</p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2025-05-28:/bloom-or-bust/</guid>

                
                    <link>https://hockenworks.com/bloom-or-bust/</link>
                

                
                    <pubDate>Wed, 28 May 2025 00:00:00 UTC</pubDate>
                

                
                    <title>Bloom Or Bust!</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I built a nice little tool to help AI write code for you.</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/R5wztMBfh0w?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p>Well, really, o3-mini and o3-mini-high worked together to write this and I corrected a few things here and there. I started using this tool to write itself about 30 mins into development!</p>
<p>Download on github (above) or the VScode marketplace:</p>
<p><a href="https://marketplace.visualstudio.com/items?itemName=Hockenmaier.context-caddy">https://marketplace.visualstudio.com/items?itemName=Hockenmaier.context-caddy</a></p>
<hr>]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2025-02-13:/context-caddy/</guid>

                
                    <link>https://hockenworks.com/context-caddy/</link>
                

                
                    <pubDate>Thu, 13 Feb 2025 00:00:00 UTC</pubDate>
                

                
                    <title>Context Caddy</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>Custom GPTs are free for everyone as of yesterday, so I thought I’d post some of the best ones I’ve made over the last few months for all of you:</p>
<p>Proofreader (<a href="https://chatgpt.com/g/g-hjaNCJ8PU-proofreader)">https://chatgpt.com/g/g-hjaNCJ8PU-proofreader)</a>:
This one is super simple. Give it what you’ve written and it will provide no-BS proofreads. It’s not going to hallucinate content, just point out mistakes and parts that don’t make sense.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="proofreader GPT"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/proofreader-gpt.png"   style="height: auto; max-width: 200px; width: 100%"   >


    
</div>

<p>Make Real (<a href="https://chatgpt.com/g/g-Hw8qvqqey-make-real)">https://chatgpt.com/g/g-Hw8qvqqey-make-real)</a>:
This makes your napkin drawings into working websites. It’s got some of the same limitations other code-generating AI tools do, but it does a surprisingly good job creating simple working web frontends for your ideas!</p>
<p>Postman for PMs (<a href="https://chatgpt.com/g/g-QeNbSmirA-postman-for-pms">https://chatgpt.com/g/g-QeNbSmirA-postman-for-pms</a>)
Talk to APIs using natural language instead of downloading technical tools or writing code (only unauthenticated APIs, for now). Also a great way to learn about APIs for newbies - Postman for PMs knows about some free online APIs to get started with.</p>
<p>The Boy (<a href="https://chatgpt.com/g/g-efYNPIDrz-the-boy">https://chatgpt.com/g/g-efYNPIDrz-the-boy</a>)
An experimental “AI generated RPG” where you play as “The Boy” who realizes fantastic superpowers. It’s fun to play around and explore, but don’t expect too much consistent gameplay from the currently available AI models.</p>
<p>Exciting times. Have fun!</p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2024-06-01:/some-custom-gpts/</guid>

                
                    <link>https://hockenworks.com/some-custom-gpts/</link>
                

                
                    <pubDate>Sat, 01 Jun 2024 00:00:00 UTC</pubDate>
                

                
                    <title>Some Custom GPTs</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Brian and Alice"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/brian-and-alice-gaming-zoom.jpg"   style="height: auto; max-width: 400px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">↑ me and Alice</span>
    
</div>

<p>I&rsquo;m Brian Hockenmaier, dad, engineer, and fun haver.</p>
<p>I grew up in Ventura, California with two UCLA-engineer parents. Even though neither of them were engineers long-term, I was an engineering child. I was always building something, highlights including a functional submarine and weather balloon with Lego robotics.</p>
<p>I went to school for industrial engineering at <a href="https://www.calpoly.edu/">Cal Poly SLO</a>, nearly double majored in economics, and then promptly moved out of both fields just like my parents had moved out of their education fields of mechanical and aerospace. Since then, after reading Ray Kurzweil&rsquo;s <a href="https://en.m.wikipedia.org/wiki/The_Singularity_Is_Near">The Singularity is Near</a> in 2011, feeling I needed to be closer to software and realizing I liked building systems more than anything in industrial engineering, I&rsquo;ve built a career in software and then AI.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="A lego crane"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/lego-crane.png"   style="height: auto; max-width: 400px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">One of the few pictures I have from my time building robots with legos, showing a robotic crane to my Dad</span>
    
</div>

<p>At work, I try to be low time preference, high autonomy, low consensus (even contrarian), high invention, process-light.</p>
<p>I&rsquo;ve been at one company for a long time for a millennial. I&rsquo;ve built a lot of enterprise software and four high-performing software teams. I started on back-office stuff like billing systems, TV scheduling systems, IP rights management systems, and file ingest systems for News. Most recently I’m making some pretty awesome stuff in agentic AI for the mundane work that the people at my company have to do!</p>
<p>My bias is to build rather than talk. I&rsquo;m the one pushing to just try to build the thing, to scrap it early if needed, and to take risks releasing early. I figure that we always know more, and usually throw away our plans, when we start to build. I love building strange things, useful things, fun things. One of the things I built was this website and the game running on top of it. <a href="/this-website">Read more about that here</a></p>
<p>Other Profiles:</p>
<p>Most of my development projects are stored on public or private repos on <a href="https://github.com/hockenmaier">my github</a></p>
<p>A collection of physical projects and 3D designs can be found on <a href="https://www.thingiverse.com/hockenmaier/designs">my thingiverse</a></p>
<p>And my professional persona can be found on <a href="https://www.linkedin.com/in/hockenmaier/">my linkedin</a></p>
<hr>
<h1 id="where-to-start">Where to start</h1>
<p>I post here mostly about things I&rsquo;m making and occasional essays. If you’re interested in this site but don’t know where to start, try reading any of these posts that sound interesting to you. They&rsquo;re either pieces or projects I put a lot of time into.</p>
<h2 id="video-games">Video Games</h2>
<p>I&rsquo;ve been developing video games on and off since 2017 or so. This has entailed more than 6 project starts and 3 finishes - those are below.</p>
<p> </p>







  








  
  

  

  
  
    
    
  








<article class="latest-item mb-4" style="display:flex; align-items:flex-start;">
  <div class="media-column">
    <div class="media-container" style="width:300px; height:300px;">

      
        <a href="/land-war/">
          <img src="images/land_war_e3.png" alt="Land War">
        </a>

      

    </div>
  </div>

  <div class="text-column" style="align-self:flex-start; margin-top:0;">
    <h2 class="post-title" style="margin-top:0 !important; margin-bottom:0 !important;">
      <a class="link-light" href="/land-war/">Land War</a>
    </h2>
    <div class="post-summary" style="margin-top:0; margin-bottom:.5rem;">
      <p>Land War is an 8-player strategy game I developed as a solo project and released to Steam in March of 2019.<br>
This game was intended to have low art requirements and simple interaction rules that result in deep strategic gameplay.</p>
<p>The core concept is that of an ultra-simplified real-time-strategy game. Each player is represented by a color and can grow their territory by moving in any direction. The strategic elements occur when players encounter other players and have to make choices about which side of their land to defend or give up. Players can use the structure of the map and the coordinated action of other players to gain defensible footholds in order to take more area and eventually be the last player on the board.</p>
    </div>
    <p class="read-more text-secondary fst-italic" style="margin:0;">
      March 1, 2019 · 3 minutes ·
      <a href="/land-war/">Read more →</a>
    </p>
  </div>
</article>


<blockquote>
<p>Land War was my first published video game, released using Unity after many unfinished starts in HTML5 and Unreal Engine. I put myself on a tight timeline, built in 6 months in my spare time and released on Steam only, where it got a few hundred downloads and made a bit over $1000</p>
</blockquote>
<p> </p>
<hr>
<p> </p>







  








  
  
  






<article class="latest-item mb-4" style="display:flex; align-items:flex-start;">
  <div class="media-column">
    <div class="media-container" style="width:300px; height:300px;">

      
        <a href="/treekeepers-vr/">
          <img src="https://hockenworks.com/images/treekeepers_moonlight.png" alt="Treekeepers VR">
        </a>

      

    </div>
  </div>

  <div class="text-column" style="align-self:flex-start; margin-top:0;">
    <h2 class="post-title" style="margin-top:0 !important; margin-bottom:0 !important;">
      <a class="link-light" href="/treekeepers-vr/">Treekeepers VR</a>
    </h2>
    <div class="post-summary" style="margin-top:0; margin-bottom:.5rem;">
      <div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    







    



    


























    
        
    
</div>

<p>Treekeepers VR is a networked VR game where up to 4 players can cooperate to navigate an oversized world and save a giant tree.</p>
<p>Treekeepers is in production on both Quest (standalone VR) and Steam (PC VR) with full cross-play functionality. See the <a href="https://togetheragainstudios.com/treekeepersvr/">Treekeepers VR Website</a> for links to all storefronts and more detail about the game.</p>
<h2 id="heading"></h2>
    </div>
    <p class="read-more text-secondary fst-italic" style="margin:0;">
      October 1, 2022 · 2 minutes ·
      <a href="/treekeepers-vr/">Read more →</a>
    </p>
  </div>
</article>


<blockquote>
<p>Treekeepers VR was an ambitious game development project I took on in 2021- my first published VR title and my first multiplayer title. The latter turned out to be the really hard part. It&rsquo;s now free on two platforms. Read more about it:</p>
</blockquote>
<p> </p>
<hr>
<p> </p>







  








  
  

  

  
  
    
    
  








<article class="latest-item mb-4" style="display:flex; align-items:flex-start;">
  <div class="media-column">
    <div class="media-container" style="width:300px; height:300px;">

      
        <a href="/this-website/">
          <img src="images/bubble4.gif" alt="This Website">
        </a>

      

    </div>
  </div>

  <div class="text-column" style="align-self:flex-start; margin-top:0;">
    <h2 class="post-title" style="margin-top:0 !important; margin-bottom:0 !important;">
      <a class="link-light" href="/this-website/">This Website</a>
    </h2>
    <div class="post-summary" style="margin-top:0; margin-bottom:.5rem;">
      <p>I&rsquo;m <a href="/about-me">Brian Hockenmaier</a>, and this site is full of things I build and write about. I love making games and things with VR and AI. And I love DIY projects, especially ones involving programming, engineering and 3D modeling. Some of this has been cross or back-posted from my <a href="https://www.thingiverse.com/hockenmaier/designs">thingiverse</a>, <a href="https://github.com/hockenmaier">github</a>, <a href="https://www.linkedin.com/in/hockenmaier/">linkedin</a>, and other places, but it all lives here permanently.</p>
<p>This is an evolution of <a href="old-site/index.html">my previous site last updated in 2022, which I still keep inside this one</a> for posterity and for the AIs of the future to know more about me. I like it not because of the content as much as because it was a fully custom js and html site with no framework&hellip; and I think it&rsquo;s sort of fun and funny that it was like this.</p>
    </div>
    <p class="read-more text-secondary fst-italic" style="margin:0;">
      May 28, 2025 · 13 minutes ·
      <a href="/this-website/">Read more →</a>
    </p>
  </div>
</article>


<blockquote>
<p>This Website itself was my 3rd released video game</p>
</blockquote>
<p> </p>
<hr>
<h2 id="top-3d-prints">Top 3D Prints</h2>
<p>I&rsquo;ve been 3D Modeling since Cal Poly and printing since I got my first printer - the MakerGearM2 - in 2013. I have dozens of designs on thingiverse, some of which got pretty popular. A lot of my best work is made up of 3D printed games and game paraphernalia.</p>
<p> </p>







  








  
  
  






<article class="latest-item mb-4" style="display:flex; align-items:flex-start;">
  <div class="media-column">
    <div class="media-container" style="width:300px; height:300px;">

      
        <a href="/bloom-or-bust/">
          <img src="https://hockenworks.com/images/bloom-or-bust-characters.jpg" alt="Bloom Or Bust!">
        </a>

      

    </div>
  </div>

  <div class="text-column" style="align-self:flex-start; margin-top:0;">
    <h2 class="post-title" style="margin-top:0 !important; margin-bottom:0 !important;">
      <a class="link-light" href="/bloom-or-bust/">Bloom Or Bust!</a>
    </h2>
    <div class="post-summary" style="margin-top:0; margin-bottom:.5rem;">
      <p>Here&rsquo;s a peek at my first major board game creation!</p>
<p>I&rsquo;ve made a few clones or slight enhancements of games I like before like <a href="/nope-game">Nope</a> and <a href="/hocken-pocket-blokus">Hocken-Pocket-Blokus</a>, but Bloom or Bust is my first attempt at something of my own design with very high production quality.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    


























    
        
    
</div>

<p>This is a risk-taking game where players compete to take over a tree with their specific type of fruit. Trees and bees are becoming a recurring theme in my games!</p>
<p>All parts of this game are hand-designed by me, mostly in VR with a tool called Gravity Sketch, blender, and one of my favorite programmer&rsquo;s 3D tools called OpenSCAD.</p>
    </div>
    <p class="read-more text-secondary fst-italic" style="margin:0;">
      May 28, 2025 · 2 minutes ·
      <a href="/bloom-or-bust/">Read more →</a>
    </p>
  </div>
</article>


<blockquote>
<p>Bloom Or Bust is my latest and best board game. Fully designed from scratch using OpenSCAD and Gravity Sketch (A very fun VR-based 3D Modeling program)</p>
</blockquote>
<p> </p>
<hr>
<p> </p>







  








  
  
  






<article class="latest-item mb-4" style="display:flex; align-items:flex-start;">
  <div class="media-column">
    <div class="media-container" style="width:300px; height:300px;">

      
        <a href="/8-bit-coasters-10-year/">
          <img src="https://hockenworks.com/images/2023-8-bit-set-2.jpg" alt="8-Bit Videogame Coasters, 10 Year Anniversary Edition">
        </a>

      

    </div>
  </div>

  <div class="text-column" style="align-self:flex-start; margin-top:0;">
    <h2 class="post-title" style="margin-top:0 !important; margin-bottom:0 !important;">
      <a class="link-light" href="/8-bit-coasters-10-year/">8-Bit Videogame Coasters, 10 Year Anniversary Edition</a>
    </h2>
    <div class="post-summary" style="margin-top:0; margin-bottom:.5rem;">
      <p>If you like retro video games and also drinking things, you&rsquo;re in luck!
Print them for your living room! Print them for your friends!
I hope these characters remind you of some of your favorite series.</p>
<p>I returned to <a href="/8-bit-coasters">this project</a> after 10 years to make more coasters, including some designs for multi-plastic printers and a reinforced 4-coaster holder!</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    


























      































    













    



    

























</div>
</div>

<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    


























      































    













    



    

























</div>
</div>

<p>It was super fun returning to this project! I was able to fix a few things that I had noticed failing over the years, like the new reinforced sides to the &ldquo;? Block&rdquo; holder. Now that multi-color prints are proliferating more widely, I&rsquo;m hoping people can use the new colored files - they really pop with the Silk+Matte PLA combo I used here. Links to those filaments:</p>
    </div>
    <p class="read-more text-secondary fst-italic" style="margin:0;">
      August 6, 2023 · 1 minute ·
      <a href="/8-bit-coasters-10-year/">Read more →</a>
    </p>
  </div>
</article>


<blockquote>
<p>My most popular 3D design, remade for color in 2023.</p>
</blockquote>
<p> </p>
<hr>
<p> </p>







  








  
  
  






<article class="latest-item mb-4" style="display:flex; align-items:flex-start;">
  <div class="media-column">
    <div class="media-container" style="width:300px; height:300px;">

      
        <a href="/nope-game/">
          <img src="https://hockenworks.com/images/nope-1.jpg" alt="NOPE - A 3D and 2D Printed Card Game">
        </a>

      

    </div>
  </div>

  <div class="text-column" style="align-self:flex-start; margin-top:0;">
    <h2 class="post-title" style="margin-top:0 !important; margin-bottom:0 !important;">
      <a class="link-light" href="/nope-game/">NOPE - A 3D and 2D Printed Card Game</a>
    </h2>
    <div class="post-summary" style="margin-top:0; margin-bottom:.5rem;">
      <p>This game is based off of a similar card game called &ldquo;No Thanks!&rdquo; but expands the number of players to 8.</p>
    </div>
    <p class="read-more text-secondary fst-italic" style="margin:0;">
      January 19, 2015 · 2 minutes ·
      <a href="/nope-game/">Read more →</a>
    </p>
  </div>
</article>


<blockquote>
<p>My first custom game, NOPE is an expanded version of No Thanks that I released for free on Thingiverse</p>
</blockquote>
<p> </p>
<hr>
<p> </p>







  








  
  
  






<article class="latest-item mb-4" style="display:flex; align-items:flex-start;">
  <div class="media-column">
    <div class="media-container" style="width:300px; height:300px;">

      
        
        <a href="/3d-key/">
          <img src="https://img.youtube.com/vi/_H2W8qXUJtg/hqdefault.jpg" alt="3D Printed Key">
        </a>

      

    </div>
  </div>

  <div class="text-column" style="align-self:flex-start; margin-top:0;">
    <h2 class="post-title" style="margin-top:0 !important; margin-bottom:0 !important;">
      <a class="link-light" href="/3d-key/">3D Printed Key</a>
    </h2>
    <div class="post-summary" style="margin-top:0; margin-bottom:.5rem;">
      <p>I 3D Modeled and printed my apartment building&rsquo;s key with the Makergear M2. I won&rsquo;t be posting the model because it IS in fact a key to my apartment. Thanks for watching!</p>
    </div>
    <p class="read-more text-secondary fst-italic" style="margin:0;">
      May 13, 2013 · 1 minute ·
      <a href="/3d-key/">Read more →</a>
    </p>
  </div>
</article>


<blockquote>
<p>One of my first great 3D printing experiments, I duplicated my apartment key in CAD shortly after getting my first 3D printer, and actually used these keys as spares.</p>
</blockquote>
<p> </p>
<hr>
<p> </p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2024-04-30:/about-me/</guid>

                
                    <link>https://hockenworks.com/about-me/</link>
                

                
                    <pubDate>Tue, 30 Apr 2024 00:00:00 UTC</pubDate>
                

                
                    <title>Hi, I’m Brian</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="this is a robot"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/ai-software-dev.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>Lots of chatter right now about AI replacing software developers.</p>
<p>I agree - AI will take over software development. The question is: what work will be left when this happens?</p>
<p>Some considerations:</p>
<ul>
<li>Benchmarks for the best LLMs still put them solidly in the &ldquo;bad at programming&rdquo; category, scoring in the 5th percentile of human programmers on common tests. Meanwhile, LLMs score in the 80th-95th percentile for law exams and 85th–100th for psychology, statistics, and many other less technical fields. More scores available in the &ldquo;simulated exams&rdquo; section of <a href="https://openai.com/research/gpt-4">https://openai.com/research/gpt-4</a>.</li>
<li>Engineers have been using language models like tabnine and copilot as &ldquo;super-stackoverflow&rdquo; style code assistance years before chatGPT released. This means much of the velocity increase we might expect from current LLMs&rsquo; ability to write code has already been &ldquo;priced in&rdquo; to the market.</li>
<li>Many of the trends making software development more costly are growing, not shrinking: Systems are becoming more distributed. The cloud lowered infrastructure costs but made applications more complex. We&rsquo;re making more and deeper integrations among disparate systems. Auth is becoming more secure and thus complex (managed identity, MFA, etc).</li>
</ul>
<p>Github copilot chat and other LLM dev tools are speeding up the rote stuff. I’ve seen it in my own work.</p>
<p>And I really do believe new AI models will do more than just the basics, maybe in the next couple of years. Even precluding &ldquo;AGI&rdquo;, the trend we are on is that more and more work is automatable, and engineers, especially more junior ones - are going to have to shift focus away from algorithmic work that AI can do.</p>
<p>But by the time our neural nets are &ldquo;good enough&rdquo; at building software to make it significantly cheaper to build, I doubt this trend will make the news. Everything else gets automated too.</p>
<p>These are my thoughts at what seems to be the beginning of the next AI revolution in early 2024. I plan to revisit this topic and see if I&rsquo;m right in future posts.</p>]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2024-01-24:/on-ai-software-development/</guid>

                
                    <link>https://hockenworks.com/on-ai-software-development/</link>
                

                
                    <pubDate>Wed, 24 Jan 2024 00:00:00 UTC</pubDate>
                

                
                    <title>On AI Software Development</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I made &ldquo;Postman for PMs,&rdquo; a tool to help non-engineers understand and use APIs!</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/3O4r_q2Ioko?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p>It&rsquo;s a &ldquo;Custom GPT&rdquo; - a customized version of chatGPT. Just give it some details about the API and then tell it in English what you want to get, post, update, whatever.</p>
<p>If you&rsquo;re a PM, business analyst, or anyone that cares about APIs but doesn&rsquo;t like terminals and engineer-y tools like Postman, and you have ChatGPT plus, try it out. Here&rsquo;s a link:
<a href="https://chatgpt.com/g/g-QeNbSmirA-postman-for-pms">https://chatgpt.com/g/g-QeNbSmirA-postman-for-pms</a></p>
<p>Important disclaimer: DON&rsquo;T use ChatGPT on corporate stuff if your company doesn&rsquo;t allow it! This was a fun experiment for me and I&rsquo;m definitely not using any corporate resources on it/for it. There are plenty of free APIs to try this out on. Maybe ask ChatGPT for some suggestions</p>
<hr>]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2024-01-13:/postman-for-pms/</guid>

                
                    <link>https://hockenworks.com/postman-for-pms/</link>
                

                
                    <pubDate>Sat, 13 Jan 2024 00:00:00 UTC</pubDate>
                

                
                    <title>Postman for PMs</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>This was a board game I &ldquo;cloned&rdquo; back in 2015, but newly redesigned in 2024 with resized pieces and a self-contained custom game box and instructions printed right into the box.</p>
<p>I love small games that travel well, and this game is about the same depth and nearly 1/4th the area of the original box - thus &ldquo;pocket&rdquo;. It&rsquo;s a snug fit but nicely sectioned out for all pieces. Have fun!</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/hocken-pocket-blokus-1.png"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/hocken-pocket-blokus-2.png"    >

</div>
</div>

<h2 id="hocken-pocket-blokus-print-instructions">Hocken-Pocket-Blokus Print Instructions</h2>
<p>If you have a multi-filament printer, check out the new 3mf for &ldquo;Hocken Pocket Blokus&rdquo; - a self contained full blokus game and box with a hinged lid, and game instructions printed into the box.</p>
<p>You can also print the lid and box STLs separately, but if you choose to do that, remember: the pocket version that the box and lid are made for requires scaling the board and pieces: X scaled to 70%, Y scaled to 70% and Z scaled to 115%.</p>
<h2 id="original-print-instructions">Original Print Instructions</h2>
<p>To print the board, print 4 of the &ldquo;Playing Board Quarter&rdquo; file. These should have the right level of tolerance to fit snugly but not too tight.</p>
<p>To print the pieces, you can either use the full plate set of 21 pieces, or pick and choose from the individual files. The file names represent the number of squares in each piece, as well as a word description of what the piece looks like.</p>
<p>Make sure the board and all sets of pieces are distinct colors of plastic.</p>
<p>Here is a link on how to play the game:</p>
<p><a href="http://entertainment.howstuffworks.com/leisure/brain-games/blokus1.htm">http://entertainment.howstuffworks.com/leisure/brain-games/blokus1.htm</a></p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2024-01-03:/hocken-pocket-blokus/</guid>

                
                    <link>https://hockenworks.com/hocken-pocket-blokus/</link>
                

                
                    <pubDate>Wed, 03 Jan 2024 00:00:00 UTC</pubDate>
                

                
                    <title>Hocken-Pocket-Blokus</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>If you like retro video games and also drinking things, you&rsquo;re in luck!
Print them for your living room! Print them for your friends!
I hope these characters remind you of some of your favorite series.</p>
<p>I returned to <a href="/8-bit-coasters">this project</a> after 10 years to make more coasters, including some designs for multi-plastic printers and a reinforced 4-coaster holder!</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/2023-8-bit-set-2.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/2023-8-bit-set-1.jpg"    >

</div>
</div>

<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/2023-8-bit-set-3.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/2023-8-bit-set-4.jpg"    >

</div>
</div>

<p>It was super fun returning to this project! I was able to fix a few things that I had noticed failing over the years, like the new reinforced sides to the &ldquo;? Block&rdquo; holder. Now that multi-color prints are proliferating more widely, I&rsquo;m hoping people can use the new colored files - they really pop with the Silk+Matte PLA combo I used here. Links to those filaments:</p>
<p><a href="https://us.store.bambulab.com/products/pla-matte">https://us.store.bambulab.com/products/pla-matte</a>
<a href="https://us.store.bambulab.com/products/pla-silk-upgrade">https://us.store.bambulab.com/products/pla-silk-upgrade</a></p>
<p>Download on Thingiverse:
<a href="https://www.thingiverse.com/thing:6158533">https://www.thingiverse.com/thing:6158533</a></p>
<p>If you have a Bambulab printer, there is an included .3mf file with coloring and print settings ready to go!</p>
<p>Here&rsquo;s the original thing: <a href="https://www.thingiverse.com/thing:115150">https://www.thingiverse.com/thing:115150</a></p>
<p>Also pictured (third to last picture) are 18 of my favorite remixed coasters from my original thing. Find them in the remixes of the link above!</p>
<p>I&rsquo;ve included an openscad file for customizing multiple sizes of pixel art for your own designs, based on the awesome customizable version by ahtly here:
<a href="http://www.thingiverse.com/thing:139754">http://www.thingiverse.com/thing:139754</a></p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2023-08-06:/8-bit-coasters-10-year/</guid>

                
                    <link>https://hockenworks.com/8-bit-coasters-10-year/</link>
                

                
                    <pubDate>Sun, 06 Aug 2023 00:00:00 UTC</pubDate>
                

                
                    <title>8-Bit Videogame Coasters, 10 Year Anniversary Edition</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I have been occasionally challenging GPT to create models using <a href="https://openscad.org/">OpenSCAD</a>, a &ldquo;programming language for 3D models&rdquo;</p>
<p>Both struggle, but GPT-4 has been a massive improvement. Here are both models&rsquo; outputs after asking for an acorn and 3 messages of me giving feedback:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="some weird acorns"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/gpt-acorn.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>For the record, it is impressive that these LLMs can get anything right with no visual input or training on shapes like these. Imagine looking at the programming reference for openSCAD and trying to do this blind. The fact that the 3.5 version has a bunch of strangely intersecting primitives and some union issues has been normal in my experience. It takes quite a bit of spatial logic to get a model not to look like that.</p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2023-03-19:/3d-modeling-with-ai/</guid>

                
                    <link>https://hockenworks.com/3d-modeling-with-ai/</link>
                

                
                    <pubDate>Sun, 19 Mar 2023 00:00:00 UTC</pubDate>
                

                
                    <title>3D Modeling With AI</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I&rsquo;m writing this post retrospectively as I never published it at the time of creation. It will live here as a &ldquo;stake in the ground&rdquo; of AI software capabilities as of March 2023. Note- if you&rsquo;re reading on substack, this post won&rsquo;t work. Go to <a href="hockenworks.com/gpt-4-solar-system/">hockenworks.com/gpt-4-solar-system</a>.</p>
<p>The interactive solar system below was created with minimal help from me, by the very first version of GPT-4, before even function calling was a feature. It was the first of an ongoing series of experiments to see what frontier models could do by themselves - and I&rsquo;m posting it here because it was the earliest example I saved.</p>
<p>Here&rsquo;s a link to the chat where it was created, though it&rsquo;s not possible to continue this conversation directly since the model involved has long since been deprecated: <a href="https://chatgpt.com/share/683b5680-8ac8-8006-9493-37add8749387">https://chatgpt.com/share/683b5680-8ac8-8006-9493-37add8749387</a></p>

<div style="width:100%; max-width:1000px; margin:1em auto; position:relative; padding-top:70%;">
  <iframe
    src="/html/solar-system-self-contained.html"
    style="position:absolute; top:0; left:0; width:100%; height:100%; border:1px solid #ccc;"
  ></iframe>
</div>

<div style="text-align: center; margin-bottom: 1rem;">
    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">GPT-4 only wrote this for desktop, sorry phone users</span>
    
</div>

<p><strong>Controls</strong></p>
<p><kbd>Mouse Click + Drag</kbd> to move the solar system around</p>
<p><kbd>Mouse Wheel Up</kbd> to zoom in from the cursor location</p>
<p><kbd>Mouse Wheel Down</kbd> to zoom out</p>
<p>If you get lost, reload the page. That&rsquo;s an edge case GPT-4 didn&rsquo;t account for :)</p>
<p>Here was the initial prompt:</p>
<blockquote>
<p>This might be a long output, so if you need to break and I&rsquo;ll ask you to continue in another message feel free to do that. But please limit any non-code text prose to only essential statements to help mitigate this</p>
<p>I want you to make me a dynamic website. It should look good on mobile or on desktop, and I would like you to pick a nice dark background color and an interesting font to use across the page.</p>
<p>The page is intended to show the scale of the solar system in an interactive way, primarily designed for children to zoom in and out of different parts of the solar system and see planets and the Sun in relative scale. Mouse controls should also include panning around the model solar system, and should include text around planets with some statistics about their size, gravity, atmospheres, and any other fun facts you think would be educational and fun for 10-12 year olds.</p>
</blockquote>
<p>Then I had to give it 4 more short prompts, one for a technical hint (to use html-5 since it was going a strange direction) and 3 for visual and mouse control misses.</p>
<p>It works - but missed some of the relatively simple directions, like the planet stats and rendering/controls for mobile. Still, I think it&rsquo;s cool to see the true scale of the planets on a zoomable canvas. And, it only goes to Neptune, the last true planet&hellip; don&rsquo;t go looking for Pluto.</p>
<p>For March 2023, this result was revolutionary - I was truly impressed. In 2025, it&rsquo;s not very impressive at all. How quickly we get used to progress!</p>]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2023-03-18:/gpt-4-solar-system/</guid>

                
                    <link>https://hockenworks.com/gpt-4-solar-system/</link>
                

                
                    <pubDate>Sat, 18 Mar 2023 00:00:00 UTC</pubDate>
                

                
                    <title>GPT-4 Solar System</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I made my latest Unity project into a multi-application &ldquo;engine&rdquo;. I am now building and releasing two applications from one project. Let me show you how it works.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Switching apps in the treekeepers engine"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/treekeepers-app-switcher-1.gif"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">Switching apps in the treekeepers engine</span>
    
</div>

<p>I did this because I had a lot of assets and code in Treekeepers that would directly translate to a new project I was prototyping. I considered other approaches - git submodules, unity packages, just cloning my old project. After a cost-benefit writeup I decided on this.</p>
<p>Now when I change variables, I edit a class called “Application Definition” for each application, which look like this:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="An applictaion definition in the editor"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/treekeepers-app-switcher-2.png"   style="height: auto; max-width: 400px; width: 100%"   >


    
</div>

<p>My plan is to use this new &ldquo;Engine project&rdquo; to not only update multiple games with common assets and code easily, but also as an instant starting point for any new networked VR/AR prototype.</p>
<p>As I go, any code I refactor to be generic across all projects goes in an Engine folder. Same for prefabs, materials, etc.</p>
<p>This way, if this gets cumbersome in the future, I can make a git submodule out of everything in &ldquo;Engine&rdquo; and import that into a new project.</p>
<p>Here are the scripts. The first runs via the Editor UI and takes variables for anything that needs to be different by project. The second file has the application definition classes you saw in the image above.</p>
<p><a href="https://gist.github.com/hockenmaier/14d50ff0bb90aece1cc6de1b9fc5419d">https://gist.github.com/hockenmaier/14d50ff0bb90aece1cc6de1b9fc5419d</a></p>
<script src="https://gist.github.com/hockenmaier/14d50ff0bb90aece1cc6de1b9fc5419d.js"></script>

<p>The files are free to use. Check them out if you&rsquo;re in a similar situation, but be warned there are still some hard-coded things and references you’ll need to change.</p>
<p>Has anyone taken this approach before? Curious on other&rsquo;s take or approaches to similar problems!</p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2023-03-17:/treekeepers-engine/</guid>

                
                    <link>https://hockenworks.com/treekeepers-engine/</link>
                

                
                    <pubDate>Fri, 17 Mar 2023 00:00:00 UTC</pubDate>
                

                
                    <title>Treekeepers Engine</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I’ve been playing around with <a href="https://en.wikipedia.org/wiki/Neural_radiance_field">neural radiance fields</a> (NeRFs) lately and thought a fun way to explore them would be flying through them in the Treekeepers “Puddle Jumper” in true scale.</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/QguH3aK90Ck?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p>Of course, you lose a lot of the draw of NeRFs when you export the model into a 3d engine because it has to flatten all the textures and lighting, and also Luma AI cuts off 3D model exports as a jarring cube</p>
<p>But still - I was amazed at how well just applying a day/night lighting cycle and mesh colliders worked with this. Projectile and enemy physics played well too.</p>
<p>It’s still early days, but I could see 3D model generation from this tech getting a lot better and forming the basis for some really interesting user-generated content in the future!</p>
<p>Neat stuff - big thanks to Luma AI for the free toolset.</p>]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2023-02-01:/nerfs/</guid>

                
                    <link>https://hockenworks.com/nerfs/</link>
                

                
                    <pubDate>Wed, 01 Feb 2023 00:00:00 UTC</pubDate>
                

                
                    <title>NeRFs in VR</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    







    



    























<img  alt="The Treekeepers Puddle Jumper"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/treekeepers_moonlight.png"   style="height: auto; max-width: 100%"   >


    
        <span style="font-style: italic; margin-top: 0.5rem;">The Treekeepers Puddle Jumper</span>
    
</div>

<p>Treekeepers VR is a networked VR game where up to 4 players can cooperate to navigate an oversized world and save a giant tree.</p>
<p>Treekeepers is in production on both Quest (standalone VR) and Steam (PC VR) with full cross-play functionality. See the <a href="https://togetheragainstudios.com/treekeepersvr/">Treekeepers VR Website</a> for links to all storefronts and more detail about the game.</p>
<h2 id="heading"></h2>
<h2 id="development">Development</h2>
<p>I began working on Treekeepers in June 2021, and my primary goal was to go significantly deeper into Unity and make a fully networked game. Very few co-op games existed in VR at the time (the area is still lacking), and my intention was to answer this need and create a game that 4 players could cooperate in within a static frame of reference (players move within a ship, and the ship moves through the world) while having to solve coordination challenges together.</p>
<p>I initially designed the project for SteamVR only using the SteamVR SDK but quickly realized that a VR game released only on PC would miss the majority of the userbase, as the (then Oculus) Quest 2 was quickly dominating the market. Treekeepers was a good fit for a mobile platform with its simple low-poly cel-shaded design, so I pivoted to using OpenXR about two months into the project to support VR interactions on both PC and mobile (Android) devices like the Quest 2.</p>
<p>By summer 2022, I had a releasable product, albeit only with one “world” available. I decided to push the game to early access to gather rapid feedback from real players, and after getting approved for both storefronts, Treekeepers released to early access on September 30, 2022.</p>]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2022-10-01:/treekeepers-vr/</guid>

                
                    <link>https://hockenworks.com/treekeepers-vr/</link>
                

                
                    <pubDate>Sat, 01 Oct 2022 00:00:00 UTC</pubDate>
                

                
                    <title>Treekeepers VR</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<blockquote>
<p>Editor&rsquo;s note from 2025:</p>
<p>This article was written as part of the launch of <a href="/treekeepers-vr">Treekeepers VR</a> and the sole proprietorship Together Again Studios, and represents some of my core beliefs of the value of VR and where it&rsquo;s taking us socially. Though I&rsquo;m no longer actively working on Treekeepers, I do hold that VR and AR are truly the &ldquo;endgame&rdquo; of interface and one that could save us from some of the social attitudes caused by social media of today. Enjoy!</p>
</blockquote>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="proofreader GPT"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/together-again-studios.png"   style="height: auto; max-width: 400px; width: 100%"   >


    
</div>

<p>With Together Again Studios and Treekeepers VR, we&rsquo;re setting out to solve an insidious problem we see all around us:</p>
<p><strong>Social Media Is Anti-Social</strong></p>
<p>Though Facebook, Instagram, Twitter, and Tiktok all let us share more with each other than ever before, what we are sharing is surprisingly hostile and dismissive of opinions other than our own.</p>
<p>Though Zoom, Hangouts and Teams let us finally see each other from a distance, we still can&rsquo;t speak naturally. We depend on tools like &ldquo;mute&rdquo;. We create meeting upon meeting with different sets of the same group of people. And we don&rsquo;t form the depth of relationships we could in-person.</p>
<p>We as humans are all-too-capable of forming us-versus-them &ldquo;tribes&rdquo; and dehumanizing those who appear too different, and this problem is becoming ever more apparent behind the curtain of the graphical user interface.</p>
<p><strong>Virtual and augmented reality are a way out</strong></p>
<p>In 2016, thanks to pioneers like Palmer Luckey, Michael Abrash, and John Carmack, we suddenly gained access to a technology that removes the curtain and forces us to see eachother. And in 2020, an event that has permanently limited our in-person interaction arose and gave new meaning to this technology.</p>
<p>In VR/AR, voices are no longer text on a screen, taken out of context by our social media bubbles. They&rsquo;re voices again.</p>
<p>In VR/AR, people are no longer user profiles with one image and a tag-line. They&rsquo;re really people, with bodies, faces, and hands that can point and gesture.</p>
<p>In VR/AR, messages are not just &ldquo;public&rdquo;, or &ldquo;direct&rdquo;. Conversations are dynamic, with people physically approaching one another to talk, with people moving in and out of physical groups, and with people attending public conversations together again while still able to have &ldquo;sidebar&rdquo; conversations.</p>
<p>All these abilities we used to have in-person, we have gained again in virtual reality.</p>
<p>Soon, we&rsquo;ll go even further with this technology. We&rsquo;ll be able to make real eye contact with eachother in VR. We&rsquo;ll use AR to invite distant friends and family over to our homes.</p>
<p>And at Together Again, we plan on using these new tools to let people like eachother again.</p>
<p><strong>Treekeepers: Only Possible in VR</strong></p>
<p>Why is Treekeepers a VR Game?</p>
<p><strong>Multiplayer of this depth only works in VR</strong></p>
<p>The challenges in Treekeepers VR hinge on player coordination and quick group decisions - Which weapon should we upgrade? Who&rsquo;s doing which job? Where are we going?</p>
<p>In VR, you gain the ability to gesture and point to enemies and obstacles naturally.</p>
<p>No more &ldquo;Who is the green player?&rdquo; - spend zero mental energy figuring out who you are talking to. Just turn towards them and speak.</p>
<p><strong>Scale is the most fun when you&rsquo;re in the world</strong></p>
<p>We&rsquo;re going to be exploring oversized objects around a gigantic tree. Only VR can get the full benefit of this experience.</p>
<p><strong>VR can be uncomfortable</strong></p>
<p>BUT, experiencing it via a static vehicle which acts as a persistent frame of reference reduces motion sickness.</p>
<p>No need to rotate - gameplay is based on the hot air balloon always facing one direction, and players navigating within it.</p>
<hr>
<p>Check out Treekeepers VR <a href="/treekeepers-vr">here</a></p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2022-08-01:/social-media-is-antisocial/</guid>

                
                    <link>https://hockenworks.com/social-media-is-antisocial/</link>
                

                
                    <pubDate>Mon, 01 Aug 2022 00:00:00 UTC</pubDate>
                

                
                    <title>Social Media Is Anti-Social</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>The &ldquo;Human Joystick&rdquo; is an experimental VR movement system in which the player moves through the virtual environment by changing their physical location within their VR &ldquo;playspace&rdquo;.</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/q_1itpdiPb4?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p>A demo of the human joystick movement system, showing how the system can work on flat surfaces or terrain.</p>
<p>This was my first barebones VR project. Though I knew Unity going in, VR and 3D games in general have a lot of unique aspects that I wanted to learn about while trying to solve an actual problem, rather than following tutorials or demos online.</p>
<p>VR has some adoption problems in its current state. We all know of some of the main problems- the clunky headset, the nausea issues, and of course the pricetag. But one major problem that you don&rsquo;t really notice until you get into it, is the lack of a good solution for virtual movement.</p>
<p>I had been wondering about &ldquo;the human joystick&rdquo; as a potential a solution to this particular problem ever since getting into consumer VR in 2016.</p>
<p>In most modern VR systems, the player can move physically around the room if they choose. Some applications and games depend on this - they put you in a small space and rely on your physical movement in order to reach different areas and interact with things. But games that provide a more traditional sense of scale and allow players to move through large worlds cannot rely on physical motion, because their users are constrained by physical space. Because of this, you see all kinds of &ldquo;artificial&rdquo; locomotion systems in order to let people move around - some just like traditional 2D games that let users &ldquo;slide&rdquo; their playspaces around the world using a joystick, and others that adopt teleportation mechanics. Neither feel very natural as compared to actually walking, and some can be downright sickening.</p>
<p>My goal with this project was to solve this problem with a mixture of physical and artificial movement.</p>
<p>It works like this: When the player is standing near the center of their playspace, physical VR movement applies. The player can move around and interact with things with their actual bodies. But once the player moves further from the center, the plaspace starts to move with them in the same direction as the vector from the center of the player&rsquo;s space to their current position. This allows for some of the benefits that physical movement experiences have, while allowing the players to more naturally move through an infinite amount of space.</p>
<p>I experimented with several speeds, both static and scaling with the distance between the center and the player. I also experimented with the size of the physical movement &ldquo;deadzone&rdquo; and with vertical and constrained movement across hills, valleys, and buildings.</p>
<hr>
<table>
  <thead>
      <tr>
          <th style="text-align: center">


















<div class="paige-image">
    





























    



    

    
        

        

        
    
        

        

        
    
        

        
            

    



    







    





    



    























<img   class="img-fluid "  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/human_joystick_centered.jpg"   style="display:block; height: auto; margin:0 auto; width: 60%"   >


</div>
</th>
          <th style="text-align: left"><em>View from the player&rsquo;s perspective looking at the guides at his feet. With the white dot in the red deadzone, the player isn&rsquo;t moving.</em></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">


















<div class="paige-image">
    





























    



    

    
        

        

        
    
        

        

        
    
        

        
            

    



    







    





    



    























<img   class="img-fluid "  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/human_joystick_moving.jpg"   style="display:block; height: auto; margin:0 auto; width: 60%"   >


</div>
</td>
          <td style="text-align: left"><strong><em>When the white dot is in the green area, the player moves in that direction. Here I am moving forward and left at about half of max speed.</em></strong></td>
      </tr>
  </tbody>
</table>
<hr>
<p>Eventually I found some good default values and the system worked, but there were some unforeseen problems: First, it was more difficult to center yourself within the playspace without looking at the visible guides I put at the player&rsquo;s feet than I expected. Second and more importantly, when you were already moving in one direction, it was not as simple as I thought to start moving in another direction accurately without fully returning to center, which was an immersion breaker.</p>
<p>Ultimately I put the project up for others to view but have not expanded it into a full experience or released it on any marketplaces. Feel free to download the Unity project and try it on your own VR setup if you&rsquo;re curious.</p>]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2020-01-01:/human-joystick/</guid>

                
                    <link>https://hockenworks.com/human-joystick/</link>
                

                
                    <pubDate>Wed, 01 Jan 2020 00:00:00 UTC</pubDate>
                

                
                    <title>Human Joystick VR</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>The Answering Machine is a proof-of-concept system that I built using <strong>pre-LLM</strong> natural language processing (NLP), specifically NLTK, to produce answers to questions asked about data in plain English.</p>
<p>Looking back, this project was a great insight into what LLMs immediately allowed that was incredibly difficult before. This project was several months of work that the openAI sdk would probably have allowed in a few weeks - and that few weeks would have been mostly frontend design and a bit of prompting.</p>
<p><strong>Try it here:</strong> <a href="http://voicequery-dev.s3-website-us-west-2.amazonaws.com/">http://voicequery-dev.s3-website-us-west-2.amazonaws.com/</a>
<strong>Github:</strong> <a href="https://github.com/hockenmaier/voicequery">https://github.com/hockenmaier/voicequery</a></p>
<p>The system uses natural language processing to produce answers to questions asked about data in plain English.</p>
<p>It is designed with simplicity in mind—upload any columnar dataset and start asking questions and getting answers. It uses advanced NLP algorithms to make assumptions about what data you&rsquo;re asking about and lets you correct those assumptions for follow-up questions if they&rsquo;re wrong.</p>
<p>It is built entirely out of serverless components, which means there is no cost to maintain or run it other than the traffic the system receives.</p>
<h2 id="how-to">How-to</h2>
<p>On a desktop or tablet, click the link in the header to navigate to the Answering Machine. For now, it isn&rsquo;t optimized for smartphone-sized screens.</p>
<p>In order to use the Answering Machine, you can either select one of the existing datasets, such as &ldquo;HR Activity Sample,&rdquo; or upload one of your own using the homepage of the site:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Answering Machine homepage"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/answering_machine_uploads.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>To upload your own, click in the upload area or just drag a file straight from your desktop. For now, use CSV data files. Excel and other spreadsheet programs can easily save data in the CSV format using the &ldquo;File &gt; Save As&rdquo; or similar option in the menu. Each file needs a unique name.</p>
<p>When you hit the upload button, the site may not appear to change until the file is uploaded, at which point you&rsquo;ll see it appear in the box labeled &ldquo;Ask Your Data Anything&rdquo; below. Click on your file to start using it with the Answering Machine, or click the red trash can icon to delete it.</p>
<p>There are no user accounts in this system yet, so the data you upload might be seen by other users using the system. Try not to use sensitive data for now.</p>
<h3 id="asking-questions">Asking questions</h3>
<p>When you enter a dataset, you&rsquo;ll see a view that presents you with quite a bit of information:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    







    





    



    























<img  alt="Answering Machine main view"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/answering_machine_hr.png"   style="height: auto; width: 100%"   >


    
</div>

<p>The only part you need to focus on right now is the information panel. This panel lists out all the fields (columns), data types of those fields, and some sample data from a few records in your dataset:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Answering Machine info panel"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/answering_machine_info.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>You can use this panel to start to formulate questions you might have about the data. If you see number values, you might ask about averages, maximums, or other math that might otherwise take some time to calculate. If you see a date, you can ask questions about the data in certain time periods.</p>
<p>Many datasets also contain fields that only have a few specific allowed values. When the Answering Machine sees fewer than 15 unique values in any field, the data type will be a &ldquo;List&rdquo; and it lists them right out under the sample values table. You can use this type of value to ask questions about records containing those specific values. For example, in the HR dataset, you might only be interested in data where the &ldquo;Education&rdquo; field&rsquo;s value is &ldquo;High School.&rdquo;</p>
<p>Now look to the query bar to start asking your data questions:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Answering Machine query bar"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/answering_machine_query.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>The types of questions that will currently be automatically detected and answered are:</p>
<ul>
<li>Counts of records where certain conditions are true</li>
<li>Math questions such as averages, medians, maximums, and minimums</li>
</ul>
<p>These types of questions can be made specific by using qualifying statements with prepositional phrases like &ldquo;in 2019&rdquo; or adjective phrases like &ldquo;male&rdquo; or &ldquo;entry-level.&rdquo;</p>
<p>Combining these two ideas, you can ask specific questions with any number of qualifiers, such as:<br>
<em>&ldquo;What was the median salary of male employees in the engineering department 5 years ago?&rdquo;</em></p>
<p>Upon hitting the &ldquo;Ask&rdquo; button (or hitting Enter), the Answering Machine will do its best to answer your question and will show you all of its work in this format:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Answering Machine response"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/answering_machine_answer.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>The last line in the response is the Answering Machine&rsquo;s answer. In this case, it is telling you the metric you asked for with all your stipulations is <strong>6871.6 dollars.</strong></p>
<p>Moving up, you see a series of assessments that the Answering Machine has made in order to filter and identify the data you are asking about. Statements like &ldquo;Best auto-detected Numeric Subject Found: salary with column: Compensation (Monthly)&rdquo; provide a glimpse into one of the Answering Machine&rsquo;s most advanced features, which uses a selection of NLP techniques to compare words and phrases that are similar in meaning, ultimately matching things you are asking about to fields and values that actually exist in your database.</p>
<p>At the very top of the response is how the Answering Machine&rsquo;s nested grammar parsing logic actually parsed your question, with some specific pieces color-coded:</p>
<ul>
<li><strong>Green</strong> chunks indicate &ldquo;subjects&rdquo; that were detected. Subjects are what the Answering Machine thinks you&rsquo;re asking &ldquo;about.&rdquo; These should represent both the main subject and other supporting subjects in your question.</li>
<li><strong>Purple</strong> chunks are conditions. These are the things that the Answering Machine thinks you are trying to use to &ldquo;specify&rdquo; or filter data.</li>
</ul>
<p>Now that your question is answered, you might notice that some new green and purple colored bubbles have appeared in the sections of your screen labeled &ldquo;New Subjects&rdquo; and &ldquo;New Conditions.&rdquo; We&rsquo;ll call these &ldquo;lexicon&rdquo;:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Answering Machine subjects and conditions"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/answering_machine_lexicon.png"   style="height: auto; max-width: 400px; width: 100%"   >


    
</div>

<h3 id="forming-concepts">Forming Concepts</h3>
<p>If the Answering Machine already understood what you were asking and successfully matched it to fields and values in your data, you don&rsquo;t have to do anything with these. But often you will be using domain-specific lexicon, or the auto-matching algorithm simply won&rsquo;t pick the correct value. These situations are what concepts are for.</p>
<p>To create a concept, click and drag on the green or purple &ldquo;lexicon&rdquo; bubble and move it out into the blank middle area of the screen. Then click and drag the field or field value from the info-panel at the top of the screen and drop it right on top of that bubble. You&rsquo;ll see both the data bubble and the lexicon bubble included in a larger gray bubble, which represents the concept:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Answering Machine concept"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/answering_machine_concept.png"   style="height: auto; max-width: 200px; width: 100%"   >


    
</div>

<p>You can add more lexicon bubbles to this concept if they mean the same thing, but you can only use one data bubble.</p>
<p>Concepts override the Answering Machine&rsquo;s auto-matching logic. If you ask another question containing a subject or condition that is now matched by a user to a data value, that data value will be used instead of the auto-match. If the concept isn&rsquo;t working well, you can delete it by dragging all of the nested bubbles out of it either into the blank middle area or into the colored panel they originally came from.</p>
<p>Feel free to play around with new datasets and questions, and use the contact section of this site if you have comments or questions. When you ask questions or create/modify concepts, that data will automatically be saved to the server in real-time. You can close the page anytime and come back to your dataset to keep asking questions.</p>
<p>Remember that there are no user accounts, meaning you can share your dataset and work in tandem with others! But again, please do not upload sensitive data to this proof-of-concept tool as it will be available for other users to see and query.</p>
<h2 id="architecture">Architecture</h2>
<p>The Answering Machine is a purely &ldquo;serverless&rdquo; application, meaning that there is no server hosting the various components of the application until those components are needed by a user. This is true for the database, the file storage, the static website, the backend compute, and the API orchestration.</p>
<p>For the cloud nerds out there, <a href="https://martinfowler.com/articles/serverless.html">here is a great article</a> by Martin Fowler on what exactly &ldquo;serverless&rdquo; means, especially in terms of the backend compute portion, which is arguably the most valuable part of the application to be serverless. For reference, I am using Martin&rsquo;s 2nd definition of &ldquo;serverless&rdquo; here.</p>
<p>This is a high-level map of all of the components that make the Answering Machine work in its current (June 2020) state. The API gateways, CloudWatch events, and some triggers &ldquo;given for free&rdquo; by AWS are left out of this for readability:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Serverless Architecture of the Answering Machine app"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/answering_machine_architecture.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>The full suite of lambdas and persistent storage services that make up the Answering Machine.</p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2019-07-03:/answering-machine/</guid>

                
                    <link>https://hockenworks.com/answering-machine/</link>
                

                
                    <pubDate>Wed, 03 Jul 2019 00:00:00 UTC</pubDate>
                

                
                    <title>The Answering Machine</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>Land War is an 8-player strategy game I developed as a solo project and released to Steam in March of 2019.<br>
This game was intended to have low art requirements and simple interaction rules that result in deep strategic gameplay.</p>
<p>The core concept is that of an ultra-simplified real-time-strategy game. Each player is represented by a color and can grow their territory by moving in any direction. The strategic elements occur when players encounter other players and have to make choices about which side of their land to defend or give up. Players can use the structure of the map and the coordinated action of other players to gain defensible footholds in order to take more area and eventually be the last player on the board.</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/5Q8PAuWcmQc?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p>A full game of the final product released on Steam played on a Windows computer.</p>
<h3 id="development">Development</h3>
<p>I built Land War over the course of 7 months and 400 hours of work using Unity with C#. Though art requirements were intentionally low for a video game, I still had to produce several hundred static graphics and GIFs, and commissioned custom music for the menu and gameplay.</p>
<p>This project is one of my favorite examples of what can be done in relatively little time with a focused vision and a constant eye on scope creep. From the very start, I knew that a key to making compelling software was to flesh out the core concept before all else. This is why I started on the most fundamental strategic interaction of the players and built an MVP version of the game without a menu, sound, art, or even a win condition.</p>
<p>I started the project on a Memorial Day Monday, and by Friday had a rudimentary prototype playable with 8 players on Nintendo Joy-Con controllers paired to a Windows machine via Bluetooth.<br>
This is what the project looked like for my first play-test with other people 5 days in:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    







    





    



    























<img  alt="Land War 4-day MVP"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/land_war_mvp.gif"   style="height: auto; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">4-player game played with Nintendo Joy-Cons on a build of the game from 5 days into development.</span>
    
</div>

<p>From there, I continued to work on depth and full feature functionality including menus, a tutorial, a map generator, a dynamic scoring and round system, better sound and sprite graphics, different play modes and settings, and support for many controllers. I released the game with very little marketing aside from some Reddit posts and a physical handout at E3 but was happy to receive positive reviews and several hundred purchases of the game.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    







    





    



    























<img  alt="Player Select screen"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/land_war_player_select.png"   style="height: auto; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">Player Select screen. Supporting menu and player controls across hundreds of controller types was one of the largest unforeseen challenges in developing Land War.</span>
    
</div>

<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    







    





    



    























<img  alt="Settings menu"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/land_war_settings.png"   style="height: auto; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">Settings menu. Most interesting mechanics I found while developing the game were added as options to keep the game interesting here.</span>
    
</div>

<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="E3 marketing material"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/land_war_e3.png"   style="height: auto; max-width: 400px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">The only physical marketing material developed for Land War. Several hundred Steam keys (copies of the game) were handed out during the E3 convention in 2019.</span>
    
</div>


    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/BylKEPF4EeU?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p><em>Land War&rsquo;s Steam release announcement trailer.</em></p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2019-03-01:/land-war/</guid>

                
                    <link>https://hockenworks.com/land-war/</link>
                

                
                    <pubDate>Fri, 01 Mar 2019 00:00:00 UTC</pubDate>
                

                
                    <title>Land War</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>First Ten is an educational app containing information about the U.S. Bill of Rights, accessible on Google devices and smart speakers. It uses a VUI (voice user interface) only, meaning there is no visual way to interact with the app.</p>
<p><strong>Try it here:</strong> <a href="https://assistant.google.com/services/a/uid/00000036f6a580ed">https://assistant.google.com/services/a/uid/00000036f6a580ed</a>
<strong>Github:</strong> <a href="https://github.com/hockenmaier/billofrights">https://github.com/hockenmaier/billofrights</a></p>
<p>Like Alexa skills, Google actions can be accessed through search or by simply asking for their names in Google Home smart speakers. Ask your Google Home or Android device, &ldquo;Can I speak to First Ten?&rdquo; in order to try it.</p>
<h3 id="architecture">Architecture</h3>
<p>First Ten&rsquo;s backend is built in the serverless AWS services Lambda and DynamoDB, and its frontend—the engine that parses your voice into different &ldquo;intents&rdquo; and parameters—is built on Google&rsquo;s Dialogflow.
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Serverless Architecture of the First Ten app"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/first_ten_architecture.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>
</p>
<hr>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2018-05-19:/first-ten/</guid>

                
                    <link>https://hockenworks.com/first-ten/</link>
                

                
                    <pubDate>Sat, 19 May 2018 00:00:00 UTC</pubDate>
                

                
                    <title>First Ten</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p><strong>Raspberry Pi Control Panel</strong> is a hardware project I designed in 2016 to manage home automation systems. The project involved designing a custom 3D-printed case for a Raspberry Pi microcomputer with a touchscreen interface.</p>
<p>Links:</p>
<ul>
<li><a href="https://github.com/hockenmaier/RaspberryPiControlPanel">GitHub</a></li>
<li><a href="https://www.thingiverse.com/thing:2524560">Thingiverse</a></li>
</ul>
<hr>
<p>I created this panel display in 2016 to control much of the home automation I used in my Studio City apartment. Mainly a hardware project, I designed and 3D-printed a case and frame for the touchscreen and raspberry pi microcomputer in order to mount them to the wall. The software running the control panel is SaaS, but I did write a custom html wrapper to control the orientation and settings of the site, which is available on the github linked above.</p>
<p>Update in 2025: This panel is still my main view into my home automation in my new house in Sherman Oaks, almost 10 years in with no modification!</p>
<p>Here&rsquo;s a video to see the panel in action:</p>
<h2 id="hahahugoshortcode30s0hbhb">
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/iFGmm-ijJvE?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>
</h2>
<p>Feel free to explore the linked repositories for schematics and source code.</p>
<h2 id="instructions">Instructions</h2>
<p>If you want to make this, all you need to do is set up a raspberry pi, download chromium (or your preferred web browser), and navigate to your action tiles panel.</p>
<p>If you want to mount the screen vertically like mine, then I have made an easier solution than going through the trouble of actually rotating the raspberry&rsquo;s display and touch device. Just use the html below and edit it to use your own panel&rsquo;s URL in the &ldquo;iframe&rdquo; element instead of mine. This will launch the panel rotated in your browser.</p>
<pre tabindex="0"><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Rotated Raspberry Panel&lt;/title&gt;
	&lt;style type=&#34;text/css&#34;&gt;
		body {
		   -webkit-transform: rotate(90deg);
		   -webkit-transform-origin: bottom left;
		   position: absolute;
		   top: -100vw;
		   height: 100vw;
		   width: 100vh;
		   background-color: #000;
		   color: #fff;
		   overflow: hidden;&#34;
		}
	   iframe{

			-ms-transform: scale(0.97);
			-moz-transform: scale(0.97);
			-o-transform: scale(0.97);
			-webkit-transform: scale(0.97);
			transform: scale(0.97);

			-ms-transform-origin: 0 0;
			-moz-transform-origin: 0 0;
			-o-transform-origin: 0 0;
			-webkit-transform-origin: 0 0;
			transform-origin: 0 0;
		}
	&lt;/style&gt;
  &lt;/head&gt;
  &lt;body&gt;
	&lt;iframe src=&#34;https://app.actiontiles.com/panel/f7a7118c-236b-4144-b5b9-ccb35abeef21&#34; height=&#34;300%&#34; width=&#34;300%&#34; frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre><p>Link to buy the screen:
<a href="https://smile.amazon.com/gp/product/B01ID5BQTC/">https://smile.amazon.com/gp/product/B01ID5BQTC/</a></p>
<p>Link to the Action Tiles web application this is running:
<a href="https://www.actiontiles.com/">https://www.actiontiles.com/</a></p>
<p>If you have issues getting your pi to use the full touchscreen width, try adding these setting to the /boot/config.txt file and reboot:</p>
<pre tabindex="0"><code>max_usb_current=1
hdmi_group=2
hdmi_mode=1
hdmi_mode=87
hdmi_cvt 800 480 60 6 0 0 0
</code></pre><p>If you want to make sure your screen doesn&rsquo;t go to sleep:</p>
<pre tabindex="0"><code>sudo nano /etc/lightdm/lightdm.conf
</code></pre><p>Add the following lines to the [SeatDefaults] section:</p>
<pre tabindex="0"><code>xserver-command=X -s 0 dpms
</code></pre>]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2016-01-01:/raspberry-pi-panel/</guid>

                
                    <link>https://hockenworks.com/raspberry-pi-panel/</link>
                

                
                    <pubDate>Fri, 01 Jan 2016 00:00:00 UTC</pubDate>
                

                
                    <title>Raspberry Pi Control Panel</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>This game is based off of a similar card game called &ldquo;No Thanks!&rdquo; but expands the number of players to 8.</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img  alt="nope"   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/nope-1.jpg"    >


      































    













    



    























<img  alt="nope"   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/nope-2.jpg"    >

</div>
</div>

<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img  alt="nope"   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/nope-3.jpg"    >


      































    













    



    























<img  alt="nope"   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/nope-4.jpg"    >

</div>
</div>

<p>Play time is about 20 minutes for the 3-5 player version, and 25-30 minutes for the 6-8 player version. Learning how to play the game takes 1-5 minutes depending on the attention span of the players. Have fun!</p>
<p>See Thingiverse for all of the files:
<a href="https://www.thingiverse.com/thing:643099">https://www.thingiverse.com/thing:643099</a></p>
<h1 id="print-instructions">Print Instructions</h1>
<p>3D-Print 88 tokens.</p>
<p>2D-Print the 2 included PDFs back-to-back, so that the numbers appear on the one side and the identical backsides are on the back. Or, leave out the backs as they are not necessary to play the game. Cut 9 cards out of each paper when they&rsquo;re done printing, along the gray lines.</p>
<p>It is recommended to either print on heavy duty paper, or to laminate the resulting cards.</p>
<p>You can also choose to make your own layout with larger or smaller cards using the included zip file of images.</p>
<p>For the 3-5 player game, print the cards numbered 3 to 35. For the 6-8 player game, print the cards numbered 3 to 46.</p>
<h1 id="to-play">To Play:</h1>
<p>Here is a link to the 3-5 player instructions:
<a href="https://cdn.1j1ju.com/medias/17/c3/3c-no-thanks-rulebook.pdf">https://cdn.1j1ju.com/medias/17/c3/3c-no-thanks-rulebook.pdf</a></p>
<p>The 6-8 player instructions are almost exactly the same as the 3-5 player game:
-All players still receive 11 tokens at the beginning of the game.
-Play with the 3-46 deck, shuffle the deck, and remove 11 cards instead of 9 cards before playing.</p>]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2015-01-19:/nope-game/</guid>

                
                    <link>https://hockenworks.com/nope-game/</link>
                

                
                    <pubDate>Mon, 19 Jan 2015 00:00:00 UTC</pubDate>
                

                
                    <title>NOPE - A 3D and 2D Printed Card Game</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>This is a working 3D-printed egg slicer! Why buy it when you can print it?</p>
<p>Both parts are printable without support and minimal bridging.</p>
<p>You can download the model for free on Thingiverse:
<a href="http://www.thingiverse.com/thing:440150">http://www.thingiverse.com/thing:440150</a></p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/1J0rH7o0R88?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<h2 id="instructions">Instructions</h2>
<p>Printing:
Print in ABS if possible. ABS is dishwasher safe (will not warp) and PLA is not. Print it hot to make it waterproof, if possible. I used .15 mm layers for the top and .25 mm layers for the base, and 30% fill for both. I would highly recommend a layer height of .15 or less for the top part, as there are a lot of small features you don&rsquo;t want your printer glossing over.</p>
<h3 id="assembly">Assembly:</h3>
<p>You&rsquo;ll need some small-gauge wire and pliers to finish the assembly of this thing. I used 28 gauge stainless steel wire, but anything 28 gauge or smaller and waterproof should work. Don&rsquo;t use fishing line because it flexes too much to work. Actual metal wire is needed.</p>
<p>Loop and tie the wire through one of the four mounting holes near the four corners of the top piece. Then weave the rest of the wire through the 20 holes (10 on each side) starting with the one immediately below the mounting hole you started with. Try to keep the wire as tight as possible with each weave. Finish by tying the other end of your wire to the remaining mounting hole on the side you started on.</p>
<p>Your wires are probably not tight enough at this point. Make sure the two ends are tied securely, and then grab your pliers. There is a small, vertical, raised wall with a notch in it between each hole on the outer edge of the top piece. Using the pliers, lift the wire into the notch on as many of the outer wire loops as possible in order to tighten it.</p>
<h3 id="operation">Operation:</h3>
<p>Peel your hard-boiled egg and place it on the base sideways. Push the top piece through the base and the wires. If you want your egg diced, lift it off the base, remove the top pieces of the slicer, put the egg back down rotated 90 degrees and proceed to dice your egg.</p>
<p>Soak in warm soapy water to wash it before storing.</p>]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2014-08-24:/3d-egg-slicer/</guid>

                
                    <link>https://hockenworks.com/3d-egg-slicer/</link>
                

                
                    <pubDate>Sun, 24 Aug 2014 00:00:00 UTC</pubDate>
                

                
                    <title>3D Printed Egg Slicer</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>This switch closes a circuit when a strong magnetic field is nearby. The magnet used in the video is a rare earth magnet which is stronger than your typical refrigerator magnet.</p>
<p>Thingiverse Download: <a href="https://www.thingiverse.com/thing:190218">https://www.thingiverse.com/thing:190218</a></p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/b4piw_LMiRg?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<h2 id="instructions">Instructions</h2>
<p>You will need two 4mm-wide wall hooks (the kind used to mount pictures). Make sure they conduct and are attracted to magnets. You will also need a hot glue gun.
Print two of the attached STL files (one of the mountable variety if you plan to mount it). Flatten the wall hooks with a hammer to get them completely flat, and lay the first one on one of your printed pieces leaving about a half an inch to spare from one end, and hanging out the other. Place a dab of hot glue on the end where it is hanging off. Do the same with the other half, and then place the halves together so the metal pieces are not quite touching in the middle. Seal the metal in place with hot glue.</p>
<p>The hot glue lets the metal move slightly, so that one metal piece bends to touch the other when a magnet is near either side of the switch, completing the circuit between the two metal ends still sticking out.</p>]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2013-11-25:/3d-reed-switch/</guid>

                
                    <link>https://hockenworks.com/3d-reed-switch/</link>
                

                
                    <pubDate>Mon, 25 Nov 2013 00:00:00 UTC</pubDate>
                

                
                    <title>3D Printed Reed Switch</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<blockquote>
<p>Editor&rsquo;s note from 2025:</p>
<p>This was my most-downloaded original 3D print, and my first design to be featured on the homepage.
I&rsquo;ve redesigned and re-released these coasters! <a href="/8-bit-coasters-10-year">Check out the 10 year anniversary edition.</a></p>
</blockquote>
<p>If you like retro video games and also drinking things, you&rsquo;re in luck!
This full set of 8 unique video game coasters comes with themed coaster holders for sets of either 4 or 8! Print them for your living room! Print them for your friends!
I hope these characters remind you of some of your favorite series.</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/2013-8-bit-set-1.png"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/2013-8-bit-set-2.jpg"    >

</div>
</div>

<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/2013-8-bit-set-3.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://hockenworks.com/images/2013-8-bit-set-4.jpg"    >

</div>
</div>

<p>Also find an awesome customizable version by ahtly here:
<a href="http://www.thingiverse.com/thing:139754">http://www.thingiverse.com/thing:139754</a></p>
]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2013-07-09:/8-bit-coasters/</guid>

                
                    <link>https://hockenworks.com/8-bit-coasters/</link>
                

                
                    <pubDate>Tue, 09 Jul 2013 00:00:00 UTC</pubDate>
                

                
                    <title>8-Bit Videogame Coasters</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I 3D Modeled and printed my apartment building&rsquo;s key with the Makergear M2. I won&rsquo;t be posting the model because it IS in fact a key to my apartment. Thanks for watching!</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/_H2W8qXUJtg?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>]]></description>
                

                <guid isPermaLink="false">tag:hockenworks.com,2013-05-13:/3d-key/</guid>

                
                    <link>https://hockenworks.com/3d-key/</link>
                

                
                    <pubDate>Mon, 13 May 2013 00:00:00 UTC</pubDate>
                

                
                    <title>3D Printed Key</title>
                
            </item>
        
    </channel>
</rss>
