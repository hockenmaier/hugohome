













    
        
    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    







    

    






<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"  xml:lang="en-us"  xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        
            

            
                
            

            
                <link href="http://localhost:1313/categories/builds/" rel="self" type="text/html"/>
            
        
            

            

            
                <link href="http://localhost:1313/categories/builds/rss.xml" rel="alternate" type="application/rss+xml"/>
            
        

        

        

        <description>Recent content</description>

        
            <language>en-us</language>
        

        
            <lastBuildDate>2025-12-10 00:00:00 +0000 UTC</lastBuildDate>
        

        <link>http://localhost:1313/categories/builds/</link>

        

        <title>Builds · Categories · hockenworks</title>

        

        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>My <a href="/raspberry-pi-panel">home automation dashboard</a> broke down in two ways this year. Hardware, then software. My wife and I really liked this dashboard. It saved us from pulling out our phones and getting sucked into emails or social media while we were supposed to be living our lives.</p>
<p>Both breakdowns ended up in rebuilds. The hardware obviously solved by 3D modeling and printing and the software part became another problem I would vibe code - no - vibe engineer - my way out of.</p>
<p>After rebuilding, it is totally different. But cooler perhaps? And everything it uses should last many decades this time, instead of just one decade.</p>
<p>Let me break it down for you:</p>
<hr>
<h1 id="the-build">The Build</h1>
<h2 id="hardware">Hardware</h2>
<p><strong>First breakdown:</strong> the screen finally died with one of the LED rows failing. It was a trooper. This meant updating to a <a href="https://www.amazon.com/dp/B07P8P3X6M">new version of the screen</a></p>
<p>And the slight physical difference of the board components meant I had to redesign how I mounted it to the wall, from a complete enclosure that attached via mounting tape to a new slim set of custom brackets I made taking advantage of the standard screw mounts on the screen’s PCB:</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/old-enclosure.webp"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/new-mount.webp"    >

</div>
</div>

<p>Old enclosure left, new mounts right (almost invisible in white like the wall). It&rsquo;s much more secure, much less plastic and a good general purpose mount for raw PCB 7-inch displays. Printed in <a href="https://us.store.bambulab.com/products/abs-filament?srsltid=AfmBOopWZrOOFNoQS26lx71-xycEFqOJ3GG7-FllK-4zYhuttsgHJYb5&id=40475105493128">glossy white ABS</a> to last forever and match the walls.</p>
<p>I posted them on Thingiverse here: <a href="https://www.thingiverse.com/thing:7226385">https://www.thingiverse.com/thing:7226385</a></p>
<h2 id="software">Software</h2>
<p><strong>Second breakdown:</strong> And the timing here was perfectly ironic - about a month after I got this new screen and made the slim mount, the software I was using to display the dashboard just gave up. That software was called <a href="http://actiontiles.com/">ActionTiles</a> and yes, that domain is gone because everything about the product disappeared about 20 days before I am posting this. <a href="https://www.reddit.com/r/SmartThings/comments/1p2ya18/action_tiles/">The subreddit</a> didn’t know what was happening but as best I can tell, it sounds like the solo developer unfortunately passed away several years ago.</p>
<p>Unfortunately ActionTiles was not open source for me to host it myself, nor does it seem worth the effort to integrate with the SmartThings API myself (I am considering moving to an open source home hub after lackluster support for SmartThings anyway), so my next course of action was to vibe code myself another dashboard. This one is less focused on home automation but equally useful to us.</p>
<p>Over the course of some prompting and <a href="https://openai.com/codex/">Codex</a> PRs, the final result shows:</p>
<ul>
<li>The weather now and for the next week</li>
<li>Upcoming birthdays on my wife&rsquo;s and my shared birthday Google sheet</li>
<li>How many months old baby Alice is</li>
<li>Upcoming SpaceX launches visible from my house, with pulsing backgrounds an hour before each launch</li>
<li>The time and date in a nice format</li>
<li>Other astronomical events like meteor showers and eclipses</li>
<li>Plus holidays and solstices</li>
</ul>
<p>Here is the end result:</p>
<p><style>
  .home-list-wrapper {
    width: 800px;
    height: 480px;
    position: relative;
    left: 50%;
    transform: translateX(-50%);
    margin: 1em 0;
  }

  .home-list-wrapper iframe {
    position: absolute;
    top: 0;
    left: 0;
    width: 800px;
    height: 480px;
    border: 0;
  }
</style>

<div class="home-list-wrapper">
  <iframe
    class="lazy-iframe"
    data-src="/html/home-list.html"
    src="about:blank"
    loading="lazy"
  ></iframe>
</div>

<div class="home-list-caption" style="text-align: center; margin-bottom: 1rem;">
  
</div>

<div style="text-align:center;">
  <a href="/html/home-list.html" target="_blank" rel="noopener noreferrer"
     style="display:inline-block;padding:.5rem 1rem;border:1px solid #ccc;border-radius:.5rem;text-decoration:none">
    Open In Standalone Tab
  </a>
</div>

Apologies to readers on phone.. this dashboard is hardcoded for fixed size a 16/9 layout.</p>
<p>I was aiming for clean, simple, readable, and things Kaitlin and I were always looking at our phones to find out. It doesn&rsquo;t do the same things as the previous dashboard but it reduces the number of times my phone has to come out even more than the previous one. We&rsquo;ve been really enjoying it!</p>
<p>I learned some interesting things throughout this process:</p>
<ul>
<li>There are surprisingly good APIs out there for weather and forecasts despite the absolutely <strong>abysmal</strong> mobile weather app market</li>
<li>Meteor showers don&rsquo;t need an API because they happen the same time every year</li>
<li>Eclipses basically don&rsquo;t either cause you can just hard code out all the eclipse data with a few kilobytes of data for decades into the future</li>
<li>The SpaceX upcoming launches list, despite being fully open and probably the simplest of all the data sets here to work with, was by far the most challenging for my AI assistant to read from. This is where the hosted AI coders fall down a lot: their environments simply are different than the ones we are using and they have a hard time accessing stuff that should be open. When they finally figure out how to do that, they have such short memories that they forget things like “only show launches from Vandenberg&quot;.</li>
</ul>
<p>As with almost everything on this site, it&rsquo;s totally open source and this one&rsquo;s contained in a single ~1000-line html file. If you want, you can throw this into your favorite AI model and ask it to change it to events you care about and weather in your location.</p>
<p> 
 </p>
<h1 id="vibe-coding-or-vibe-engineering">Vibe Coding? Or Vibe Engineering?</h1>
<p>Here is where I launch into another breakdown of AI software development. I feel the need to write about it every time I wrap another project, because it&rsquo;s changing so quickly.</p>
<p>I used <a href="https://openai.com/codex/">Codex</a>, mostly, to build this dashboard. I like Codex <a href="/on-ai-software-development-2/#autonomous-coding-agents">because it makes more sense to me to have AI models make discrete code changes and pull-request them into my project rather than trying to work in the same IDE as the AI</a>.</p>
<p>Every time I &ldquo;vibe code&rdquo; something new, I find new ways to be amazed and disappointed by these thinking machines. The main takeaway I had this time is, despite the amazing speed of development, I just can&rsquo;t see anyone other than an engineer getting a workable software product out of these models in 2025.</p>
<p>This is why the term “vibe engineering” is growing on me. Now that the basic code writes itself, what I see engineers doing all day are things <em>around</em> the code like making sure environments work and making sure features don&rsquo;t conflict. And, most key of all: determining the actual specific logic of the product. Check out the detail in my original prompt for this dashboard:</p>
<blockquote>
<p>Please create a new dashboard at <a href="https://hockenworks.com/html/home-calendar.html">https://hockenworks.com/html/home-calendar.html</a>.</p>
<p>It will function as a standalone servable page like <a href="https://hockenworks.com/html/agent-mode-solar-system-self-contained.html">https://hockenworks.com/html/agent-mode-solar-system-self-contained.html</a>.</p>
<p>This is going to be permanently displayed on a small 16/9 touchscreen in our kitchen running on chromium on Raspberry Pi.</p>
<p>On the right part of the screen (a full square aligned with the left side of the 16 by 9 screen) will be a calendar. That calendar should display the current week and next 7 weeks on a 7 by seven grid, using your stylistic preferences to denote the dates and days of the week. Draw a bold line horizontally and vertically through month breaks with a clear delineation between the two.</p>
<p>This calendar should use public data which does not require any sign-in to fetch:</p>
<ul>
<li>All US Holidays</li>
<li>First day of each season, dates when the time changes</li>
<li>Special astronomical events like eclipses or visible meteor showers etc (list time of day for these ones, for example &ldquo;Solar Eclipse at 2:11 PM&rdquo; listed on its date</li>
<li>SpaceX launches from Vandenberg ONLY</li>
<li>Anything else you see fit to list here (let me know if you&rsquo;ve added anything when you finish)</li>
</ul>
<p>Come up with theme colors and icons for each foreseeable event (such as a clock for time change days, spaceship for launches, egg for Easter, etc, and fall back to just text for unknown events.</p>
<p>On the left half of the screen, full remaining width (to the left of the square calendar on the right) should be in this order:</p>
<p>Time in the format: 12:42 PM
Date in the format: Nov 23rd</p>
<p>Both of these should have fun, randomized animated transitions. Use whatever html and css tricks you want to do this, just make sure it&rsquo;s all self-contained code and libraries you can include in hockenworks so this thing never breaks.</p>
<p>Then have a few lines which list any upcoming holidays or events in the next 4 weeks verbally in the format: Solar Eclipse coming up next Tuesday, February 17th at 2:11 PM or Solar Eclipse coming up February 17th at 2:11 PM</p>
<p>You should use &ldquo;this&rdquo; and &ldquo;next&rdquo; for upcoming days of the week, or leave part that out if it&rsquo;s further than 2 weeks out.</p>
<p>Do this on a black background with primarily white and light pastel colorings.
New data such as holidays should be fetch hourly, if you need to decide on a frequency.
Remember, this will be permanently displayed and always be up to date so account for any edge cases.</p>
</blockquote>
<p>The combination of <a href="/vision-is-the-last-hurdle-before-agi">AIs really not being able to see yet</a> and also being unable to test on the physical Raspberry Pi device which had some unique properties, Codex simply failed at the visual calendar. So I pivoted to a text-only dashboard.</p>
<p>But here is where I think the term vibe coding should become &ldquo;vibe engineering.&rdquo; Look at that prompt, which was still not nearly detailed enough to produce what I wanted. There were at least ten more prompts, several as long as that, after pivoting to a text-only dashboard to get it working well. This wasn&rsquo;t to correct AI mistakes, but to get to the level of precision in <em>what I actually wanted out of the dashboard</em>. You have to be <strong>SO</strong> precise in your prompting to get what you want. Precise like an engineer, not an idea guy.</p>
<p>It&rsquo;s much faster to have AI code for you than to write it yourself. But if you are spending this much time designing detailed logic and building up the knowledge of what is feasible and what isn&rsquo;t, in my opinion, you&rsquo;re an engineer.</p>
<p>The AI also lacks any touchpoints with the real world - in this case, my old chromium running on Raspberry Pi was not testable for the AI, and so I had to run back and forth from my office to the dashboard to see if things scaled correctly. This is not just a problem for niche projects like this. I have seen AI code not work on certain devices and browsers in “normal” web projects at work too, and fixing these things is what <em>engineers</em> do.</p>
<p>And then, potentially the most egregious consistent failure mode (and this really needs to be fixed): AI still loves to mock up fake data. This happened multiple times in this project where AI just started ignoring API calls and making up dates and times for things to happen. This tendency feels like the labs are trying to game benchmarks by making their software agents make plausible-looking successes that a human evaluator might miss and accidentally rate highly - but made up data is far, far worse for real world use, especially for non-engineers who are less likely to catch it.</p>
<p>Even with all of these problems preventing these models from “democratizing engineering” - they are still amazing tools. I would not have known where to start on many of these features without the AI simply knowing things I didn’t, like the open weather API and the method of accessing Google sheets as a CSV export. Even as an engineer, there&rsquo;s no chance I would have whipped up a custom dashboard to do all this and solve my dashboardlessness before the era of AI.</p>
<p>These models are liars and cheats that are also blind, but somehow they’re still greatly expanding what it’s possible to build, and how fast we can build it. Just recognize that once you are building and running real software that actually fits your intentions, you are, effectively, an engineer.</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-12-10:/raspberry-pi-panel-2/</guid>

                
                    <link>http://localhost:1313/raspberry-pi-panel-2/</link>
                

                
                    <pubDate>Wed, 10 Dec 2025 00:00:00 UTC</pubDate>
                

                
                    <title>Dashboard Breakdowns</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>Today&rsquo;s post is about another video game start that either I or AI will finish one day. I&rsquo;m building up a bit of a repertoire of those!</p>
<p>This one I started when AI image generation started to become decent. It&rsquo;s a game that I&rsquo;ve always wanted to exist, but wasn&rsquo;t feasible for me to create with my current skillsets. I could never pull it off without a lot of commissioning due to the art requirements.</p>
<p>The idea is not as original as some of my games but it&rsquo;s very fun when played in a large group. Essentially, I combine the gameplay of the NES classic balloon fight with eight-player multiplayer. If you&rsquo;ve played my game <a href="/land-war/">Land War</a>, you might know that I&rsquo;ve been a bit obsessed with eight player multiplayer, or really any game that allows for more than four players to join in.</p>
<h1 id="eight-player-video-games">Eight-player Video Games</h1>
<p>Kaitlin and I love to have people over to socialize, and I love to game. I think they are honestly one of the best ways to have productive, good-natured socialization where people can do things that humans probably evolved to do a lot: band together, form alliances, rib on each other a bit, and sometimes even feel like they&rsquo;ve seen something beautiful or had a new experience together. I know that’s a little philosophical and sappy, but I think video games have a huge place in in-person socialization, just like board games do.</p>
<p>I love board games. I play them all the time. But so often when playing board games you run into mechanics that are only there because the game doesn&rsquo;t have a computer involved, can&rsquo;t count for you, can&rsquo;t add things up, can&rsquo;t simulate multiple players&rsquo; turns at the same time, and though it&rsquo;s nice to not have any screens in front of anybody, I think the limitations of board games hold people back from playing games as a group in general more often than not.</p>
<p>My favorite example of this is Power Grid.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="The cover art for Power Grid"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/power-grid.png"   style="height: auto; max-width: 200px; width: 100%"   >


    
</div>

<p>Power Grid is a clever game that would be really quite fun if it didn&rsquo;t require players to spend half their time literally doing simple math in their heads or on paper while other people wait. A modern video game with similar dynamics would never do that; it would just let you play the fun part.</p>
<p>Many such cases in board gaming.</p>
<p>But video games have their own limitations and requirements. There are some barriers we aren&rsquo;t getting around anytime before true augmented reality is on everybody&rsquo;s faces, like getting a controller into everybody&rsquo;s hands, and getting them over the fact that they are looking at a screen to socialize. But aside from those, split screen video games have one fundamental limitation most of the time: they only go up to four players. And most social gatherings involve more than four people.</p>
<p>Today, mass-socialization through video games already exists. It&rsquo;s mostly amongst the very young, and mostly over the internet, via metaverses like Roblox. But I&rsquo;m quite sure that in the future, it will be much more common to play video games (or whatever we call computer-aided social experiences) as a primary form of socialization in-person too.</p>
<p>This belief is the core reason I wanted to make Land War an eight-player strategy game, and this setting of group gatherings was also why the controls for Land War are dead simple.</p>
<h1 id="generated-art-first-edition">Generated Art, First Edition</h1>
<p>The reason I waited to make a game like this is because I&rsquo;m no artist. I like to think I have taste, but it certainly is not in my wheelhouse to make beautiful artwork, even for a simple, sprite-based game I want to make here.</p>
<p>The image models I was mostly working with on this project were Midjourney 6 and Dalle3, both diffusion models. This was essentially the best available at the time. If you&rsquo;ve worked with diffusion models before, you know you can get some pretty beautiful and creative stuff, but there are always a few artifacts that will be noticed if someone stares at it long enough, which is always going to be the case for a video game sprite. And, they generally don&rsquo;t do transparency. So I found myself having to do a lot of cleaning and filtering and processing of these images, and I landed on an oil painting filter that worked pretty well to disguise some of the noise and my own edits.</p>
<p>I used these models and techniques for the few backgrounds, tiles, and items in the current game. It was a lot of work just to get a decent looking single sprite, even disregarding animation. Animation is where I ran into the real challenges.</p>
<p>Without complex techniques like <a href="https://arxiv.org/abs/2106.09685">LoRAs</a>, diffusion models just can&rsquo;t iterate on the same image over and over again. Character consistency is not really a thing, and that&rsquo;s what&rsquo;s needed to make a multi-frame sprite that animates. This is the real impasse I ran into, and the core reason I stopped working on this game. I wanted to spend 80% of my time on gameplay, logic, and testing this game, and 20% or less prompting for art and music, but it started to be about 50/50. And the results of those art generations were not amazing.</p>
<h1 id="the-state-of-generated-art-in-2025">The State of Generated Art in 2025</h1>
<p>So fast forward to now. We all knew this has been coming for a long time, but finally we have transformer models that do image generation. And part of what that means is that conversation history, including past image generations and reference images, can be included in the neural context of the next generation. We&rsquo;ve probably all seen this by now with image <a href="https://www.reuters.com/technology/artificial-intelligence/ghibli-effect-chatgpt-usage-hits-record-after-rollout-viral-feature-2025-04-01/">&ldquo;Ghiblification&rdquo;</a>.</p>
<p>OpenAI was yet again the first to release this type of capability, at least in a serious way. Technically, there was a Gemini model that did native image gen maybe a month before OpenAI released theirs, but it was pretty garbage in comparison. And, unexpectedly, the new OpenAI image gen can also generate images on transparent PNG backgrounds, which is absolutely crucial for any image that&rsquo;s going to be set against some dynamic background. Which is the case for most game art.</p>
<p>I have since taken a few attempts at making some multi-frame sprite animations, and it&rsquo;s almost there - almost good enough to one-shot simple game animations. But, unlike what you might be led to believe by excited Xitter posts with whole sprite sheets generated, it&rsquo;s still a lot of work to get what you want for a game. The models just still aren&rsquo;t consistent enough to produce images that don&rsquo;t require a heavy amount of editing to get the same amount of background space, full actual sprite sheet specs, keep characters absolutely consistent, etc. But I think they will get there soon.</p>
<h1 id="generated-audio">Generated Audio</h1>
<p>Generated music was a surprising high point of this project. Great quality sound effect and music generators were on my checklist of things that I knew would come soon, but I got super lucky when <a href="https://www.udio.com/creators/hockenmaier">Udio</a> came out about a month or two into prototyping this thing. Check out some of these tracks in the link above and the video below.</p>
<p>But as good as AI generated music is getting, sound effects are still not there. You can occasionally get something that sounds like what you intended but in general there&rsquo;s a lot of noise, a lot of strange lead-ins, and in general just strangeness. AI sound effects will be a huge unlock for indie development when they&rsquo;re good enough. I didn&rsquo;t spend much time or any money on sound effects so far, so you won&rsquo;t hear too many in the prototype.</p>
<h1 id="current-state-of-the-game">Current State of the Game</h1>
<p>So here&rsquo;s where I&rsquo;m at, check out this video which is just me playing against seven bots:</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/G3v7M9V9NGk?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p>The game is fun with multiple players, but it&rsquo;s still quite basic, and I&rsquo;m still waiting on image generation that would make the graphics good rather than the stand-ins that are mostly still from the diffusion era of image generation.</p>
<p>I did not tune much, nor did I add a lot of the platformer-niceties that are really needed to make a 2D platformer feel right, and it&rsquo;s a bit clunky as a result. But I do think this is a promising enough mechanic to make a great battle game out of one day.</p>
<p>At some point I will pick this thing back up, or I will have some AI agent pick it back up for me, because the core game itself is something I really want to exist, even if it&rsquo;s just another Land War that a few hundred people download and I play at my own get-togethers, or play with my kids.</p>
<p>You can download a Windows build here, which is still very much a prototype, but the core gameplay is there and it works with 8 connected controllers:</p>
<a href="https://www.dropbox.com/scl/fo/4piy97k725ee1xp3cn4pe/AEUfIYTEgcOtlUmsc0qeT1s?rlkey=ygd4jhs57c35xq3ska7vs6xjy&amp;dl=1" download class="d-flex align-items-center download-link">
  <i class="bi bi-file-earmark me-1"></i>
  
7/24/24 Build Download

</a>

<p>Thanks for reading! Leave me a comment if you have ideas for the game or AI models I should be on the lookout for!</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-09-29:/balloon-fight/</guid>

                
                    <link>http://localhost:1313/balloon-fight/</link>
                

                
                    <pubDate>Mon, 29 Sep 2025 00:00:00 UTC</pubDate>
                

                
                    <title>8 Player Balloon Fighter</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<blockquote>
<p>Warning: This article has a lot of embedded code, so <a href="/this-website/#ball-machine---the-game">the ball machine</a> is slow unless you have a REALLY fast computer. Play at your own risk.</p>
</blockquote>
<p>Seriously, though.</p>
<p>GPT-5, as a simple text completion model, is not a revelation.</p>
<p>This isn&rsquo;t so surprising. It was becoming clearer with every new raw LLM release that the fundamental improvements from scaling solely the performance of the core text predictor were starting to show diminishing returns. But I&rsquo;m going to make an argument today that, although the LLM itself is not nearly as much of a leap from GPT-4 as GPT-4 was from GPT-3, we have still seen at least a whole-version-number of real improvement between the release of GPT-4 and 5 as we did between 3 and 4. The reasons for that are mostly what exists around that LLM core.</p>
<p>And I&rsquo;m going to make this argument by showing you things the original GPT-4 could never have done.</p>
<h1 id="exhibit-a-a-new-solar-system">Exhibit A: A New Solar System</h1>
<p>GPT-5 came at a great time for me, because when OpenAI set the announcement to 8/7/25, I was in the middle of stress testing Agent Mode with the prior models. So, let me start by just illustrating the progress we had made between the first GPT-4 release in early 2023 and the capabilities of GPT-4 level models the week before the release of GPT-5.</p>
<p>Two years and four months have gone by since I ran my original Interactive Solar System experiment with the original version of GPT-4. You can play with it at <a href="/gpt-4-solar-system">hockenworks.com/gpt-4-solar-system</a>.</p>
<p>Now have a look at the same test performed a week before the release of GPT-5, which uses ChatGPT Agent Mode:</p>
<p>
<style>
  .agent-mode-solar-wrapper {
    position: relative;
    left: 50%;
    transform: translateX(-50%);
    width: 150%;
    max-width: 1500px;
    margin: 1em 0;
    padding-top: 70%;
  }

  @media (max-width: 768px) {
    .agent-mode-solar-wrapper {
      width: 100%;
      left: 0;
      transform: none;
      padding-top: 180%;
    }
  }
</style>

<div class="agent-mode-solar-wrapper">
  <iframe
    class="lazy-iframe"
    data-src="/html/agent-mode-solar-system-self-contained.html"
    src="about:blank"
    loading="lazy"
    style="position:absolute; top:0; left:0; width:100%; height:100%; border:1px solid #ccc;"
  ></iframe>
</div>

<div style="text-align: center; margin-bottom: 1rem;">
  
    <span style="display: block; font-style: italic; margin-top: 0.5rem;">Works on desktop or mobile</span>
  
</div>

<div style="text-align:center;">
  <a href="/html/agent-mode-solar-system-self-contained.html" target="_blank" rel="noopener noreferrer"
     style="display:inline-block;padding:.5rem 1rem;border:1px solid #ccc;border-radius:.5rem;text-decoration:none">
    Open In Standalone Tab
  </a>
</div>
</p>
<p>Here are controls, again:</p>
<p><kbd>Mouse Click + Drag</kbd> to move the solar system around</p>
<p><kbd>Mouse Wheel Up</kbd> to zoom in from the cursor location</p>
<p><kbd>Mouse Wheel Down</kbd> to zoom out</p>
<p>And I again used this initial prompt:</p>
<blockquote>
<p>I want you to make me a dynamic website. It should look good on mobile or on desktop, and I would like you to pick a nice dark background color and an interesting font to use across the page.</p>
<p>The page is intended to show the scale of the solar system in an interactive way, primarily designed for children to zoom in and out of different parts of the solar system and see planets and the Sun in relative scale. Mouse controls should also include panning around the model solar system, and should include text around planets with some statistics about their size, gravity, atmospheres, and any other fun facts you think would be educational and fun for 10-12 year olds.
 </p>
</blockquote>
<p>Quite an improvement, right?</p>
<p>Like my original experiment, I didn’t one-shot this result. This is the final result after 7 prompts, but unlike in the original, those follow-up prompts were not primarily fixes - they were new features that I thought would be good additions after playing with each previous version - all of which worked right away.</p>
<p>The most striking part of this experiment for me is that, despite the plateau that has largely been observed in base LLMs, this result is clearly far above and beyond what GPT-4 was able to do when it first released, and the reasons for that have to do with what the labs have been building <em>around</em> the base models.</p>
<p>In the case of Agent mode, as far as we know, we have a GPT-4 class model at the root. o3, which is what Agent Mode uses, is a GPT-4 class model with chain-of-thought and lots of self-play training.</p>
<p>It also has the ability to use tools, like the web search tool it used to find the planet facts.</p>
<p>But then the thing that most sets it apart from its base model is the deep research and computer use elements of Agent mode. As it was building this model, I saw Agent mode do things such as perusing the internet with its text browser to find scale information and browse for textures it could use as planet skins.</p>
<p>It wrote and ran test code using its Code Interpreter tool.</p>
<p>It used its chain-of-thought &ldquo;thinking&rdquo; to respond to errors, rethink controls and scale decisions, and decide to go back and search the web or use other tools some more.</p>
<p>Then, the most impressive new ability that allowed it to make this: It ran this code on a local browser and <em>visually tested it</em>, clicking on the planets to make sure the information panels were coming up, zooming and panning around, and using its own toolbars.</p>
<p>This last one to me, when paired with all of the other things that GPT-4 class models are not instrumented to do, is the start of a true general capability for AI software testing, almost as a side note to all of the other things it will unlock in the coming few years. Not just the little unit and automated tests that LLMs have been writing into our codebases for a long time - but actual visual look and feel testing. This is a huge market and will be a huge shock to the software industry when it’s fully realized.</p>
<p>These are all net-new abilities that GPT-4 class models have gained since GPT-4 came out in March of 2023. It&rsquo;s hard to see how much progress these capabilities add up to without just running the direct experiment like this solar system generation.</p>
<h1 id="gpt-5-without-agent-mode">GPT-5 Without Agent Mode</h1>
<p>I see GPT-5 as a formalization of all of these capabilities that lock in the step change in capability we&rsquo;ve seen over the last 2 years. There is a new model underneath there somewhere (some are saying it is o4) and that underlying model has certainly been reinforcement-trained to choose its tools wisely. It is the first model I have seen that can do all of these simultaneously, without user choice:</p>
<ul>
<li>Choose when to think and when to just answer</li>
<li>Run iterative web search calls</li>
<li>Write and run code to do highly logical-symbolic tasks like data analysis</li>
<li>Create, edit, and analyze images</li>
<li>Create and read nearly any kind of document a user might be working with</li>
</ul>
<p>And there are still a couple of things locked behind user choice, which is probably because these both result in much longer running and expensive tasks than simple thinking:</p>
<ul>
<li>Deep map-reduce style web research</li>
<li>Computer use (mouse and keyboard style, with Agent Mode)</li>
</ul>
<p>Using only the first set of &ldquo;default&rdquo; behaviors, GPT-5 can do things that the original GPT-4 could never have dreamed of. I have had the following prompt sitting around in my &ldquo;intelligence tests&rdquo; document for more than a year now under <em>&ldquo;Cool picross app idea, def solvable by competent AI (which doesn&rsquo;t exist yet at the end of 2024)&rdquo;</em>, waiting for a single model that can one-shot it. GPT-5 is the first one that does:</p>
<h2 id="exhibit-b-picross">Exhibit B: Picross</h2>
<blockquote>
<p>Take an image, increase contrast, and turn it into a 15x15 image. Create a black and white picross puzzle out of the image, including a UI that lets a player solve the puzzle.</p>
</blockquote>
<p>It&rsquo;s a simple prompt that implies a lot of underlying complexity. Here is the first one-shot result from GPT-5 I got (normal mode, I didn&rsquo;t select &ldquo;Thinking&rdquo; in advance):</p>
<p><style>
  .picross-wrapper { display:flex; justify-content:center; }
  .picross-wrapper .frame {
    position: relative;
    width: 100%;
    max-width: 900px;
    aspect-ratio: 3.35/4;
    border: 2px solid #fff; border-radius: 4px; overflow: hidden;
  }
  .picross-wrapper .frame > iframe {
    position:absolute; inset:0; width:100%; height:100%;
    transform-origin: top left;
  }
   
  @media (max-width: 480px){
    .picross-wrapper .frame { --s: .65; }
    .picross-wrapper .frame > iframe {
      transform: scale(var(--s,1));
      width: calc(100% / var(--s,1));
      height: calc(100% / var(--s,1));
    }
  }
</style>

<div class="picross-wrapper">
  <div class="frame">
    <iframe
      class="lazy-iframe"
      data-src="/html/picross-generator.html"
      src="about:blank"
      loading="lazy"
    ></iframe>
  </div>
</div>

<div style="text-align:center;">
  <a href="/html/picross-generator.html" target="_blank" rel="noopener noreferrer"
     style="display:inline-block;padding:.5rem 1rem;border:1px solid #ccc;border-radius:.5rem;text-decoration:none">
    Open In Standalone Tab
  </a>
</div>
</p>
<p>It didn&rsquo;t make all the choices I would have, but it worked in one shot, the first time I tried it. All the way from uploading an image and transforming that to a puzzle, to a whole UI that lets you solve it. I purposely left this here after its one-shot result just to demonstrate the progress. You could take this idea much further.</p>
<h2 id="exhibit-c-the-baby-mesmerizer">Exhibit C: The Baby Mesmerizer</h2>
<p>Now for the coolest thing I&rsquo;ve made with GPT-5 so far. I call this one the baby mesmerizer because baby Alice is absolutely stunned every time she sees it. I got this idea from another entertaining little physics simulation I saw somewhere.</p>
<p>I had GPT-5 make this one, then I tested it using the built-in runner in ChatGPT, changed it, and iterated on it 16 times. But I didn&rsquo;t write any of it myself - nor did I even open the code other than to tweak some variables to make it &ldquo;feel right&rdquo; here and there.</p>
<p>
<style>
  .agent-mode-solar-wrapper {
    position: relative;
    left: 50%;
    transform: translateX(-50%);
    width: 150%;
    max-width: 1500px;
    margin: 1em 0;
    padding-top: 85%;
  }

  @media (max-width: 768px) {
    .agent-mode-solar-wrapper {
      width: 100%;
      left: 0;
      transform: none;
      padding-top: 180%;
    }
  }
</style>

<div class="agent-mode-solar-wrapper">
  <iframe
    class="lazy-iframe"
    data-src="/html/exponential_bounce.html"
    src="about:blank"
    loading="lazy"
    style="position:absolute; top:0; left:0; width:100%; height:100%; border:1px solid #ccc;"
  ></iframe>
</div>

<div style="text-align: center; margin-bottom: 1rem;">
  
</div>

<div style="text-align:center;">
  <a href="/html/exponential_bounce.html" target="_blank" rel="noopener noreferrer"
     style="display:inline-block;padding:.5rem 1rem;border:1px solid #ccc;border-radius:.5rem;text-decoration:none">
    Open In Standalone Tab
  </a>
</div>
</p>
<p>How cool is that?</p>
<p>After you’re done messing around with this, take a detailed look at what has been built here. It is a tech demo, yes, but it has:</p>
<ul>
<li>A nice-looking UI and color scheme</li>
<li>A side menu that dynamically operates as a fly-out menu based on screen size</li>
<li>A bunch of tunable variables, including niceties like minimums and maximums affecting each other</li>
<li>Dynamic generated sound effects</li>
</ul>
<p>I also thought it was interesting that GPT-5, when I said that it needed to run as a single HTML file with no external dependencies, chose to write its own physics for this. There is no prebuilt physics engine at all here.</p>
<p>This result is about 1400 lines of code. This isn’t a huge project, but it is far more than we could get a GPT to reliably produce just a year ago. The typical loop before was that you’d get past 200 lines of code or so, and then every new feature or bugfix requested would break two other things around the codebase, effectively enforcing a tiny complexity cap.</p>
<p>Let&rsquo;s be real: It&rsquo;s absolutely amazing that I could make something as complicated as this, exactly how I imagined it, just by describing it in English and a collective hour or two of testing. And though I like to code and have been bummed for a while that most straightforward coding like this is going the way of the dodo, this experience of not coding and instead just setting requirements and playing with the result was also a lot of fun. More fun than tearing through <a href="/on-ai-software-development-2/#agentic-ides">codespam in a tool like Cursor</a>. And frankly, I would never spend time making something like this if I had to code it all from scratch.</p>
<h1 id="a-plateau">A Plateau?</h1>
<p>I&rsquo;ve already read more than enough takes that GPT-5 signals the end of the current wave of AI, as a sort of intelligence plateau somewhere just below humans.</p>
<p>We should observe that we did not foresee the advancements that would get us from GPT-4 to GPT-5. Yet here we are: GPT-4 was <a href="/gpt-4-solar-system/">barely able to write 200 lines of buggy solar system code</a>, and GPT-5 one-shots it. The core model under the hood is likely a bit better, but it was proper tooling and reinforcement training on that tooling that really made the difference. And from what I hear, there are many other avenues of work that researchers say are still in early stages, such as reinforcement training on long-running agentic tasks and building the synthetic datasets that will allow for that.</p>
<p>So, even though GPT-5 doesn&rsquo;t seem like a huge advancement from models like o3 and Sonnet 4, hindsight makes the upward trajectory clear.</p>
<p>No matter how fast we see progress, there is clearly a ton of fun to have along the way!</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-08-24:/gpt5/</guid>

                
                    <link>http://localhost:1313/gpt5/</link>
                

                
                    <pubDate>Sun, 24 Aug 2025 00:00:00 UTC</pubDate>
                

                
                    <title>The Real GPT-5 Was The Friends We Made Along The Way</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>Here&rsquo;s my most patriotic print yet! I have been using our new (hand-me-down) stroller a lot lately, for obvious reasons, and I decided there were a few things I just couldn&rsquo;t go without.</p>
<p>So, I made a one-print solution that requires zero support and attaches to the handle of any stroller with hose clamps, which are shown here covered by separate printed strap covers to protect the leather of the stroller handle. I&rsquo;ve deemed it the Strollerhock:</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/strollerhock-front.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/strollerhock-left.jpg"    >

</div>
</div>

<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/strollerhock-back.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/strollerhock-top.jpg"    >

</div>
</div>

<p>I couldn&rsquo;t resist printing it in my red, white, and blue ABS since its first real test run would be in Coronado, CA for the 4th of July weekend.</p>
<p>The Strollerhock includes:</p>
<ul>
<li>A battery holder for a 40K mAh rechargeable battery (about 8 smartphones&rsquo; worth)</li>
<li>A baby fan mount, powered by the battery</li>
<li>Two phone mount positions, both of which can be used while the phone is charging from the battery</li>
<li>A paper or cash clip</li>
<li>A key hook</li>
<li>A pacifier compartment</li>
<li>A multi-width tapered cupholder</li>
</ul>
<p>I may have gone a little overboard on design on this one - probably 8+ hours of design and print prep, but it did come in handy walking all around the island! I am still adding finishing touches, but for anyone interested, here is the first complete versions of the Strollerhock and the clamp cover straps:
<a href="https://www.dropbox.com/scl/fo/8wqaijh17n7gous0fvmnm/AO1IujdmtVEPSskDDzMKBY4?rlkey=fmjum9d3h5idvczup4pcp1va6&amp;st=5ces8mis&amp;dl=1" download class="d-flex align-items-center download-link">
  <i class="bi bi-file-earmark me-1"></i>
  
7/04/25 Strollerhock Download

</a>
</p>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-07-04:/strollerhock/</guid>

                
                    <link>http://localhost:1313/strollerhock/</link>
                

                
                    <pubDate>Fri, 04 Jul 2025 00:00:00 UTC</pubDate>
                

                
                    <title>The Strollerhock</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>The advent of general coding AI assistants almost immediately changed how I think about hiring and interviews.</p>
<p>In the software engineering world, this mindset shift was psychologically easy for me, because I&rsquo;ve always had a bias against the types of coding questions that AI can now answer near-perfectly. And they also happen to be the kind of questions I personally do badly at - the ones requiring troves of knowledge or rote memory of specific language capabilities, libraries, and syntax. It is not so psychologically easy for everyone, especially those who have developed a core skill set of running or passing &ldquo;leetcode-style&rdquo; interviews. Even before AI, the only types of coding questions I would personally ask were things that simply evaluate whether a candidate is lying or not about whether they can code at all, which was and still is surprisingly common. I have interviewed people that list bullet points like 7 years of Java experience but can&rsquo;t pass a fizz-buzz like question, and this was a question I gave out on paper with a closed door and no significant time pressure.</p>
<p>So, when LLMs that could remember any syntax or attribute of any programming language perfectly were released, not only was I excited - I immediately saw that a huge chunk of the programming questions I and many I know have asked in interviews were essentially irrelevant now, not only because people could cheat on interviews, at least virtually, but because this knowledge simply lost much of its value overnight.</p>
<p>Over a few conversations with friends and colleagues I began to explore the idea of what this meant generally for the interview process. There are just lots of questions that we ask in every field, it turns out, that are mostly solved by LLMs today. These models have memorized most useful information that lets them ace simple interviewing questions across fields, even if the original intent of the question was to test for experience.</p>
<h2 id="the-build">The Build</h2>
<p>In the summer of 2022 my ideas and conversations on this topic had gotten to the point where I really just needed to test my hypothesis: LLMs and continuous audio transcription could let someone with no knowledge answer many interview questions correctly. My initial thought was that an app like this must already exist. But after searching for apps on the app stores that did what I was thinking of, to my surprise, I found none did.</p>
<p>I&rsquo;m still not sure if this was a legal thing at the time, or if it&rsquo;s hard to get apps that continuously transcribe audio published, but as of 2025 apps like this definitely exist. Some of them have gotten famous and one has gotten its creator expelled from an Ivy League for revealing that he used it to ace interviews with some top tech companies. Link for the curious here:</p>
<p><a href="https://cluely.com/">https://cluely.com/</a></p>
<p>But, in mid 2023, these apps were apparently not a thing, so I decided to make a prototype.</p>
<p>My basic requirements were simply something that could continuously transcribe words being spoken in a meeting or over a call, group them up into meaningfully long chunks, and then send those chunks with some overlap to two different AI passes:</p>
<ol>
<li>An AI pass that would try to make meaningful questions out of the transcribed potential gibberish</li>
<li>An AI pass that would answer those questions</li>
</ol>
<p>My tech stack for this was a little weird, but I know Unity well and I don&rsquo;t know other ways of deploying native mobile apps as well, and this definitely needed to be a mobile app if it was going to sit on the phone and continuously transcribe audio. Web has all kinds of restrictions on its APIs and I hadn&rsquo;t made a web app like this anyways.</p>
<p>This was surprisingly easy to achieve, even in 2023. I ran into a few hiccups mainly around continuous audio transcription, but for an app I wasn&rsquo;t going to publish and that I was directly putting onto my own Android device, I got around these difficulties by simply starting up a new audio transcription thread every time one closed.</p>
<div style="display: flex; align-items: center; justify-content: center; gap: 10px; margin-bottom: 1rem;">
    





























    



    



    





    







    



    























<img  alt="the UI"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/make-us-smarter.jpg"   style="height: auto; max-width: 200px"   >


    
        <span style="font-style: italic;">Super barebones UI just showing the continuously auto-transcribed words, questions derived from those words, and answers to those questions.  This particular screen was grabbed long after my API key had expired and is only here to show the basic output of the app, transcription building continuously in the background and detected questions and answers in the foreground.</span>
    
</div>

<p>And the results were surprisingly compelling. Of course I was using some of the very first versions of GPT-4 and AI is still not perfect, but the main result of this was that occasionally questions were picked up that were not actually implied by the meeting audio, and occasionally real questions were missed. The part that I knew was going to work did indeed work incredibly well: when I simulated some fizz-buzz style questions and there were no major audio transcription issues, the second question-answering AI nailed them and was able to put a succinct script to answer the question on screen within a few seconds.</p>
<p>There was clearly more work to be done on UI and also the flow between the AI passes, and more agentic APIs of today could definitely do this all more seamlessly.</p>
<p>But for me, my question was answered: My hunch was right and we should definitely not be asking questions about basic constructs of programming languages or simple scripts in interviews anymore.</p>
<p>I open-sourced the project which is a pretty small Unity build, and it&rsquo;s a Unity version from a couple of years ago now, but anyone is welcome to look through and modify the code any way they want:</p>
<p><a href="https://github.com/hockenmaier/make-us-smarter">https://github.com/hockenmaier/make-us-smarter</a></p>
<h2 id="interviewing-mitigations">Interviewing Mitigations</h2>
<p>This whole experience has led me to an interview approach that I think is infallible (for now). And it doesn&rsquo;t require sending someone home with a project or any of the stuff that great candidates often don&rsquo;t even consider. I heard about a version of this technique on Twitter, so can&rsquo;t take credit here:</p>
<p>First: ask candidates to bring some code they have written, regardless of language or framework. Then simply walk through it with them in the interview. asking them questions about why they made certain decisions and trying to guide the conversation to parts that are technically interesting. It only takes 15 minutes or so, and it usually gets much better conversation going than sample interview questions do. This leans on the fact that you need an interviewer who can mostly understand most programming projects, but it cannot be faked with any LLM assistance. LLM-written code is typically pretty obvious: much better commented and differently organized than most humans would write. But even if the code was very sneakily written AI code the person didn&rsquo;t actually contribute to, then having a human go through and explain the parts they thought were clever defeats the purpose of cheating with AI anyway.</p>
<p>This is just a little tidbit of a technique that works well today, if the goal is to assess coding skills. Of course, it leaves some obvious lingering questions about what we are evaluating and why. I hope no one out there that I know is using these apps to cheat on interviews, but we all need to be wise to the fact that it is trivially easy to do so in 2025, and we should shift focus to testing for the qualities that actually matter in the era of AI - or at the very least techniques that prevent the types of cheating possible today.</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-06-29:/my-experiments-with-ai-cheating/</guid>

                
                    <link>http://localhost:1313/my-experiments-with-ai-cheating/</link>
                

                
                    <pubDate>Sun, 29 Jun 2025 00:00:00 UTC</pubDate>
                

                
                    <title>My Experiments with AI Cheating</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>&ldquo;The Flapper&rdquo; is a project that spawned out of a simple VR movement mechanic test that I had in my head for a while, which turned out to be surprisingly fun! The idea is to flap your arms to fly - wrapped up as a multiplayer battle to really get people moving.</p>
<p>In order to start working on this game, because there was so much standard VR code that I had to write for <a href="/treekeepers-vr">Treekeepers</a>, I decided to make a sort of engine out of the Treekeepers codebase and work off of that rather than start from scratch. That let me tie in some of the nice associated graphics, music and sound effects I had made, and a bunch of other helper functions and tools I use for things like the camera following around the character, how I deal with collisions, a bunch of netcode, etc.</p>
<p>You can see my more detailed post about that engine here: <a href="/treekeepers-engine">Treekeepers Engine</a></p>
<h2 id="core-mechanic--gameplay">Core Mechanic &amp; Gameplay</h2>
<p>Most of the start of this game was just tuning the movement mechanic, which borrowed from some physics realities and some elements I made up to make flapping feel good. But, the essential idea was that each arm generates unique thrust in the direction it moves with an exponential applied to its speed. It&rsquo;s hard to describe any native VR mechanic with words and videos only, but to me and the folks I demoed it to, it felt &ldquo;right&rdquo; for how flying should work if you did it by flapping your arms - and that feeling is based in the physical reality of wing-powered flight. I had a ton of fun just jetting around the obstacle courses I made for myself.</p>
<p>My idea for this other than just the mechanic was to make a sort of gorilla tag-esque multiplayer game where players would fly around and try to pop each other&rsquo;s balloons in an NES balloon fight {link} style. Ideally something like 15 to 20 people would be in a lobby flying around and trying to pop each other.</p>
<p>Like gorilla tag I didn&rsquo;t want anyone to have to &ldquo;sit out&rdquo; of the game, so it&rsquo;s essentially a deathmatch where the player who pops the most balloons wins, and is also visible who&rsquo;s winning, because they also gain the balloons that they pop. In some playtests players would have 20 or 30 balloons on their heads. This was my clever idea of adding a built-in rubber-band effect to the gameplay as well, since having more balloons over your head made you a bigger target to pop. The gameplay worked well - but I never quite got the game to a place with netcode and networking engine where multiplayer felt seamless enough.</p>
<p>Here’s a video of one of the later states of the game, where I have it fully networked and am testing with friends, though it still has a few bugs here:</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/Vxn8rDOZ7dU?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<h2 id="today">Today</h2>
<p>I stopped working on this project after about 3 months. It turned out that flying alone with this mechanic was very compelling (and also a great workout!) but the networking engine I had used for Treekeepers, Photon, was not up to the task for how low latency a competitive game needed to be. Treekeepers was four-player co-op so Photon was just fine.</p>
<p>In the future I might pick this one back up (or maybe have an AI agent pick it up for me depending on how that goes) using <a href="https://spacetimedb.com/">space-time DB</a> which looks like a great solution for this type of game that doesn&rsquo;t require a whole ton of cloud programming and setup</p>
<p>I haven&rsquo;t made a build of this game public yet due to its unfinished and multiplayer nature - it&rsquo;s not set up with a usable server other than for testing. If I receive interest in playing it from enough people, I&rsquo;ll go back in and package up the single player parts as a tech demo and put a download here.</p>
<p>I learned a lot from this project, both in terms of game code organization and game mechanic design, and I still think it&rsquo;s a great concept. I hope this movement mechanic becomes the basis for a full game in the future and with any luck with the direction software development AI is going I might get that opportunity sooner vs later. About 3 weeks from now, I will be releasing an article on the modern state of AI software development, including a deep dive on some of the latest tools for web and game development, so stay tuned!</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-06-23:/the-flapper/</guid>

                
                    <link>http://localhost:1313/the-flapper/</link>
                

                
                    <pubDate>Mon, 23 Jun 2025 00:00:00 UTC</pubDate>
                

                
                    <title>The Flapper - A Physical VR Multiplayer Game</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I&rsquo;m <a href="/about-me">Brian Hockenmaier</a>, and this site is full of things I build and write about. I love making games and things with VR and AI. And I love DIY projects, especially ones involving programming, engineering and 3D modeling. Some of this has been cross or back-posted from my <a href="https://www.thingiverse.com/hockenmaier/designs">thingiverse</a>, <a href="https://github.com/hockenmaier">github</a>, <a href="https://www.linkedin.com/in/hockenmaier/">linkedin</a>, and other places, but it all lives here permanently.</p>
<p>This is an evolution of <a href="old-site/index.html">my previous site last updated in 2022, which I still keep inside this one</a> for posterity and for the AIs of the future to know more about me. I like it not because of the content as much as because it was a fully custom js and html site with no framework&hellip; and I think it&rsquo;s sort of fun and funny that it was like this.</p>
<p>All work and opinions here are my own, not my employer&rsquo;s.</p>
<h1 id="why-im-making-it">Why I&rsquo;m making it</h1>
<p>I&rsquo;m creating this website in 2025 after starting a family as well as my first full-time role in AI. It&rsquo;s an effort to clean up my website&rsquo;s focus, move several disparate collections into one place, and emphasize what I truly care about. I wanted it to be easier to add content, CMS style, and I wanted a space to occasionally post written content, too.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="the hockenworks homepage"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/hockenworks.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">This webpage, if you hadn&#39;t noticed</span>
    
</div>

<p>A big reason I&rsquo;m doing this now is that, after listening to the Dwarkesh podcast with Gwern, I was convinced I really should have more of a record for future AIs to learn about me. I really don’t have a social media presence, nor do I want one, and over the years I have had a lot of projects and writing that I have unnecessarily kept private. AGI or not, there are non-artificial intelligences that may be interested one day. Talking to you, Alice :) When I started this website, your cousin Lily kept asking where you were and didn&rsquo;t seem to get the concept that you currently occupied the same space as Kaitlin.</p>
<p>I love some of the 2010s era blogs, and though mine is not going to be nearly as longform, nearly as focused on prose, or nearly as articulate, two of the sites I&rsquo;m trying to take inspiration from are <a href="https://slatestarcodex.com/about/">Slate Star Codex</a> and <a href="https://gwern.net/about">Gwern&rsquo;s website</a> which are definitely advising on style here. Other than the fact that mine is also a game.</p>
<hr>
<h1 id="etymology-of-hockenworks">Etymology of &ldquo;hockenworks&rdquo;</h1>
<p><strong>Hockenmaier</strong> is a great name. I&rsquo;ve always loved it. Not just because it’s unique and has my favorite number of letters, but because of its meaning, at least my family’s “folk-etymology” for it.</p>
<p>You have:</p>
<blockquote>
<p><strong>Hocken</strong></p>
</blockquote>
<p>Which can roughly translate to “sitting down, squatting, settling, idling”.</p>
<p>And then you have:</p>
<blockquote>
<p><strong>Maier</strong></p>
</blockquote>
<p>Which has many different spellings, and ours has southern German roots, but all &ldquo;Meyer&rdquo; names come from the latin root &ldquo;maior&rdquo; meaning steward, administrator, or more generally &ldquo;worker&rdquo;</p>
<p>My family often puts these two ideas together as &ldquo;Lazy Worker,&rdquo; which is very on-brand for our sense of humor, but I think it&rsquo;s not just funny, but true.</p>
<p>“Lazy Worker” is perfect for someone who wants to get a lot done, especially in software engineering. We only have so many hours, and the best lives are lived restricting the number of hours spent on work that isn&rsquo;t done with people you love. So you better be efficient about it. You better be lazy. There are <a href="https://blog.codinghorror.com/how-to-be-lazy-dumb-and-successful/?utm_source=chatgpt.com">many</a> <a href="https://xkcd.com/1205/?utm_source=chatgpt.com">correct</a> <a href="https://thethreevirtues.com/">takes</a> out there on the value of being lazy when programming.</p>
<p>Now that we are starting to have AI, it&rsquo;s even better. A lazy worker like myself will not only avoid unnecessary work, but will delegate all that can be delegated to the new AI workers that are multiplying in our computers. That makes the &ldquo;steward&rdquo; connotation of &ldquo;Maier&rdquo; all the more fitting.</p>
<p>I&rsquo;m proud to be the lazy worker, and this site is all about sharing my lazy works. My <em>hockenworks</em>.</p>
<hr>
<h1 id="ball-machine---the-game">Ball Machine - The Game</h1>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="A ball machine"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/bubble4.gif"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">The Ball Machine</span>
    
</div>

<p>Most blogs and personal websites are a bit boring. I think that is because most professionals consider what they do &ldquo;for work&rdquo; a bit boring by its nature, and don&rsquo;t necessarily make a concerted effort to have fun with it.</p>
<p>I have always tried to be the opposite, and with kids coming I am trying to make a bigger effort than ever to have fun whatever I&rsquo;m doing. Which is often working, in some way or another.</p>
<p>So for my website, I wanted it to be intentionally fun. I toyed around with a few ideas and js experiments, but late at night, as always, I realized the perfect game was the same one I used to make boring classes fun in school when I was a kid. That game consisted of the book of graph paper I always kept with me, plus a pencil, a ruler, and a protractor. I was a bit obsessed with physics simulation at the time. My favorite game in church growing up, where I was often daydreaming and looking at the huge arched ceiling, was to imagine a laser coming out of my line of sight and bouncing off of every surface in the room, to see where it would end up. This graph paper game I played was similar.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="balls everywhere"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/this-website-ball-machine-1.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">Some of my early playtests got pretty chaotic</span>
    
</div>

<p>I would start by making a &ldquo;spawn point&rdquo; usually near the top left of the page, where balls would start falling. I would draw out the path of these balls a few inches from each other along their path with &ldquo;speed lines&rdquo; to denote which way they were going, and how fast. Then I would add platforms, trampolines, loops, curves, &ldquo;booster&rdquo; acceleration zones, jumps, machines that would disassemble and reassemble balls, and so many other things - usually something new each sheet of paper - and I would end up with a Rube Goldberg machine of balls flying all around the sheet. The only goal was to fill the sheet with more ridiculous paths.</p>
<p>I started calling the sheets my &ldquo;ball machines&rdquo;. I wish I still had some of these drawings. I remember them being quite intricate.. I must have reserved English class for them.</p>
<p>So, to honor kid Brian, I am making my website a permanent ball machine. I hope you have fun with it and see all there is to unlock!</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="balls everywhere"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/waves2.gif"   style="height: auto; max-width: 300px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">Even on the limited phone version, you can create some productive chaos</span>
    
</div>

<h2 id="how-its-made">How it&rsquo;s made</h2>
<p>I don&rsquo;t typically make complicated things like this with JavaScript. So when I found the perfect physics engine for the game - <a href="https://brm.io/matter-js/">matter.js</a> - I knew I would need help from our new little assistants. And though this game is a bit too structured to call it &ldquo;vibe coded&rdquo; - at times, it was close.</p>
<p>I ended up making my own tool called <a href="/context-caddy">Context Caddy</a> to help me with it. Part of the reason I leaned so hard into this is because I&rsquo;m always trying to push the limits of current AI, and I hadn&rsquo;t built a game since the GPT-4 days (I&rsquo;ll post about that soon). The new thinking models are truly a step above GPT-4 (this was mostly done with o3 and its minis) but they&rsquo;re still way too eager to write duplicate code, and they still don&rsquo;t &ldquo;get&rdquo; the structure of your project a lot of the time, especially with visual and physical things like this. Still, they were a great help here.</p>
<p>This game is made extra complicated by the fact that it runs on top of <a href="https://gohugo.io/">Hugo</a>, which is the static site generator behind the &ldquo;content&rdquo; part of this site. This probably doubled or tripled the effort of making this game. But, the balls in the &ldquo;ball machines&rdquo; of my youth would interact with my text notes and drawings, so this ball machine needed to do so as well.</p>
<p>There is quite a bit going on under the hood to make these two very distinct types of development projects work in tandem, and for both of them to work well. The Ball Machine would love to eat up all of the resources and make the site content unresponsive, and the content was quite a lot to dynamically build physical bodies and colliders around. I like the end result. But I like it a lot better on desktop, where the two can really interact, so I think you should play it on a real computer with a mouse.</p>
<h2 id="how-to-play">How to Play</h2>
<span
  style="
    float: left;
    width: 150px;
    margin: 0 1rem 1rem 0;
    display: inline-block;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="ball chute"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/ball-chute-hatch-1.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
  <span style="display: block; font-style: italic; margin-top: 0.5rem">
    This tube creates balls every time you click it
  </span>
  
</span>

<p>The ball machine on this site is a gamified version of my graph paper drawings as a kid. Each time you load a page, you&rsquo;ll see a little pneumatic delivery tube on the top right of the screen.</p>
<p>When you spawn your first ball, you&rsquo;ll see a few things appear. First - you&rsquo;ll find a goal     <span
  style="
    display: inline-block;
    width: 40px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="the goal"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/goal.png"   style="height: auto; max-width: 40px; width: 100%"   >

 
</span>
 somewhere randomly on the page. Find a way to get the balls you spawn into that goal. But there is a bit of a trick - balls start out being worth 1 coin and accumulate another coin in value every two seconds. So, the longer you can keep balls around, the more they will be worth when going into the goals, and this might get more and more challenging as your drawings take up more of the screen and balls start bouncing off of each other.</p>
<p><strong>Keep Clicking!</strong></p>
<p>It&rsquo;s <a href="https://en.wikipedia.org/wiki/Incremental_game">a clicker game</a> - start by manually clicking the pneumatic delivery tube to spawn balls, but as you accumulate coins you&rsquo;ll be able to unlock different drawables and things that will let you accumulate more coins faster. If it feels like it&rsquo;s taking a while to make coins and unlock things, try playing around more with how the balls interact with the content, and use all of the tools you can draw. The site also works across multiple pages. And if all else fails&hellip; just give it time. This is a clicker game after all, so waiting is always a strategy! There is plenty to read while you wait.</p>
<p>It works best when you&rsquo;re on desktop, working on one tab at a time.</p>
<p> </p>
<blockquote>
<p>Quick Disclaimer: This game is designed for big screens, ideally desktop computers. If you must play on a phone, try landscape mode!</p>
</blockquote>
<h3 id="controls">Controls</h3>
<p><span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/line-mode.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>

<span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="curved line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/curve-mode.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>

<span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="compactor toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/compactor-mode.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>
</p>
<p>To start drawing your ball machine, you need to <kbd>Left Click</kbd> or <kbd>Tap</kbd> one of these drawable toggles in the main UI (top left of the screen)</p>
<p>When you have a drawable tool toggled on, you won&rsquo;t be able to click other links on the site. You&rsquo;ll see this visually indicated when you choose them. Unselect the currently selected tool in order to see it</p>
<p>Every drawable item (lines, launchers, and more) uses the following mechanics:</p>
<p> </p>
<h4 id="drawing-on-desktop">Drawing on Desktop</h4>
<p><strong>Spawn Balls:</strong> <kbd>Left Click</kbd> on the pneumatic spawner tube</p>
<p><strong>Draw Objects:</strong> <kbd>Left Click</kbd> and drag to see a preview, then <kbd>Left Click </kbd> to place</p>
<ul>
<li>Some drawables have a second action, like curved lines, that is previewed after the second click and confirmed with a third click</li>
</ul>
<p><strong>Cancel Drawing</strong> After you&rsquo;ve started a line or other drawing but before you&rsquo;ve clicked again to confirm, <kbd>Right Click</kbd> to cancel it.</p>
<p><strong>Delete Objects:</strong> Hover over a drawn item and <kbd>Right Click</kbd> to delete it, getting 50% of your money back</p>
<p> </p>
<h4 id="drawing-on-mobile">Drawing on Mobile</h4>
<p><span
  style="
    color: #ff0040;
    font-family: 'Arial Black', Arial, sans-serif;
    font-size: 20px;
  "
>
   Mobile Scroll Lock Warning:
</span>
 On Mobile, scrolling the page is blocked while you&rsquo;re drawing to allow you to draw lines in any direction.</p>
<p>You will need to untoggle your selected tool before you can scroll or click links.</p>
<p>If your phone has gesture controls to reload, go back or forward, or other browser things, you should disable them if you really want to play on your phone. Or, just play on desktop!</p>
<p><strong>Spawn Balls:</strong> <kbd>Tap</kbd> on the pneumatic spawner tube</p>
<p><strong>Draw Objects:</strong> <kbd>Touch and Drag</kbd> to see a preview, then <kbd>Release</kbd> to place</p>
<ul>
<li>Some drawables have a second action, like curved lines, that is previewed and confirmed on the next touch-and-drag.</li>
</ul>
<p><strong>Cancel Drawing</strong> After you&rsquo;ve started a line or other drawing but before you&rsquo;ve released to confirm, go back to where you started and release around there to cancel it. The threshold to cancel is within 25 pixels of where you started.</p>
<p><strong>Delete Objects:</strong> <kbd>Tap and hold</kbd> an object to delete it, getting 50% of your money back. You will see it pulse before it deletes.</p>
<p> </p>
<h4 id="the-auto-clicker">The Auto-Clicker</h4>
<span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="auto clicker"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/auto-clicker.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>

<p>This is the autoclicker button that lets you pay to auto-spawn balls.</p>
<p><kbd>Left Click</kbd> or <kbd>Tap</kbd> to buy the first auto-clicker, or upgrade it.</p>
<p><kbd>Right Click</kbd> on desktop or <kbd>Tap and hold</kbd> on mobile to refund and downgrade it to the previous click frequency.</p>
<p> </p>
<h3 id="money--other-hints">Money &amp; Other Hints</h3>
<p>You&rsquo;ll quickly find ways to lengthen your Rube-Goldberg Machines and build up value before you send balls into the goal. Your money is displayed on the coin counter next to the ball spawner.</p>
<p> </p>
<p><span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="dotted line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/everything-has-a-price.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>
<strong>Everything has a price!</strong></p>
<p>If you can&rsquo;t draw an item, you probably can&rsquo;t afford it. You&rsquo;ll see your coin counter flash red in the UI when this happens.</p>
<p><span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="dotted line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/dotted-line-mode.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>
<strong>You get what you pay for&hellip;</strong></p>
<p>If you ever find yourself out of money, these dotted lines are free. They are not saved permanently like other lines and they go away after 50 balls hit them.</p>
<p> </p>
<p>❌ A couple of things to watch out for when building ball machines:</p>
<ul>
<li>Balls have to be moving at all times. If they sit still for too long, they are considered dead and will poof out of existence.</li>
<li>This applies to balls hitting the goal, too. If your balls aren&rsquo;t moving much when they hit the target, they won&rsquo;t go in.
So keep your balls moving!</li>
</ul>
<p>😵 If you have a good run going, but it descends into chaos, it can be hard to recover. That&rsquo;s what the <kbd>Erase Balls</kbd> button above the draw tools is for!</p>
<p> </p>
<p>Each post on this site will be a slightly different randomized game! Try making ball machines on multiple pages at once. Your work will be saved in realtime, and you can make money even on pages you&rsquo;re not currently playing on.</p>
<p><span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="dotted line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/page-revenue.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>
 These counters display how much <strong>sustainable</strong> coin revenue per second you&rsquo;re making on this page, and how much other pages you&rsquo;re not currently working on are contributing. Any balls that are spawned automatically and continuously travel through your contraption to hit the goal will be averaged into the top amount. When you visit other pages, you will keep making this money - that&rsquo;s what the &ldquo;Other Pages&rdquo; revenue displays.</p>
<p>Your progress is saved to your device because your contraptions will be highly dependent on the screen size the site renders to.</p>
<p>The game works a bit differently on desktop and mobile, and the best experience is really on desktop - so try on a computer if you can! If on mobile, flip to landscape.</p>
<h3 id="the-end-of-the-game">The End of the Game</h3>
<p>Right now, the Ball Machine doesn&rsquo;t end, but you will be surprised the amount of money you can make across the whole site! Eventually, there will be other ways to spend coins on this site and potentially &ldquo;beat&rdquo; the ball machine. The late game items change the game in very interesting ways! I hope you make some fun machines on my website.</p>
<p>You&rsquo;ll know you&rsquo;ve done about all there is to do by tracking the achievements below!</p>
<h4 id="achievements">Achievements</h4>
<div id="achievements-list"></div>
<script>
document.addEventListener('DOMContentLoaded', function(){
  var container = document.getElementById('achievements-list');
  if(!container){ console.error('Achievements container missing'); return; }
  try {
    var defs = (window.App && App.Achievements && App.Achievements.defs) || [];
    var unlocked = JSON.parse(localStorage.getItem('game.achievementsUnlocked') || '{}');
    var yes = 'http:\/\/localhost:1313\/images\/achievement-yes.png';
    var no = 'http:\/\/localhost:1313\/images\/achievement-no.png';
    if(!defs.length){
      console.warn('No achievements definitions found');
    }
    defs.forEach(function(a){
      var row = document.createElement('div');
      var img = document.createElement('img');
      var got = unlocked[a.id];
      img.src = got ? yes : no;
      img.alt = got ? 'Unlocked' : 'Locked';
      img.style.width = '16px';
      img.style.height = '16px';
      img.style.marginRight = '4px';
      row.appendChild(img);
      var b = document.createElement('b');
      b.textContent = a.name;
      row.appendChild(b);
      if(got){
        row.appendChild(document.createTextNode(' – ' + a.desc));
      }
      container.appendChild(row);
    });
    if (location.hash && location.hash.includes('achievements')) {
      var anchor = document.getElementById('achievements');
      if (anchor) {
        setTimeout(function(){ anchor.scrollIntoView(); }, 50);
      }
    }
  } catch(e){
    console.error('Failed to render achievements', e);
    container.textContent = 'Error loading achievements.';
  }
});
</script>

<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<h3 id="resetting-the-game">Resetting the Game</h3>
<span
  style="
    color: #ff0040;
    font-family: 'Arial Black', Arial, sans-serif;
    font-size: 20px;
  "
>
   WARNING! Don't navigate to the below page unless you're sure you want to reset the ball machine game
</span>

<p>Resetting will erase all of your drawings on all pages and reset your goal locations, unlocks, coins and everything else.</p>
<p>If you are thinking about doing this because you want to try on another device, you don&rsquo;t need to, because progress is already saved to your device. The only reason to do this is to have a fresh start on this device.</p>
<p>Navigate <a href="/reset-ball-machine">here</a> and click reset to do that.</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-05-28:/this-website/</guid>

                
                    <link>http://localhost:1313/this-website/</link>
                

                
                    <pubDate>Wed, 28 May 2025 00:00:00 UTC</pubDate>
                

                
                    <title>This Website</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>Here&rsquo;s a peek at my first major board game creation!</p>
<p>I&rsquo;ve made a few clones or slight enhancements of games I like before like <a href="/nope-game">Nope</a> and <a href="/hocken-pocket-blokus">Hocken-Pocket-Blokus</a>, but Bloom or Bust is my first attempt at something of my own design with very high production quality.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Image description"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/bloom-or-bust-characters.jpg"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">The Cast</span>
    
</div>

<p>This is a risk-taking game where players compete to take over a tree with their specific type of fruit. Trees and bees are becoming a recurring theme in my games!</p>
<p>All parts of this game are hand-designed by me, mostly in VR with a tool called Gravity Sketch, blender, and one of my favorite programmer&rsquo;s 3D tools called OpenSCAD.</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/bloom-or-bust-7.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/bloom-or-bust-4.jpg"    >

</div>
</div>

<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/bloom-or-bust-3.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/bloom-or-bust-8.jpg"    >

</div>
</div>

<p>Of all my models, this one takes most advantage of my multicolor BambuLab printer. All parts including the custom box which cleverly incorporates the instructions and game board itself are printed in BambuLab Matte PLA, which in my opinion is the most beautiful way to print.</p>
<p>Production is batched with 80 to 150 of each fruit or bee on a build plate, with overall production heavily limited by the game board and latching box each requiring a separate print.</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/bloom-or-bust-2.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/bloom-or-bust-9.jpg"    >

</div>
</div>

<p>I have looked into outsourcing production of this game so that I can actually distribute it, but that has not happened yet. Its design is totally dependent on multicolor 3D printing, and most print farms would require nearly $30 just to produce it, let alone shipping it and any margin. Injection molding is an option but also gets expensive with this level of detailed color, and requires remodeling in several significant ways. It still might happen. Or I might put it out on a site that lets people buy the model and print it themselves.</p>
<p>I&rsquo;ll post in the future about how I decide to distribute this. If you really want to buy one now, contact me - but as of now I need to charge about $100 for a set.</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-05-28:/bloom-or-bust/</guid>

                
                    <link>http://localhost:1313/bloom-or-bust/</link>
                

                
                    <pubDate>Wed, 28 May 2025 00:00:00 UTC</pubDate>
                

                
                    <title>Bloom Or Bust!</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I built a nice little tool to help AI write code for you.</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/R5wztMBfh0w?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p>Well, really, o3-mini and o3-mini-high worked together to write this and I corrected a few things here and there. I started using this tool to write itself about 30 mins into development!</p>
<p>Download on github (above) or the VScode marketplace:</p>
<p><a href="https://marketplace.visualstudio.com/items?itemName=Hockenmaier.context-caddy">https://marketplace.visualstudio.com/items?itemName=Hockenmaier.context-caddy</a></p>
<hr>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-02-13:/context-caddy/</guid>

                
                    <link>http://localhost:1313/context-caddy/</link>
                

                
                    <pubDate>Thu, 13 Feb 2025 00:00:00 UTC</pubDate>
                

                
                    <title>Context Caddy</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>Custom GPTs are free for everyone as of yesterday, so I thought I’d post some of the best ones I’ve made over the last few months for all of you:</p>
<p>Proofreader (<a href="https://chatgpt.com/g/g-hjaNCJ8PU-proofreader)">https://chatgpt.com/g/g-hjaNCJ8PU-proofreader)</a>:
This one is super simple. Give it what you’ve written and it will provide no-BS proofreads. It’s not going to hallucinate content, just point out mistakes and parts that don’t make sense.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="proofreader GPT"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/proofreader-gpt.png"   style="height: auto; max-width: 200px; width: 100%"   >


    
</div>

<p>Make Real (<a href="https://chatgpt.com/g/g-Hw8qvqqey-make-real)">https://chatgpt.com/g/g-Hw8qvqqey-make-real)</a>:
This makes your napkin drawings into working websites. It’s got some of the same limitations other code-generating AI tools do, but it does a surprisingly good job creating simple working web frontends for your ideas!</p>
<p>Postman for PMs (<a href="https://chatgpt.com/g/g-QeNbSmirA-postman-for-pms">https://chatgpt.com/g/g-QeNbSmirA-postman-for-pms</a>)
Talk to APIs using natural language instead of downloading technical tools or writing code (only unauthenticated APIs, for now). Also a great way to learn about APIs for newbies - Postman for PMs knows about some free online APIs to get started with.</p>
<p>The Boy (<a href="https://chatgpt.com/g/g-efYNPIDrz-the-boy">https://chatgpt.com/g/g-efYNPIDrz-the-boy</a>)
An experimental “AI generated RPG” where you play as “The Boy” who realizes fantastic superpowers. It’s fun to play around and explore, but don’t expect too much consistent gameplay from the currently available AI models.</p>
<p>Exciting times. Have fun!</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2024-06-01:/some-custom-gpts/</guid>

                
                    <link>http://localhost:1313/some-custom-gpts/</link>
                

                
                    <pubDate>Sat, 01 Jun 2024 00:00:00 UTC</pubDate>
                

                
                    <title>Some Custom GPTs</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I made &ldquo;Postman for PMs,&rdquo; a tool to help non-engineers understand and use APIs!</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/3O4r_q2Ioko?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p>It&rsquo;s a &ldquo;Custom GPT&rdquo; - a customized version of chatGPT. Just give it some details about the API and then tell it in English what you want to get, post, update, whatever.</p>
<p>If you&rsquo;re a PM, business analyst, or anyone that cares about APIs but doesn&rsquo;t like terminals and engineer-y tools like Postman, and you have ChatGPT plus, try it out. Here&rsquo;s a link:
<a href="https://chatgpt.com/g/g-QeNbSmirA-postman-for-pms">https://chatgpt.com/g/g-QeNbSmirA-postman-for-pms</a></p>
<p>Important disclaimer: DON&rsquo;T use ChatGPT on corporate stuff if your company doesn&rsquo;t allow it! This was a fun experiment for me and I&rsquo;m definitely not using any corporate resources on it/for it. There are plenty of free APIs to try this out on. Maybe ask ChatGPT for some suggestions</p>
<hr>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2024-01-13:/postman-for-pms/</guid>

                
                    <link>http://localhost:1313/postman-for-pms/</link>
                

                
                    <pubDate>Sat, 13 Jan 2024 00:00:00 UTC</pubDate>
                

                
                    <title>Postman for PMs</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>This was a board game I &ldquo;cloned&rdquo; back in 2015, but newly redesigned in 2024 with resized pieces and a self-contained custom game box and instructions printed right into the box.</p>
<p>I love small games that travel well, and this game is about the same depth and nearly 1/4th the area of the original box - thus &ldquo;pocket&rdquo;. It&rsquo;s a snug fit but nicely sectioned out for all pieces. Have fun!</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/hocken-pocket-blokus-1.png"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/hocken-pocket-blokus-2.png"    >

</div>
</div>

<h2 id="hocken-pocket-blokus-print-instructions">Hocken-Pocket-Blokus Print Instructions</h2>
<p>If you have a multi-filament printer, check out the new 3mf for &ldquo;Hocken Pocket Blokus&rdquo; - a self contained full blokus game and box with a hinged lid, and game instructions printed into the box.</p>
<p>You can also print the lid and box STLs separately, but if you choose to do that, remember: the pocket version that the box and lid are made for requires scaling the board and pieces: X scaled to 70%, Y scaled to 70% and Z scaled to 115%.</p>
<h2 id="original-print-instructions">Original Print Instructions</h2>
<p>To print the board, print 4 of the &ldquo;Playing Board Quarter&rdquo; file. These should have the right level of tolerance to fit snugly but not too tight.</p>
<p>To print the pieces, you can either use the full plate set of 21 pieces, or pick and choose from the individual files. The file names represent the number of squares in each piece, as well as a word description of what the piece looks like.</p>
<p>Make sure the board and all sets of pieces are distinct colors of plastic.</p>
<p>Here is a link on how to play the game:</p>
<p><a href="http://entertainment.howstuffworks.com/leisure/brain-games/blokus1.htm">http://entertainment.howstuffworks.com/leisure/brain-games/blokus1.htm</a></p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2024-01-03:/hocken-pocket-blokus/</guid>

                
                    <link>http://localhost:1313/hocken-pocket-blokus/</link>
                

                
                    <pubDate>Wed, 03 Jan 2024 00:00:00 UTC</pubDate>
                

                
                    <title>Hocken-Pocket-Blokus</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>If you like retro video games and also drinking things, you&rsquo;re in luck!
Print them for your living room! Print them for your friends!
I hope these characters remind you of some of your favorite series.</p>
<p>I returned to <a href="/8-bit-coasters">this project</a> after 10 years to make more coasters, including some designs for multi-plastic printers and a reinforced 4-coaster holder!</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/2023-8-bit-set-2.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/2023-8-bit-set-1.jpg"    >

</div>
</div>

<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/2023-8-bit-set-3.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/2023-8-bit-set-4.jpg"    >

</div>
</div>

<p>It was super fun returning to this project! I was able to fix a few things that I had noticed failing over the years, like the new reinforced sides to the &ldquo;? Block&rdquo; holder. Now that multi-color prints are proliferating more widely, I&rsquo;m hoping people can use the new colored files - they really pop with the Silk+Matte PLA combo I used here. Links to those filaments:</p>
<p><a href="https://us.store.bambulab.com/products/pla-matte">https://us.store.bambulab.com/products/pla-matte</a>
<a href="https://us.store.bambulab.com/products/pla-silk-upgrade">https://us.store.bambulab.com/products/pla-silk-upgrade</a></p>
<p>Download on Thingiverse:
<a href="https://www.thingiverse.com/thing:6158533">https://www.thingiverse.com/thing:6158533</a></p>
<p>If you have a Bambulab printer, there is an included .3mf file with coloring and print settings ready to go!</p>
<p>Here&rsquo;s the original thing: <a href="https://www.thingiverse.com/thing:115150">https://www.thingiverse.com/thing:115150</a></p>
<p>Also pictured (third to last picture) are 18 of my favorite remixed coasters from my original thing. Find them in the remixes of the link above!</p>
<p>I&rsquo;ve included an openscad file for customizing multiple sizes of pixel art for your own designs, based on the awesome customizable version by ahtly here:
<a href="http://www.thingiverse.com/thing:139754">http://www.thingiverse.com/thing:139754</a></p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2023-08-06:/8-bit-coasters-10-year/</guid>

                
                    <link>http://localhost:1313/8-bit-coasters-10-year/</link>
                

                
                    <pubDate>Sun, 06 Aug 2023 00:00:00 UTC</pubDate>
                

                
                    <title>8-Bit Videogame Coasters, 10 Year Anniversary Edition</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I&rsquo;m writing this post retrospectively as I never published it at the time of creation. It will live here as a &ldquo;stake in the ground&rdquo; of AI software capabilities as of March 2023. Note- if you&rsquo;re reading on substack, this post won&rsquo;t work. Go to <a href="hockenworks.com/gpt-4-solar-system/">hockenworks.com/gpt-4-solar-system</a>.</p>
<p>The interactive solar system below was created with minimal help from me, by the very first version of GPT-4, before even function calling was a feature. It was the first of an ongoing series of experiments to see what frontier models could do by themselves - and I&rsquo;m posting it here because it was the earliest example I saved.</p>
<p>Here&rsquo;s a link to the chat where it was created, though it&rsquo;s not possible to continue this conversation directly since the model involved has long since been deprecated: <a href="https://chatgpt.com/share/683b5680-8ac8-8006-9493-37add8749387">https://chatgpt.com/share/683b5680-8ac8-8006-9493-37add8749387</a></p>

<div style="width:100%; max-width:1000px; margin:1em auto; position:relative; padding-top:70%;">
  <iframe
    class="lazy-iframe"
    data-src="/html/solar-system-self-contained.html"
    src="about:blank"
    loading="lazy"
    style="position:absolute; top:0; left:0; width:100%; height:100%; border:1px solid #ccc;"
  ></iframe>
</div>

<div style="text-align: center; margin-bottom: 1rem;">
    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">GPT-4 only wrote this for desktop, sorry phone users</span>
    
</div>

<p><strong>Controls</strong></p>
<p><kbd>Mouse Click + Drag</kbd> to move the solar system around</p>
<p><kbd>Mouse Wheel Up</kbd> to zoom in from the cursor location</p>
<p><kbd>Mouse Wheel Down</kbd> to zoom out</p>
<p>If you get lost, reload the page. That&rsquo;s an edge case GPT-4 didn&rsquo;t account for :)</p>
<p>Here was the initial prompt:</p>
<blockquote>
<p>This might be a long output, so if you need to break and I&rsquo;ll ask you to continue in another message feel free to do that. But please limit any non-code text prose to only essential statements to help mitigate this</p>
<p>I want you to make me a dynamic website. It should look good on mobile or on desktop, and I would like you to pick a nice dark background color and an interesting font to use across the page.</p>
<p>The page is intended to show the scale of the solar system in an interactive way, primarily designed for children to zoom in and out of different parts of the solar system and see planets and the Sun in relative scale. Mouse controls should also include panning around the model solar system, and should include text around planets with some statistics about their size, gravity, atmospheres, and any other fun facts you think would be educational and fun for 10-12 year olds.</p>
</blockquote>
<p>Then I had to give it 4 more short prompts, one for a technical hint (to use html-5 since it was going a strange direction) and 3 for visual and mouse control misses.</p>
<p>It works - but missed some of the relatively simple directions, like the planet stats and rendering/controls for mobile. Still, I think it&rsquo;s cool to see the true scale of the planets on a zoomable canvas. And, it only goes to Neptune, the last true planet&hellip; don&rsquo;t go looking for Pluto.</p>
<p>For March 2023, this result was revolutionary - I was truly impressed. In 2025, it&rsquo;s not very impressive at all. How quickly we get used to progress!</p>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2023-03-18:/gpt-4-solar-system/</guid>

                
                    <link>http://localhost:1313/gpt-4-solar-system/</link>
                

                
                    <pubDate>Sat, 18 Mar 2023 00:00:00 UTC</pubDate>
                

                
                    <title>GPT-4 Solar System</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I made my latest Unity project into a multi-application &ldquo;engine&rdquo;. I am now building and releasing two applications from one project. Let me show you how it works.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Switching apps in the treekeepers engine"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/treekeepers-app-switcher-1.gif"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">Switching apps in the treekeepers engine</span>
    
</div>

<p>I did this because I had a lot of assets and code in Treekeepers that would directly translate to a new project I was prototyping. I considered other approaches - git submodules, unity packages, just cloning my old project. After a cost-benefit writeup I decided on this.</p>
<p>Now when I change variables, I edit a class called “Application Definition” for each application, which look like this:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="An applictaion definition in the editor"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/treekeepers-app-switcher-2.png"   style="height: auto; max-width: 400px; width: 100%"   >


    
</div>

<p>My plan is to use this new &ldquo;Engine project&rdquo; to not only update multiple games with common assets and code easily, but also as an instant starting point for any new networked VR/AR prototype.</p>
<p>As I go, any code I refactor to be generic across all projects goes in an Engine folder. Same for prefabs, materials, etc.</p>
<p>This way, if this gets cumbersome in the future, I can make a git submodule out of everything in &ldquo;Engine&rdquo; and import that into a new project.</p>
<p>Here are the scripts. The first runs via the Editor UI and takes variables for anything that needs to be different by project. The second file has the application definition classes you saw in the image above.</p>
<p><a href="https://gist.github.com/hockenmaier/14d50ff0bb90aece1cc6de1b9fc5419d">https://gist.github.com/hockenmaier/14d50ff0bb90aece1cc6de1b9fc5419d</a></p>
<script src="https://gist.github.com/hockenmaier/14d50ff0bb90aece1cc6de1b9fc5419d.js"></script>

<p>The files are free to use. Check them out if you&rsquo;re in a similar situation, but be warned there are still some hard-coded things and references you’ll need to change.</p>
<p>Has anyone taken this approach before? Curious on other&rsquo;s take or approaches to similar problems!</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2023-03-17:/treekeepers-engine/</guid>

                
                    <link>http://localhost:1313/treekeepers-engine/</link>
                

                
                    <pubDate>Fri, 17 Mar 2023 00:00:00 UTC</pubDate>
                

                
                    <title>Treekeepers Engine</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I’ve been playing around with <a href="https://en.wikipedia.org/wiki/Neural_radiance_field">neural radiance fields</a> (NeRFs) lately and thought a fun way to explore them would be flying through them in the Treekeepers “Puddle Jumper” in true scale.</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/QguH3aK90Ck?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p>Of course, you lose a lot of the draw of NeRFs when you export the model into a 3d engine because it has to flatten all the textures and lighting, and also Luma AI cuts off 3D model exports as a jarring cube</p>
<p>But still - I was amazed at how well just applying a day/night lighting cycle and mesh colliders worked with this. Projectile and enemy physics played well too.</p>
<p>It’s still early days, but I could see 3D model generation from this tech getting a lot better and forming the basis for some really interesting user-generated content in the future!</p>
<p>Neat stuff - big thanks to Luma AI for the free toolset.</p>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2023-02-01:/nerfs/</guid>

                
                    <link>http://localhost:1313/nerfs/</link>
                

                
                    <pubDate>Wed, 01 Feb 2023 00:00:00 UTC</pubDate>
                

                
                    <title>NeRFs in VR</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    







    



    























<img  alt="The Treekeepers Puddle Jumper"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/treekeepers_moonlight.png"   style="height: auto; max-width: 100%"   >


    
        <span style="font-style: italic; margin-top: 0.5rem;">The Treekeepers Puddle Jumper</span>
    
</div>

<p>Treekeepers VR is a networked VR game where up to 4 players can cooperate to navigate an oversized world and save a giant tree.</p>
<p>Treekeepers is in production on both Quest (standalone VR) and Steam (PC VR) with full cross-play functionality. See the <a href="https://togetheragainstudios.com/treekeepersvr/">Treekeepers VR Website</a> for links to all storefronts and more detail about the game.</p>
<h2 id="heading"></h2>
<h2 id="development">Development</h2>
<p>I began working on Treekeepers in June 2021, and my primary goal was to go significantly deeper into Unity and make a fully networked game. Very few co-op games existed in VR at the time (the area is still lacking), and my intention was to answer this need and create a game that 4 players could cooperate in within a static frame of reference (players move within a ship, and the ship moves through the world) while having to solve coordination challenges together.</p>
<p>I initially designed the project for SteamVR only using the SteamVR SDK but quickly realized that a VR game released only on PC would miss the majority of the userbase, as the (then Oculus) Quest 2 was quickly dominating the market. Treekeepers was a good fit for a mobile platform with its simple low-poly cel-shaded design, so I pivoted to using OpenXR about two months into the project to support VR interactions on both PC and mobile (Android) devices like the Quest 2.</p>
<p>By summer 2022, I had a releasable product, albeit only with one “world” available. I decided to push the game to early access to gather rapid feedback from real players, and after getting approved for both storefronts, Treekeepers released to early access on September 30, 2022.</p>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2022-10-01:/treekeepers-vr/</guid>

                
                    <link>http://localhost:1313/treekeepers-vr/</link>
                

                
                    <pubDate>Sat, 01 Oct 2022 00:00:00 UTC</pubDate>
                

                
                    <title>Treekeepers VR</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>The &ldquo;Human Joystick&rdquo; is an experimental VR movement system in which the player moves through the virtual environment by changing their physical location within their VR &ldquo;playspace&rdquo;.</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/q_1itpdiPb4?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p>A demo of the human joystick movement system, showing how the system can work on flat surfaces or terrain.</p>
<p>This was my first barebones VR project. Though I knew Unity going in, VR and 3D games in general have a lot of unique aspects that I wanted to learn about while trying to solve an actual problem, rather than following tutorials or demos online.</p>
<p>VR has some adoption problems in its current state. We all know of some of the main problems- the clunky headset, the nausea issues, and of course the pricetag. But one major problem that you don&rsquo;t really notice until you get into it, is the lack of a good solution for virtual movement.</p>
<p>I had been wondering about &ldquo;the human joystick&rdquo; as a potential a solution to this particular problem ever since getting into consumer VR in 2016.</p>
<p>In most modern VR systems, the player can move physically around the room if they choose. Some applications and games depend on this - they put you in a small space and rely on your physical movement in order to reach different areas and interact with things. But games that provide a more traditional sense of scale and allow players to move through large worlds cannot rely on physical motion, because their users are constrained by physical space. Because of this, you see all kinds of &ldquo;artificial&rdquo; locomotion systems in order to let people move around - some just like traditional 2D games that let users &ldquo;slide&rdquo; their playspaces around the world using a joystick, and others that adopt teleportation mechanics. Neither feel very natural as compared to actually walking, and some can be downright sickening.</p>
<p>My goal with this project was to solve this problem with a mixture of physical and artificial movement.</p>
<p>It works like this: When the player is standing near the center of their playspace, physical VR movement applies. The player can move around and interact with things with their actual bodies. But once the player moves further from the center, the plaspace starts to move with them in the same direction as the vector from the center of the player&rsquo;s space to their current position. This allows for some of the benefits that physical movement experiences have, while allowing the players to more naturally move through an infinite amount of space.</p>
<p>I experimented with several speeds, both static and scaling with the distance between the center and the player. I also experimented with the size of the physical movement &ldquo;deadzone&rdquo; and with vertical and constrained movement across hills, valleys, and buildings.</p>
<hr>
<table>
  <thead>
      <tr>
          <th style="text-align: center">


















<div class="paige-image">
    





























    



    

    
        

        

        
    
        

        

        
    
        

        
            

    



    







    





    



    























<img   class="img-fluid "  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/human_joystick_centered.jpg"   style="display:block; height: auto; margin:0 auto; width: 60%"   >


</div>
</th>
          <th style="text-align: left"><em>View from the player&rsquo;s perspective looking at the guides at his feet. With the white dot in the red deadzone, the player isn&rsquo;t moving.</em></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">


















<div class="paige-image">
    





























    



    

    
        

        

        
    
        

        

        
    
        

        
            

    



    







    





    



    























<img   class="img-fluid "  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/human_joystick_moving.jpg"   style="display:block; height: auto; margin:0 auto; width: 60%"   >


</div>
</td>
          <td style="text-align: left"><strong><em>When the white dot is in the green area, the player moves in that direction. Here I am moving forward and left at about half of max speed.</em></strong></td>
      </tr>
  </tbody>
</table>
<hr>
<p>Eventually I found some good default values and the system worked, but there were some unforeseen problems: First, it was more difficult to center yourself within the playspace without looking at the visible guides I put at the player&rsquo;s feet than I expected. Second and more importantly, when you were already moving in one direction, it was not as simple as I thought to start moving in another direction accurately without fully returning to center, which was an immersion breaker.</p>
<p>Ultimately I put the project up for others to view but have not expanded it into a full experience or released it on any marketplaces. Feel free to download the Unity project and try it on your own VR setup if you&rsquo;re curious.</p>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2020-01-01:/human-joystick/</guid>

                
                    <link>http://localhost:1313/human-joystick/</link>
                

                
                    <pubDate>Wed, 01 Jan 2020 00:00:00 UTC</pubDate>
                

                
                    <title>Human Joystick VR</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>The Answering Machine is a proof-of-concept system that I built using <strong>pre-LLM</strong> natural language processing (NLP), specifically NLTK, to produce answers to questions asked about data in plain English.</p>
<p>Looking back, this project was a great insight into what LLMs immediately allowed that was incredibly difficult before. This project was several months of work that the openAI sdk would probably have allowed in a few weeks - and that few weeks would have been mostly frontend design and a bit of prompting.</p>
<p><strong>Try it here:</strong> <a href="http://voicequery-dev.s3-website-us-west-2.amazonaws.com/">http://voicequery-dev.s3-website-us-west-2.amazonaws.com/</a>
<strong>Github:</strong> <a href="https://github.com/hockenmaier/voicequery">https://github.com/hockenmaier/voicequery</a></p>
<p>The system uses natural language processing to produce answers to questions asked about data in plain English.</p>
<p>It is designed with simplicity in mind—upload any columnar dataset and start asking questions and getting answers. It uses advanced NLP algorithms to make assumptions about what data you&rsquo;re asking about and lets you correct those assumptions for follow-up questions if they&rsquo;re wrong.</p>
<p>It is built entirely out of serverless components, which means there is no cost to maintain or run it other than the traffic the system receives.</p>
<h2 id="how-to">How-to</h2>
<p>On a desktop or tablet, click the link in the header to navigate to the Answering Machine. For now, it isn&rsquo;t optimized for smartphone-sized screens.</p>
<p>In order to use the Answering Machine, you can either select one of the existing datasets, such as &ldquo;HR Activity Sample,&rdquo; or upload one of your own using the homepage of the site:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Answering Machine homepage"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/answering_machine_uploads.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>To upload your own, click in the upload area or just drag a file straight from your desktop. For now, use CSV data files. Excel and other spreadsheet programs can easily save data in the CSV format using the &ldquo;File &gt; Save As&rdquo; or similar option in the menu. Each file needs a unique name.</p>
<p>When you hit the upload button, the site may not appear to change until the file is uploaded, at which point you&rsquo;ll see it appear in the box labeled &ldquo;Ask Your Data Anything&rdquo; below. Click on your file to start using it with the Answering Machine, or click the red trash can icon to delete it.</p>
<p>There are no user accounts in this system yet, so the data you upload might be seen by other users using the system. Try not to use sensitive data for now.</p>
<h3 id="asking-questions">Asking questions</h3>
<p>When you enter a dataset, you&rsquo;ll see a view that presents you with quite a bit of information:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    







    





    



    























<img  alt="Answering Machine main view"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/answering_machine_hr.png"   style="height: auto; width: 100%"   >


    
</div>

<p>The only part you need to focus on right now is the information panel. This panel lists out all the fields (columns), data types of those fields, and some sample data from a few records in your dataset:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Answering Machine info panel"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/answering_machine_info.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>You can use this panel to start to formulate questions you might have about the data. If you see number values, you might ask about averages, maximums, or other math that might otherwise take some time to calculate. If you see a date, you can ask questions about the data in certain time periods.</p>
<p>Many datasets also contain fields that only have a few specific allowed values. When the Answering Machine sees fewer than 15 unique values in any field, the data type will be a &ldquo;List&rdquo; and it lists them right out under the sample values table. You can use this type of value to ask questions about records containing those specific values. For example, in the HR dataset, you might only be interested in data where the &ldquo;Education&rdquo; field&rsquo;s value is &ldquo;High School.&rdquo;</p>
<p>Now look to the query bar to start asking your data questions:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Answering Machine query bar"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/answering_machine_query.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>The types of questions that will currently be automatically detected and answered are:</p>
<ul>
<li>Counts of records where certain conditions are true</li>
<li>Math questions such as averages, medians, maximums, and minimums</li>
</ul>
<p>These types of questions can be made specific by using qualifying statements with prepositional phrases like &ldquo;in 2019&rdquo; or adjective phrases like &ldquo;male&rdquo; or &ldquo;entry-level.&rdquo;</p>
<p>Combining these two ideas, you can ask specific questions with any number of qualifiers, such as:<br>
<em>&ldquo;What was the median salary of male employees in the engineering department 5 years ago?&rdquo;</em></p>
<p>Upon hitting the &ldquo;Ask&rdquo; button (or hitting Enter), the Answering Machine will do its best to answer your question and will show you all of its work in this format:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Answering Machine response"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/answering_machine_answer.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>The last line in the response is the Answering Machine&rsquo;s answer. In this case, it is telling you the metric you asked for with all your stipulations is <strong>6871.6 dollars.</strong></p>
<p>Moving up, you see a series of assessments that the Answering Machine has made in order to filter and identify the data you are asking about. Statements like &ldquo;Best auto-detected Numeric Subject Found: salary with column: Compensation (Monthly)&rdquo; provide a glimpse into one of the Answering Machine&rsquo;s most advanced features, which uses a selection of NLP techniques to compare words and phrases that are similar in meaning, ultimately matching things you are asking about to fields and values that actually exist in your database.</p>
<p>At the very top of the response is how the Answering Machine&rsquo;s nested grammar parsing logic actually parsed your question, with some specific pieces color-coded:</p>
<ul>
<li><strong>Green</strong> chunks indicate &ldquo;subjects&rdquo; that were detected. Subjects are what the Answering Machine thinks you&rsquo;re asking &ldquo;about.&rdquo; These should represent both the main subject and other supporting subjects in your question.</li>
<li><strong>Purple</strong> chunks are conditions. These are the things that the Answering Machine thinks you are trying to use to &ldquo;specify&rdquo; or filter data.</li>
</ul>
<p>Now that your question is answered, you might notice that some new green and purple colored bubbles have appeared in the sections of your screen labeled &ldquo;New Subjects&rdquo; and &ldquo;New Conditions.&rdquo; We&rsquo;ll call these &ldquo;lexicon&rdquo;:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Answering Machine subjects and conditions"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/answering_machine_lexicon.png"   style="height: auto; max-width: 400px; width: 100%"   >


    
</div>

<h3 id="forming-concepts">Forming Concepts</h3>
<p>If the Answering Machine already understood what you were asking and successfully matched it to fields and values in your data, you don&rsquo;t have to do anything with these. But often you will be using domain-specific lexicon, or the auto-matching algorithm simply won&rsquo;t pick the correct value. These situations are what concepts are for.</p>
<p>To create a concept, click and drag on the green or purple &ldquo;lexicon&rdquo; bubble and move it out into the blank middle area of the screen. Then click and drag the field or field value from the info-panel at the top of the screen and drop it right on top of that bubble. You&rsquo;ll see both the data bubble and the lexicon bubble included in a larger gray bubble, which represents the concept:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Answering Machine concept"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/answering_machine_concept.png"   style="height: auto; max-width: 200px; width: 100%"   >


    
</div>

<p>You can add more lexicon bubbles to this concept if they mean the same thing, but you can only use one data bubble.</p>
<p>Concepts override the Answering Machine&rsquo;s auto-matching logic. If you ask another question containing a subject or condition that is now matched by a user to a data value, that data value will be used instead of the auto-match. If the concept isn&rsquo;t working well, you can delete it by dragging all of the nested bubbles out of it either into the blank middle area or into the colored panel they originally came from.</p>
<p>Feel free to play around with new datasets and questions, and use the contact section of this site if you have comments or questions. When you ask questions or create/modify concepts, that data will automatically be saved to the server in real-time. You can close the page anytime and come back to your dataset to keep asking questions.</p>
<p>Remember that there are no user accounts, meaning you can share your dataset and work in tandem with others! But again, please do not upload sensitive data to this proof-of-concept tool as it will be available for other users to see and query.</p>
<h2 id="architecture">Architecture</h2>
<p>The Answering Machine is a purely &ldquo;serverless&rdquo; application, meaning that there is no server hosting the various components of the application until those components are needed by a user. This is true for the database, the file storage, the static website, the backend compute, and the API orchestration.</p>
<p>For the cloud nerds out there, <a href="https://martinfowler.com/articles/serverless.html">here is a great article</a> by Martin Fowler on what exactly &ldquo;serverless&rdquo; means, especially in terms of the backend compute portion, which is arguably the most valuable part of the application to be serverless. For reference, I am using Martin&rsquo;s 2nd definition of &ldquo;serverless&rdquo; here.</p>
<p>This is a high-level map of all of the components that make the Answering Machine work in its current (June 2020) state. The API gateways, CloudWatch events, and some triggers &ldquo;given for free&rdquo; by AWS are left out of this for readability:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Serverless Architecture of the Answering Machine app"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/answering_machine_architecture.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>The full suite of lambdas and persistent storage services that make up the Answering Machine.</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2019-07-03:/answering-machine/</guid>

                
                    <link>http://localhost:1313/answering-machine/</link>
                

                
                    <pubDate>Wed, 03 Jul 2019 00:00:00 UTC</pubDate>
                

                
                    <title>The Answering Machine</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>Land War is an 8-player strategy game I developed as a solo project and released to Steam in March of 2019.<br>
This game was intended to have low art requirements and simple interaction rules that result in deep strategic gameplay.</p>
<p>The core concept is that of an ultra-simplified real-time-strategy game. Each player is represented by a color and can grow their territory by moving in any direction. The strategic elements occur when players encounter other players and have to make choices about which side of their land to defend or give up. Players can use the structure of the map and the coordinated action of other players to gain defensible footholds in order to take more area and eventually be the last player on the board.</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/5Q8PAuWcmQc?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p>A full game of the final product released on Steam played on a Windows computer.</p>
<h3 id="development">Development</h3>
<p>I built Land War over the course of 7 months and 400 hours of work using Unity with C#. Though art requirements were intentionally low for a video game, I still had to produce several hundred static graphics and GIFs, and commissioned custom music for the menu and gameplay.</p>
<p>This project is one of my favorite examples of what can be done in relatively little time with a focused vision and a constant eye on scope creep. From the very start, I knew that a key to making compelling software was to flesh out the core concept before all else. This is why I started on the most fundamental strategic interaction of the players and built an MVP version of the game without a menu, sound, art, or even a win condition.</p>
<p>I started the project on a Memorial Day Monday, and by Friday had a rudimentary prototype playable with 8 players on Nintendo Joy-Con controllers paired to a Windows machine via Bluetooth.<br>
This is what the project looked like for my first play-test with other people 5 days in:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    







    





    



    























<img  alt="Land War 4-day MVP"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/land_war_mvp.gif"   style="height: auto; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">4-player game played with Nintendo Joy-Cons on a build of the game from 5 days into development.</span>
    
</div>

<p>From there, I continued to work on depth and full feature functionality including menus, a tutorial, a map generator, a dynamic scoring and round system, better sound and sprite graphics, different play modes and settings, and support for many controllers. I released the game with very little marketing aside from some Reddit posts and a physical handout at E3 but was happy to receive positive reviews and several hundred purchases of the game.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    







    





    



    























<img  alt="Player Select screen"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/land_war_player_select.png"   style="height: auto; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">Player Select screen. Supporting menu and player controls across hundreds of controller types was one of the largest unforeseen challenges in developing Land War.</span>
    
</div>

<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    







    





    



    























<img  alt="Settings menu"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/land_war_settings.png"   style="height: auto; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">Settings menu. Most interesting mechanics I found while developing the game were added as options to keep the game interesting here.</span>
    
</div>

<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="E3 marketing material"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/land_war_e3.png"   style="height: auto; max-width: 400px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">The only physical marketing material developed for Land War. Several hundred Steam keys (copies of the game) were handed out during the E3 convention in 2019.</span>
    
</div>


    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/BylKEPF4EeU?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p><em>Land War&rsquo;s Steam release announcement trailer.</em></p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2019-03-01:/land-war/</guid>

                
                    <link>http://localhost:1313/land-war/</link>
                

                
                    <pubDate>Fri, 01 Mar 2019 00:00:00 UTC</pubDate>
                

                
                    <title>Land War</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<blockquote>
<p>Editor&rsquo;s note from 2025:</p>
<p>First Ten is no longer available after Google discontinued custom voice apps in 2023, but I&rsquo;m leaving this article here as a record. Now, similar apps can be built in hours or minutes using modern AI models. First Ten used a now outdated intent routing system to fetch information from a serverless architecture about the Bill of Rights. Interestingly, my infrastructure for this app is still up and running behind the scenes because it&rsquo;s truly serverless and costs nothing to host.</p>
</blockquote>
<p>First Ten is an educational app containing information about the U.S. Bill of Rights, accessible on Google devices and smart speakers.</p>
<p>It uses a VUI (voice user interface) only, meaning there is no visual way to interact with the app.</p>
<p><strong>Try it here:</strong> <a href="https://assistant.google.com/services/a/uid/00000036f6a580ed">https://assistant.google.com/services/a/uid/00000036f6a580ed</a>
Like Alexa skills, Google actions can be accessed through search or by simply asking for their names in Google Home smart speakers. Ask your Google Home or Android device, &ldquo;Can I speak to First Ten?&rdquo; in order to try it.</p>
<h3 id="architecture">Architecture</h3>
<p>First Ten&rsquo;s backend is built in the serverless AWS services Lambda and DynamoDB, and its frontend—the engine that parses your voice into different &ldquo;intents&rdquo; and parameters—is built on Google&rsquo;s Dialogflow.
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="Serverless Architecture of the First Ten app"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/first_ten_architecture.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>
</p>
<hr>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2018-05-19:/first-ten/</guid>

                
                    <link>http://localhost:1313/first-ten/</link>
                

                
                    <pubDate>Sat, 19 May 2018 00:00:00 UTC</pubDate>
                

                
                    <title>First Ten</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p><strong>Raspberry Pi Control Panel</strong> is a hardware project I designed in 2016 to manage home automation systems. The project involved designing a custom 3D-printed case for a Raspberry Pi microcomputer with a touchscreen interface.</p>
<p>Links:</p>
<ul>
<li><a href="https://github.com/hockenmaier/RaspberryPiControlPanel">GitHub</a></li>
<li><a href="https://www.thingiverse.com/thing:2524560">Thingiverse</a></li>
</ul>
<hr>
<p>I created this panel display in 2016 to control much of the home automation I used in my Studio City apartment. Mainly a hardware project, I designed and 3D-printed a case and frame for the touchscreen and raspberry pi microcomputer in order to mount them to the wall. The software running the control panel is SaaS, but I did write a custom html wrapper to control the orientation and settings of the site, which is available on the github linked above.</p>
<p>Update in 2025: This panel is still my main view into my home automation in my new house in Sherman Oaks, almost 10 years in with no modification to the software or Pi itself! However, the LED behind the screen died this year and I had to replace it (link below)</p>
<p>Here&rsquo;s a video to see the panel in action:</p>
<h2 id="hahahugoshortcode29s0hbhb">
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/iFGmm-ijJvE?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>
</h2>
<p>Feel free to explore the linked repositories for schematics and source code.</p>
<h2 id="instructions">Instructions</h2>
<p>If you want to make this, all you need to do is set up a raspberry pi, download chromium (or your preferred web browser), and navigate to your action tiles panel.</p>
<p>If you want to mount the screen vertically like mine, then I have made an easier solution than going through the trouble of actually rotating the raspberry&rsquo;s display and touch device. Just use the html below and edit it to use your own panel&rsquo;s URL in the &ldquo;iframe&rdquo; element instead of mine. This will launch the panel rotated in your browser.</p>
<div class="highlight"><pre tabindex="0" style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-html" data-lang="html"><span style="display:flex;"><span><span style="color:#ff0007;background-color:#0f140f;font-weight:bold;font-style:italic">&lt;!DOCTYPE html&gt;</span>
</span></span><span style="display:flex;"><span>&lt;<span style="color:#fb660a;font-weight:bold">html</span>&gt;
</span></span><span style="display:flex;"><span>  &lt;<span style="color:#fb660a;font-weight:bold">head</span>&gt;
</span></span><span style="display:flex;"><span>    &lt;<span style="color:#fb660a;font-weight:bold">title</span>&gt;Rotated Raspberry Panel&lt;/<span style="color:#fb660a;font-weight:bold">title</span>&gt;
</span></span><span style="display:flex;"><span>    &lt;<span style="color:#fb660a;font-weight:bold">style</span> <span style="color:#ff0086;font-weight:bold">type</span>=<span style="color:#0086d2">&#34;text/css&#34;</span>&gt;
</span></span><span style="display:flex;"><span>      <span style="color:#fb660a;font-weight:bold">body</span> {
</span></span><span style="display:flex;"><span>         <span style="color:#fb660a">-webkit-</span><span style="color:#fb660a;font-weight:bold">transform</span>: rotate(<span style="color:#0086f7;font-weight:bold">90</span><span style="color:#cdcaa9;font-weight:bold">deg</span>);
</span></span><span style="display:flex;"><span>         <span style="color:#fb660a">-webkit-</span><span style="color:#fb660a;font-weight:bold">transform-origin</span>: <span style="color:#fb660a;font-weight:bold">bottom</span> <span style="color:#fb660a;font-weight:bold">left</span>;
</span></span><span style="display:flex;"><span>         <span style="color:#fb660a;font-weight:bold">position</span>: <span style="color:#fb660a;font-weight:bold">absolute</span>;
</span></span><span style="display:flex;"><span>         <span style="color:#fb660a;font-weight:bold">top</span>: <span style="color:#0086f7;font-weight:bold">-100</span><span style="color:#cdcaa9;font-weight:bold">vw</span>;
</span></span><span style="display:flex;"><span>         <span style="color:#fb660a;font-weight:bold">height</span>: <span style="color:#0086f7;font-weight:bold">100</span><span style="color:#cdcaa9;font-weight:bold">vw</span>;
</span></span><span style="display:flex;"><span>         <span style="color:#fb660a;font-weight:bold">width</span>: <span style="color:#0086f7;font-weight:bold">100</span><span style="color:#cdcaa9;font-weight:bold">vh</span>;
</span></span><span style="display:flex;"><span>         <span style="color:#fb660a;font-weight:bold">background-color</span>: <span style="color:#0086f7;font-weight:bold">#000</span>;
</span></span><span style="display:flex;"><span>         <span style="color:#fb660a;font-weight:bold">color</span>: <span style="color:#0086f7;font-weight:bold">#fff</span>;
</span></span><span style="display:flex;"><span>         <span style="color:#fb660a;font-weight:bold">overflow</span>: <span style="color:#fb660a;font-weight:bold">hidden</span>;&#34;
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>        <span style="color:#fb660a;font-weight:bold">iframe</span>{
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      	<span style="color:#fb660a">-ms-</span><span style="color:#fb660a;font-weight:bold">transform</span>: scale(<span style="color:#0086f7;font-weight:bold">0.97</span>);
</span></span><span style="display:flex;"><span>      	<span style="color:#fb660a">-moz-</span><span style="color:#fb660a;font-weight:bold">transform</span>: scale(<span style="color:#0086f7;font-weight:bold">0.97</span>);
</span></span><span style="display:flex;"><span>      	<span style="color:#fb660a">-o-</span><span style="color:#fb660a;font-weight:bold">transform</span>: scale(<span style="color:#0086f7;font-weight:bold">0.97</span>);
</span></span><span style="display:flex;"><span>      	<span style="color:#fb660a">-webkit-</span><span style="color:#fb660a;font-weight:bold">transform</span>: scale(<span style="color:#0086f7;font-weight:bold">0.97</span>);
</span></span><span style="display:flex;"><span>      	<span style="color:#fb660a;font-weight:bold">transform</span>: scale(<span style="color:#0086f7;font-weight:bold">0.97</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      	<span style="color:#fb660a">-ms-</span><span style="color:#fb660a;font-weight:bold">transform-origin</span>: <span style="color:#0086f7;font-weight:bold">0</span> <span style="color:#0086f7;font-weight:bold">0</span>;
</span></span><span style="display:flex;"><span>      	<span style="color:#fb660a">-moz-</span><span style="color:#fb660a;font-weight:bold">transform-origin</span>: <span style="color:#0086f7;font-weight:bold">0</span> <span style="color:#0086f7;font-weight:bold">0</span>;
</span></span><span style="display:flex;"><span>      	<span style="color:#fb660a">-o-</span><span style="color:#fb660a;font-weight:bold">transform-origin</span>: <span style="color:#0086f7;font-weight:bold">0</span> <span style="color:#0086f7;font-weight:bold">0</span>;
</span></span><span style="display:flex;"><span>      	<span style="color:#fb660a">-webkit-</span><span style="color:#fb660a;font-weight:bold">transform-origin</span>: <span style="color:#0086f7;font-weight:bold">0</span> <span style="color:#0086f7;font-weight:bold">0</span>;
</span></span><span style="display:flex;"><span>      	<span style="color:#fb660a;font-weight:bold">transform-origin</span>: <span style="color:#0086f7;font-weight:bold">0</span> <span style="color:#0086f7;font-weight:bold">0</span>;
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    &lt;/<span style="color:#fb660a;font-weight:bold">style</span>&gt;
</span></span><span style="display:flex;"><span>  &lt;/<span style="color:#fb660a;font-weight:bold">head</span>&gt;
</span></span><span style="display:flex;"><span>  &lt;<span style="color:#fb660a;font-weight:bold">body</span>&gt;
</span></span><span style="display:flex;"><span>    &lt;<span style="color:#fb660a;font-weight:bold">iframe</span>
</span></span><span style="display:flex;"><span>      <span style="color:#ff0086;font-weight:bold">src</span>=<span style="color:#0086d2">&#34;https://app.actiontiles.com/panel/f7a7118c-236b-4144-b5b9-ccb35abeef21&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#ff0086;font-weight:bold">height</span>=<span style="color:#0086d2">&#34;300%&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#ff0086;font-weight:bold">width</span>=<span style="color:#0086d2">&#34;300%&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#ff0086;font-weight:bold">frameborder</span>=<span style="color:#0086d2">&#34;0&#34;</span>
</span></span><span style="display:flex;"><span>    &gt;&lt;/<span style="color:#fb660a;font-weight:bold">iframe</span>&gt;
</span></span><span style="display:flex;"><span>  &lt;/<span style="color:#fb660a;font-weight:bold">body</span>&gt;
</span></span><span style="display:flex;"><span>&lt;/<span style="color:#fb660a;font-weight:bold">html</span>&gt;
</span></span></code></pre></div><p>Link to buy the screen:
Modern:
<a href="https://www.amazon.com/dp/B07P8P3X6M">https://www.amazon.com/dp/B07P8P3X6M</a>
Original:
<a href="https://smile.amazon.com/gp/product/B01ID5BQTC/">https://smile.amazon.com/gp/product/B01ID5BQTC/</a></p>
<p>Link to the Action Tiles web application this is running:
<a href="https://www.actiontiles.com/">https://www.actiontiles.com/</a></p>
<p>If you have issues getting your pi to use the full touchscreen width, try adding these setting to the /boot/config.txt file and reboot:</p>
<div class="highlight"><pre tabindex="0" style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#fb660a">max_usb_current</span>=<span style="color:#0086f7;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span><span style="color:#fb660a">hdmi_group</span>=<span style="color:#0086f7;font-weight:bold">2</span>
</span></span><span style="display:flex;"><span><span style="color:#fb660a">hdmi_mode</span>=<span style="color:#0086f7;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span><span style="color:#fb660a">hdmi_mode</span>=<span style="color:#0086f7;font-weight:bold">87</span>
</span></span><span style="display:flex;"><span>hdmi_cvt <span style="color:#0086f7;font-weight:bold">800</span> <span style="color:#0086f7;font-weight:bold">480</span> <span style="color:#0086f7;font-weight:bold">60</span> <span style="color:#0086f7;font-weight:bold">6</span> <span style="color:#0086f7;font-weight:bold">0</span> <span style="color:#0086f7;font-weight:bold">0</span> <span style="color:#0086f7;font-weight:bold">0</span>
</span></span></code></pre></div><p>If you want to make sure your screen doesn&rsquo;t go to sleep:</p>
<div class="highlight"><pre tabindex="0" style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo nano /etc/lightdm/lightdm.conf
</span></span></code></pre></div><p>Add the following lines to the [SeatDefaults] section:</p>
<div class="highlight"><pre tabindex="0" style="color:#fff;background-color:#111;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>xserver-command=X -s <span style="color:#0086f7;font-weight:bold">0</span> dpms
</span></span></code></pre></div>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2016-01-01:/raspberry-pi-panel/</guid>

                
                    <link>http://localhost:1313/raspberry-pi-panel/</link>
                

                
                    <pubDate>Fri, 01 Jan 2016 00:00:00 UTC</pubDate>
                

                
                    <title>Raspberry Pi Control Panel</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>This game is based off of a similar card game called &ldquo;No Thanks!&rdquo; but expands the number of players to 8.</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img  alt="nope"   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/nope-1.jpg"    >


      































    













    



    























<img  alt="nope"   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/nope-2.jpg"    >

</div>
</div>

<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img  alt="nope"   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/nope-3.jpg"    >


      































    













    



    























<img  alt="nope"   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/nope-4.jpg"    >

</div>
</div>

<p>Play time is about 20 minutes for the 3-5 player version, and 25-30 minutes for the 6-8 player version. Learning how to play the game takes 1-5 minutes depending on the attention span of the players. Have fun!</p>
<p>See Thingiverse for all of the files:
<a href="https://www.thingiverse.com/thing:643099">https://www.thingiverse.com/thing:643099</a></p>
<h1 id="print-instructions">Print Instructions</h1>
<p>3D-Print 88 tokens.</p>
<p>2D-Print the 2 included PDFs back-to-back, so that the numbers appear on the one side and the identical backsides are on the back. Or, leave out the backs as they are not necessary to play the game. Cut 9 cards out of each paper when they&rsquo;re done printing, along the gray lines.</p>
<p>It is recommended to either print on heavy duty paper, or to laminate the resulting cards.</p>
<p>You can also choose to make your own layout with larger or smaller cards using the included zip file of images.</p>
<p>For the 3-5 player game, print the cards numbered 3 to 35. For the 6-8 player game, print the cards numbered 3 to 46.</p>
<h1 id="to-play">To Play:</h1>
<p>Here is a link to the 3-5 player instructions:
<a href="https://cdn.1j1ju.com/medias/17/c3/3c-no-thanks-rulebook.pdf">https://cdn.1j1ju.com/medias/17/c3/3c-no-thanks-rulebook.pdf</a></p>
<p>The 6-8 player instructions are almost exactly the same as the 3-5 player game:
-All players still receive 11 tokens at the beginning of the game.
-Play with the 3-46 deck, shuffle the deck, and remove 11 cards instead of 9 cards before playing.</p>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2015-01-19:/nope-game/</guid>

                
                    <link>http://localhost:1313/nope-game/</link>
                

                
                    <pubDate>Mon, 19 Jan 2015 00:00:00 UTC</pubDate>
                

                
                    <title>NOPE - A 3D and 2D Printed Card Game</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>This is a working 3D-printed egg slicer! Why buy it when you can print it?</p>
<p>Both parts are printable without support and minimal bridging.</p>
<p>You can download the model for free on Thingiverse:
<a href="http://www.thingiverse.com/thing:440150">http://www.thingiverse.com/thing:440150</a></p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/1J0rH7o0R88?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<h2 id="instructions">Instructions</h2>
<p>Printing:
Print in ABS if possible. ABS is dishwasher safe (will not warp) and PLA is not. Print it hot to make it waterproof, if possible. I used .15 mm layers for the top and .25 mm layers for the base, and 30% fill for both. I would highly recommend a layer height of .15 or less for the top part, as there are a lot of small features you don&rsquo;t want your printer glossing over.</p>
<h3 id="assembly">Assembly:</h3>
<p>You&rsquo;ll need some small-gauge wire and pliers to finish the assembly of this thing. I used 28 gauge stainless steel wire, but anything 28 gauge or smaller and waterproof should work. Don&rsquo;t use fishing line because it flexes too much to work. Actual metal wire is needed.</p>
<p>Loop and tie the wire through one of the four mounting holes near the four corners of the top piece. Then weave the rest of the wire through the 20 holes (10 on each side) starting with the one immediately below the mounting hole you started with. Try to keep the wire as tight as possible with each weave. Finish by tying the other end of your wire to the remaining mounting hole on the side you started on.</p>
<p>Your wires are probably not tight enough at this point. Make sure the two ends are tied securely, and then grab your pliers. There is a small, vertical, raised wall with a notch in it between each hole on the outer edge of the top piece. Using the pliers, lift the wire into the notch on as many of the outer wire loops as possible in order to tighten it.</p>
<h3 id="operation">Operation:</h3>
<p>Peel your hard-boiled egg and place it on the base sideways. Push the top piece through the base and the wires. If you want your egg diced, lift it off the base, remove the top pieces of the slicer, put the egg back down rotated 90 degrees and proceed to dice your egg.</p>
<p>Soak in warm soapy water to wash it before storing.</p>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2014-08-24:/3d-egg-slicer/</guid>

                
                    <link>http://localhost:1313/3d-egg-slicer/</link>
                

                
                    <pubDate>Sun, 24 Aug 2014 00:00:00 UTC</pubDate>
                

                
                    <title>3D Printed Egg Slicer</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>This switch closes a circuit when a strong magnetic field is nearby. The magnet used in the video is a rare earth magnet which is stronger than your typical refrigerator magnet.</p>
<p>Thingiverse Download: <a href="https://www.thingiverse.com/thing:190218">https://www.thingiverse.com/thing:190218</a></p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/b4piw_LMiRg?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<h2 id="instructions">Instructions</h2>
<p>You will need two 4mm-wide wall hooks (the kind used to mount pictures). Make sure they conduct and are attracted to magnets. You will also need a hot glue gun.
Print two of the attached STL files (one of the mountable variety if you plan to mount it). Flatten the wall hooks with a hammer to get them completely flat, and lay the first one on one of your printed pieces leaving about a half an inch to spare from one end, and hanging out the other. Place a dab of hot glue on the end where it is hanging off. Do the same with the other half, and then place the halves together so the metal pieces are not quite touching in the middle. Seal the metal in place with hot glue.</p>
<p>The hot glue lets the metal move slightly, so that one metal piece bends to touch the other when a magnet is near either side of the switch, completing the circuit between the two metal ends still sticking out.</p>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2013-11-25:/3d-reed-switch/</guid>

                
                    <link>http://localhost:1313/3d-reed-switch/</link>
                

                
                    <pubDate>Mon, 25 Nov 2013 00:00:00 UTC</pubDate>
                

                
                    <title>3D Printed Reed Switch</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<blockquote>
<p>Editor&rsquo;s note from 2025:</p>
<p>This was my most-downloaded original 3D print, and my first design to be featured on the homepage.
I&rsquo;ve redesigned and re-released these coasters! <a href="/8-bit-coasters-10-year">Check out the 10 year anniversary edition.</a></p>
</blockquote>
<p>If you like retro video games and also drinking things, you&rsquo;re in luck!
This full set of 8 unique video game coasters comes with themed coaster holders for sets of either 4 or 8! Print them for your living room! Print them for your friends!
I hope these characters remind you of some of your favorite series.</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/2013-8-bit-set-1.png"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/2013-8-bit-set-2.jpg"    >

</div>
</div>

<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/2013-8-bit-set-3.jpg"    >


      































    













    



    























<img   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/2013-8-bit-set-4.jpg"    >

</div>
</div>

<p>Also find an awesome customizable version by ahtly here:
<a href="http://www.thingiverse.com/thing:139754">http://www.thingiverse.com/thing:139754</a></p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2013-07-09:/8-bit-coasters/</guid>

                
                    <link>http://localhost:1313/8-bit-coasters/</link>
                

                
                    <pubDate>Tue, 09 Jul 2013 00:00:00 UTC</pubDate>
                

                
                    <title>8-Bit Videogame Coasters</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I 3D Modeled and printed my apartment building&rsquo;s key with the Makergear M2. I won&rsquo;t be posting the model because it IS in fact a key to my apartment. Thanks for watching!</p>

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/_H2W8qXUJtg?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2013-05-13:/3d-key/</guid>

                
                    <link>http://localhost:1313/3d-key/</link>
                

                
                    <pubDate>Mon, 13 May 2013 00:00:00 UTC</pubDate>
                

                
                    <title>3D Printed Key</title>
                
            </item>
        
    </channel>
</rss>
