













    
        
    

    
        
    

    

    
        
    

    

    
        
    







    

    






<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"  xml:lang="en-us"  xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        
            

            
                
            

            
                <link href="https://bhock.net/tags/rapid-prototyping/" rel="self" type="text/html"/>
            
        
            

            

            
                <link href="https://bhock.net/tags/rapid-prototyping/rss.xml" rel="alternate" type="application/rss+xml"/>
            
        

        

        

        <description>Recent content</description>

        
            <language>en-us</language>
        

        
            <lastBuildDate>2025-02-05 00:00:00 +0000 UTC</lastBuildDate>
        

        <link>https://bhock.net/tags/rapid-prototyping/</link>

        

        <title>Rapid Prototyping · Tags · Home</title>

        

        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<hr>
]]></description>
                

                <guid isPermaLink="false">tag:bhock.net,2025-02-05:/context-caddy/</guid>

                
                    <link>https://bhock.net/context-caddy/</link>
                

                
                    <pubDate>Wed, 05 Feb 2025 00:00:00 UTC</pubDate>
                

                
                    <title>Context Caddy</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>The Answering Machine is a proof-of-concept system that I built using <strong>pre-LLM</strong> natural language processing (NLP), specifically NLTK, to produce answers to questions asked about data in plain English.</p>
<p>Looking back, this project was a great insight into what LLMs immediately allowed that was incredibly difficult before.  This project was several months of work that the openAI sdk would probably have allowed in a few weeks - and that few weeks would have been mostly frontend design and a bit of prompting.</p>
<p><strong>Try it here:</strong> <a href="http://voicequery-dev.s3-website-us-west-2.amazonaws.com/">http://voicequery-dev.s3-website-us-west-2.amazonaws.com/</a>
<strong>Github:</strong> <a href="https://github.com/hockenmaier/voicequery">https://github.com/hockenmaier/voicequery</a></p>
<p>The system uses natural language processing (NLP) to produce answers to questions asked about data in plain English.</p>
<p>It is designed with simplicity in mind—upload any columnar dataset and start asking questions and getting answers. It uses advanced NLP algorithms to make assumptions about what data you&rsquo;re asking about and lets you correct those assumptions for follow-up questions if they&rsquo;re wrong.</p>
<p>It is built entirely out of serverless components, which means there is no cost to maintain or run it other than the traffic the system receives.</p>
<h2 id="how-to">How-to</h2>
<p>On a desktop or tablet, click the link in the header to navigate to the Answering Machine. For now, it isn&rsquo;t optimized for smartphone-sized screens.</p>
<p>In order to use the Answering Machine, you can either select one of the existing datasets, such as &ldquo;HR Activity Sample,&rdquo; or upload one of your own using the homepage of the site:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    




























    



    



    





    



    





    



    






















<img  alt="Answering Machine homepage"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://bhock.net/images/answering_machine_uploads.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>To upload your own, click in the upload area or just drag a file straight from your desktop. For now, use CSV data files. Excel and other spreadsheet programs can easily save data in the CSV format using the &ldquo;File &gt; Save As&rdquo; or similar option in the menu. Each file needs a unique name.</p>
<p>When you hit the upload button, the site may not appear to change until the file is uploaded, at which point you&rsquo;ll see it appear in the box labeled &ldquo;Ask Your Data Anything&rdquo; below. Click on your file to start using it with the Answering Machine, or click the red trash can icon to delete it.</p>
<p>There are no user accounts in this system yet, so the data you upload might be seen by other users using the system. Try not to use sensitive data for now.</p>
<h3 id="asking-questions">Asking questions</h3>
<p>When you enter a dataset, you&rsquo;ll see a view that presents you with quite a bit of information:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    




























    



    



    







    





    



    






















<img  alt="Answering Machine main view"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://bhock.net/images/answering_machine_hr.png"   style="height: auto; width: 100%"   >


    
</div>

<p>The only part you need to focus on right now is the information panel. This panel lists out all the fields (columns), data types of those fields, and some sample data from a few records in your dataset:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    




























    



    



    





    



    





    



    






















<img  alt="Answering Machine info panel"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://bhock.net/images/answering_machine_info.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>You can use this panel to start to formulate questions you might have about the data. If you see number values, you might ask about averages, maximums, or other math that might otherwise take some time to calculate. If you see a date, you can ask questions about the data in certain time periods.</p>
<p>Many datasets also contain fields that only have a few specific allowed values. When the Answering Machine sees fewer than 15 unique values in any field, the data type will be a &ldquo;List&rdquo; and it lists them right out under the sample values table. You can use this type of value to ask questions about records containing those specific values. For example, in the HR dataset, you might only be interested in data where the &ldquo;Education&rdquo; field&rsquo;s value is &ldquo;High School.&rdquo;</p>
<p>Now look to the query bar to start asking your data questions:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    




























    



    



    





    



    





    



    






















<img  alt="Answering Machine query bar"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://bhock.net/images/answering_machine_query.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>The types of questions that will currently be automatically detected and answered are:</p>
<ul>
<li>Counts of records where certain conditions are true</li>
<li>Math questions such as averages, medians, maximums, and minimums</li>
</ul>
<p>These types of questions can be made specific by using qualifying statements with prepositional phrases like &ldquo;in 2019&rdquo; or adjective phrases like &ldquo;male&rdquo; or &ldquo;entry-level.&rdquo;</p>
<p>Combining these two ideas, you can ask specific questions with any number of qualifiers, such as:<br>
<em>&ldquo;What was the median salary of male employees in the engineering department 5 years ago?&rdquo;</em></p>
<p>Upon hitting the &ldquo;Ask&rdquo; button (or hitting Enter), the Answering Machine will do its best to answer your question and will show you all of its work in this format:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    




























    



    



    





    



    





    



    






















<img  alt="Answering Machine response"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://bhock.net/images/answering_machine_answer.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>The last line in the response is the Answering Machine&rsquo;s answer. In this case, it is telling you the metric you asked for with all your stipulations is <strong>6871.6 dollars.</strong></p>
<p>Moving up, you see a series of assessments that the Answering Machine has made in order to filter and identify the data you are asking about. Statements like &ldquo;Best auto-detected Numeric Subject Found: salary with column: Compensation (Monthly)&rdquo; provide a glimpse into one of the Answering Machine&rsquo;s most advanced features, which uses a selection of NLP techniques to compare words and phrases that are similar in meaning, ultimately matching things you are asking about to fields and values that actually exist in your database.</p>
<p>At the very top of the response is how the Answering Machine&rsquo;s nested grammar parsing logic actually parsed your question, with some specific pieces color-coded:</p>
<ul>
<li><strong>Green</strong> chunks indicate &ldquo;subjects&rdquo; that were detected. Subjects are what the Answering Machine thinks you&rsquo;re asking &ldquo;about.&rdquo; These should represent both the main subject and other supporting subjects in your question.</li>
<li><strong>Purple</strong> chunks are conditions. These are the things that the Answering Machine thinks you are trying to use to &ldquo;specify&rdquo; or filter data.</li>
</ul>
<p>Now that your question is answered, you might notice that some new green and purple colored bubbles have appeared in the sections of your screen labeled &ldquo;New Subjects&rdquo; and &ldquo;New Conditions.&rdquo; We&rsquo;ll call these &ldquo;lexicon&rdquo;:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    




























    



    



    





    



    





    



    






















<img  alt="Answering Machine subjects and conditions"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://bhock.net/images/answering_machine_lexicon.png"   style="height: auto; max-width: 400px; width: 100%"   >


    
</div>

<h3 id="forming-concepts">Forming Concepts</h3>
<p>If the Answering Machine already understood what you were asking and successfully matched it to fields and values in your data, you don&rsquo;t have to do anything with these. But often you will be using domain-specific lexicon, or the auto-matching algorithm simply won&rsquo;t pick the correct value. These situations are what concepts are for.</p>
<p>To create a concept, click and drag on the green or purple &ldquo;lexicon&rdquo; bubble and move it out into the blank middle area of the screen. Then click and drag the field or field value from the info-panel at the top of the screen and drop it right on top of that bubble. You&rsquo;ll see both the data bubble and the lexicon bubble included in a larger gray bubble, which represents the concept:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    




























    



    



    





    



    





    



    






















<img  alt="Answering Machine concept"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://bhock.net/images/answering_machine_concept.png"   style="height: auto; max-width: 200px; width: 100%"   >


    
</div>

<p>You can add more lexicon bubbles to this concept if they mean the same thing, but you can only use one data bubble.</p>
<p>Concepts override the Answering Machine&rsquo;s auto-matching logic. If you ask another question containing a subject or condition that is now matched by a user to a data value, that data value will be used instead of the auto-match. If the concept isn&rsquo;t working well, you can delete it by dragging all of the nested bubbles out of it either into the blank middle area or into the colored panel they originally came from.</p>
<p>Feel free to play around with new datasets and questions, and use the contact section of this site if you have comments or questions. When you ask questions or create/modify concepts, that data will automatically be saved to the server in real-time. You can close the page anytime and come back to your dataset to keep asking questions.</p>
<p>Remember that there are no user accounts, meaning you can share your dataset and work in tandem with others! But again, please do not upload sensitive data to this proof-of-concept tool as it will be available for other users to see and query.</p>
<h2 id="architecture">Architecture</h2>
<p>The Answering Machine is a purely &ldquo;serverless&rdquo; application, meaning that there is no server hosting the various components of the application until those components are needed by a user. This is true for the database, the file storage, the static website, the backend compute, and the API orchestration.</p>
<p>For the cloud nerds out there, <a href="https://martinfowler.com/articles/serverless.html">here is a great article</a> by Martin Fowler on what exactly &ldquo;serverless&rdquo; means, especially in terms of the backend compute portion, which is arguably the most valuable part of the application to be serverless. For reference, I am using Martin&rsquo;s 2nd definition of &ldquo;serverless&rdquo; here.</p>
<p>This is a high-level map of all of the components that make the Answering Machine work in its current (June 2020) state. The API gateways, CloudWatch events, and some triggers &ldquo;given for free&rdquo; by AWS are left out of this for readability:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    




























    



    



    





    



    





    



    






















<img  alt="Serverless Architecture of the Answering Machine app"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://bhock.net/images/answering_machine_architecture.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>The full suite of lambdas and persistent storage services that make up the Answering Machine.</p>
]]></description>
                

                <guid isPermaLink="false">tag:bhock.net,2019-07-03:/answering-machine/</guid>

                
                    <link>https://bhock.net/answering-machine/</link>
                

                
                    <pubDate>Wed, 03 Jul 2019 00:00:00 UTC</pubDate>
                

                
                    <title>The Answering Machine</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>First Ten is an educational app containing information about the U.S. Bill of Rights, accessible on Google devices and smart speakers. It uses a VUI (voice user interface) only, meaning there is no visual way to interact with the app.</p>
<p><strong>Try it here:</strong> <a href="https://assistant.google.com/services/a/uid/00000036f6a580ed">https://assistant.google.com/services/a/uid/00000036f6a580ed</a>
<strong>Github:</strong> <a href="https://github.com/hockenmaier/billofrights">https://github.com/hockenmaier/billofrights</a></p>
<p>Like Alexa skills, Google actions can be accessed through search or by simply asking for their names in Google Home smart speakers. Ask your Google Home or Android device, &ldquo;Can I speak to First Ten?&rdquo; in order to try it.</p>
<h3 id="architecture">Architecture</h3>
<p>First Ten&rsquo;s backend is built in the serverless AWS services Lambda and DynamoDB, and its frontend—the engine that parses your voice into different &ldquo;intents&rdquo; and parameters—is built on Google&rsquo;s Dialogflow.
<div style="text-align: center; margin-bottom: 1rem;">
    




























    



    



    





    



    





    



    






















<img  alt="Serverless Architecture of the First Ten app"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="https://bhock.net/images/first_ten_architecture.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>
</p>
<hr>
]]></description>
                

                <guid isPermaLink="false">tag:bhock.net,2018-05-19:/first-ten/</guid>

                
                    <link>https://bhock.net/first-ten/</link>
                

                
                    <pubDate>Sat, 19 May 2018 00:00:00 UTC</pubDate>
                

                
                    <title>First Ten</title>
                
            </item>
        
    </channel>
</rss>
