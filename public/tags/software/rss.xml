













    
        
    

    
        
    

    

    
        
    







    

    






<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"  xml:lang="en-us"  xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        
            

            
                
            

            
                <link href="http://localhost:1313/tags/software/" rel="self" type="text/html"/>
            
        
            

            

            
                <link href="http://localhost:1313/tags/software/rss.xml" rel="alternate" type="application/rss+xml"/>
            
        

        

        

        <description>Recent content</description>

        
            <language>en-us</language>
        

        
            <lastBuildDate>2025-05-24 00:00:00 +0000 UTC</lastBuildDate>
        

        <link>http://localhost:1313/tags/software/</link>

        

        <title>Software · Tags · hockenworks</title>

        

        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>Recently I read the <a href="https://ai-2027.com/scenario.pdf">AGI 2027 paper</a>. I was surprised to see Scott Alexander&rsquo;s name on this paper and I was doubly surprised to see him do his <a href="https://www.dwarkesh.com/p/scott-daniel">first face reveal podcast about it with Dwarkesh</a></p>
<p>On its face this is one of the most aggressive predictions for when we will have AGI, at least the new definition of AGI which is something that is comparable or better than humans at all non-bodily tasks, that I have read. Even as someone who has been a long believer in Ray kurzweils Singularity predictions, 2027 strikes me as very early.</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      






























    













    



    






















<img  alt="AI 2027"   class="rounded-4 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/ai-2027png"    >


      






























    













    



    






















<img  alt="Singularity Is Near"   class="rounded-4 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/The-Singularity-Is-Near.JPG"    >

</div>
</div>

<p>I won&rsquo;t get into a full summary here, but the core argument comes down to the same one I was making in my <a href="/on-ai-software-development">original post on AI software development</a></p>
<ul>
<li>which is that, once AI agents are able to replace software engineers, instead of just assisting them, it doesn&rsquo;t matter how they are doing another realms, because they will simply be able to improve on themselves and their own software at such a rate that the difference between the time of automating software engineering jobs and the time of automating all other jobs is negligible.</li>
</ul>
<p>So I figured it was a good time to update on where I think AI is actually at at software engineering tasks.</p>
<p>&mdash;Notes&mdash;</p>
<p>Add links to my chat with 03 about the refund feature,</p>
<p>Add links to videos about co-pilot agents as well as codex as the state of the art actual software developers</p>
<p>Talk a little bit about my experience using cursor and what a disappointment it was for a code base as unique as mine</p>
<p>Add notes about cursor not handling context any more easily than context caddy - and that might be a bit of a stumbling block</p>
<p>First feature that sonnet 3.7 consistently failed at was simply having the compactors add ball value accumulation of compacted balls</p>
<p>Your request has been blocked as our system has detected suspicious activity from your account.If you believe this is a mistake, please contact us at <a href="mailto:hi@cursor.com">hi@cursor.com</a>.(Request ID: 997e94bb-34ee-44c0-b0aa-15bb6822add6)</p>
<p>LOL</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-05-24:/on-ai-software-development-2/</guid>

                
                    <link>http://localhost:1313/on-ai-software-development-2/</link>
                

                
                    <pubDate>Sat, 24 May 2025 00:00:00 UTC</pubDate>
                

                
                    <title>On AI Software Development, 2025 Edition</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<div style="text-align: center; margin-bottom: 1rem;">
    




























    



    



    





    



    





    



    






















<img  alt="this is a robot"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/ai-software-dev.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>Lots of chatter right now about AI replacing software developers.</p>
<p>I agree - AI will take over software development. The question is: what work will be left when this happens?</p>
<p>Some considerations:</p>
<ul>
<li>Benchmarks for the best LLMs still put them solidly in the &ldquo;bad at programming&rdquo; category, scoring in the 5th percentile of human programmers on common tests. Meanwhile, LLMs score in the 80th-95th percentile for law exams and 85th–100th for psychology, statistics, and many other less technical fields. More scores available in the &ldquo;simulated exams&rdquo; section of <a href="https://openai.com/research/gpt-4">https://openai.com/research/gpt-4</a>.</li>
<li>Engineers have been using language models like tabnine and copilot as &ldquo;super-stackoverflow&rdquo; style code assistance years before chatGPT released. This means much of the velocity increase we might expect from current LLMs&rsquo; ability to write code has already been &ldquo;priced in&rdquo; to the market.</li>
<li>Many of the trends making software development more costly are growing, not shrinking: Systems are becoming more distributed. The cloud lowered infrastructure costs but made applications more complex. We&rsquo;re making more and deeper integrations among disparate systems. Auth is becoming more secure and thus complex (managed identity, MFA, etc).</li>
</ul>
<p>Github copilot chat and other LLM dev tools are speeding up the rote stuff. I’ve seen it in my own work.</p>
<p>And I really do believe new AI models will do more than just the basics, maybe in the next couple of years. Even precluding &ldquo;AGI&rdquo;, the trend we are on is that more and more work is automatable, and engineers, especially more junior ones - are going to have to shift focus away from algorithmic work that AI can do.</p>
<p>But by the time our neural nets are &ldquo;good enough&rdquo; at building software to make it significantly cheaper to build, I doubt this trend will make the news. Everything else gets automated too.</p>
<p>These are my thoughts at what seems to be the beginning of the next AI revolution in early 2024. I plan to revisit this topic and see if I&rsquo;m right in future posts.</p>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2024-01-24:/on-ai-software-development/</guid>

                
                    <link>http://localhost:1313/on-ai-software-development/</link>
                

                
                    <pubDate>Wed, 24 Jan 2024 00:00:00 UTC</pubDate>
                

                
                    <title>On AI Software Development</title>
                
            </item>
        
    </channel>
</rss>
