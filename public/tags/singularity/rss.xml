













    
        
    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    

    

    
        
    







    

    






<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"  xml:lang="en-us"  xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        
            

            
                
            

            
                <link href="http://localhost:1313/tags/singularity/" rel="self" type="text/html"/>
            
        
            

            

            
                <link href="http://localhost:1313/tags/singularity/rss.xml" rel="alternate" type="application/rss+xml"/>
            
        

        

        

        <description>Recent content</description>

        
            <language>en-us</language>
        

        
            <lastBuildDate>2025-07-14 00:00:00 +0000 UTC</lastBuildDate>
        

        <link>http://localhost:1313/tags/singularity/</link>

        

        <title>Singularity · Tags · hockenworks</title>

        

        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I came across this tweet today that was surprisingly contentious. Maybe not so surprising given the state of Twitter, but still:</p>
<p><a href="https://twitter.com/AdamRackis/status/1762321041899012307">https://twitter.com/AdamRackis/status/1762321041899012307</a></p>
<p>On the face of it, “people get twisted in their relationship with work” seems like a reasonable take. Stop complaining—you are making 16x the median salary in this country. Just do the boring job with the toxic team.</p>
<p>Let’s stop and think about this for a second. The original poster (OP from now on) is making $800K annually due to the appreciation of Spotify stock. An obscene amount of money? Maybe, maybe not. I do not have the typical hang-ups about the wealthy or ultra-wealthy. I don’t see this world as a zero-sum game, and I think the richest people out there have usually done some amazing things, especially in countries like the US where most wealth is not old wealth.</p>
<p>But there is a difference between founding a company you’re passionate about, which goes on to become incredibly valuable, and working for someone else doing a job you think is boring in order to join the 1%. In this article, I’m talking about the latter.</p>
<p>I propose this core question for this type of person: Is this large income worth doing a job you find boring, or working with people you feel are toxic? I would say no. Absolutely not. OP is clearly regretting how he’s spending his time at work. He should look for something to do that he values, even if it pays a quarter as much as he gets now. Or less!</p>
<h2 id="the-hedonic-treadmill">The Hedonic Treadmill</h2>
<p>There’s an often misquoted study from ~2010 that personal income beyond about $75K (presumed to cover basic necessities with a comfortable overhead) does not equate to further happiness. This number is actually about right when it comes to simple reported happiness, which has more to do with the hedonic treadmill than anything else. But the study in question was also measuring reported “life satisfaction” as surveyed, which did not stop increasing with income. Of course, “life satisfaction” is a fraught survey metric as well, as it might actually measure a perceived comparative number with one’s neighbors (we’ll get to this later).</p>
<p>But whatever the proper measure of happiness or satisfaction is, there is a great deal of logic to thinking its relationship with income looks like this:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="happiness income curve"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/treadmill-graph.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>As in: there are diminishing returns to incremental income. Not a revolutionary idea. It’s obvious. But it also means that somewhere along this curve is the often-quoted $75K, and somewhere far to the right is OP’s $800K. And the curve between those points is probably pretty flat.</p>
<p>What could OP get in return for moving to the left along this flat section of the curve? Eight hours of time per workday, at least, that he finds incrementally more valuable. How much do you think those 8 hours could improve his life satisfaction on their own happiness/hours curve?</p>
<p>This is where the real paradox comes in. Gaining wealth is supposed to make your time more valuable. You choose to get more services, have a housekeeper, maybe even a private chef. But if those things actually indicate a person values their time more highly than someone poorer, how come they would even consider sacrificing most of that time doing something they find boring, or with people they find annoying? Just to maintain their position along the flat section of the curve?</p>
<p>Maybe they aren’t prioritizing happiness at all.</p>
<h2 id="keeping-up-with-the-joneses">Keeping up with the Joneses</h2>
<p>My argument so far would be absolute blasphemy to most of the $500K+ salary people who don’t have much fun at work. Let’s talk about their two most common counterarguments:</p>







<div class="paige-quote">
<blockquote class="blockquote"><ol>
<li><em>&ldquo;Work should be a sacrifice, and more money means more security for my family.&rdquo;</em></li>
</ol>
</blockquote>


</div>

<p>This is noble. It’s also way too self-sacrificial for the extremely wealthy first-world people we’re talking about. You’re making $800K. There is not a salary sacrifice in the world that will make your family “insecure.”</p>
<p>And what pattern does this even establish? You’re going to choose to be unhappy for most of your waking hours so that you can guarantee your children will be able to do the same? What are you actually working for if not you or anyone else being able to actually enjoy themselves?</p>







<div class="paige-quote">
<blockquote class="blockquote"><ol start="2">
<li><em>&ldquo;But I could make this crazy money and then retire in 5 years.&rdquo;</em></li>
</ol>
</blockquote>


</div>

<p>Now this is a good argument! You could indeed retire in 5 years after making $800K per year and then spend your time with family or pursue passion projects! The problems here are twofold:</p>
<p><strong>First</strong>, nobody does this. Instead, they spend more money. Of course, some of it will be saved, but the main thing that happens when people find themselves with far more money than needed for their family’s security is that they spend it. Bigger houses, more trips, elite schools for the kids. These make you feel well-off compared to your neighbors but don’t push you much higher on that flat curve.</p>
<p><strong>Second</strong>, people find value in being useful. There’s a reason why so many struggle in retirement. Even with a rigid FIRE plan, you’ll still want to work afterward on something interesting. So why not find that now?</p>
<p>What’s actually happening? Lifestyle creep. I think this is 90% of why people feel they could never work on something more fun or meaningful for less money. They’ve already started to spend their new money, and now losing those things would hurt more than gaining them felt good. That damn hedonic treadmill.</p>
<h2 id="closing-thoughts">Closing Thoughts</h2>
<p>I’m asking you to think deeply about what you value. Money is a means to an end. The way you spend your time, including work itself, has true value. Value your own time as much as your spending habits suggest you do. This is the right logic for your well-being.</p>
<p>My last thought on this:</p>
<p>I’m obsessed with AI and the technological singularity. It’s a healthy time to step back, reflect on the fundamental values driving our behavior, and make changes. Wouldn’t it be silly to spend most of our waking hours working miserably on meaningless things, only to arrive in the second half of your life in a world of true abundance?</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-07-14:/the-treadmill/</guid>

                
                    <link>http://localhost:1313/the-treadmill/</link>
                

                
                    <pubDate>Mon, 14 Jul 2025 00:00:00 UTC</pubDate>
                

                
                    <title>The Treadmill</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>Recently I read the <a href="https://ai-2027.com/scenario.pdf">AI 2027 paper</a>. I was surprised to see Scott Alexander&rsquo;s name on this paper and I was doubly surprised to see him do his <a href="https://www.dwarkesh.com/p/scott-daniel">first face reveal podcast about it with Dwarkesh</a></p>
<p>On its face this is one of the most aggressive predictions for when we will have AGI (at least the new definition of AGI which is something that is comparable or better than humans at all non-bodily tasks) that I have read. Even as someone who has been a long believer in <a href="https://en.wikipedia.org/wiki/The_Singularity_Is_Near">Ray Kurzweil&rsquo;s Singularity predictions</a>, 2027 strikes me as very early. I realize that Kurzweil&rsquo;s AGI date was also late 2020&rsquo;s and 2045 was his singulartiy prediction - 2027 still feels early to me.</p>
<div class="paige-row-wide">
  <div style="display:grid; grid-template-columns:repeat(2, minmax(0,1fr)); gap:15px;">
      































    













    



    























<img  alt="AI 2027"   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/ai-2027.png"    >


      































    













    



    























<img  alt="Singularity Is Near"   class="rounded-3 w-100"  crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/The-Singularity-Is-Near.jpg"    >

</div>
</div>

<p>I won&rsquo;t get into my full take on AI 2027 here, but the core argument comes down to the same one I was making in my <a href="/on-ai-software-development">original post on AI software development</a></p>
<ul>
<li>which is that, once AI agents are able to replace software engineers, instead of just assisting them, it doesn&rsquo;t matter how they are doing in other realms, because they will simply be able to improve on themselves and their own software at such a rate that the difference between the time of automating software engineering jobs and the time of automating all other jobs is negligible.</li>
</ul>
<p>So I figured it was a good time to update on where I think AI is actually at at software engineering tasks. I&rsquo;ve had the chance to test many of the latest AI software development tools and models, and we have come a long way since my original post.</p>
<p>I have been doing a lot of development with AI for the last few years, especially the last couple of months on parental leave building the game in this site. And they are good! But the core problems with these models for software engineering are:</p>
<ol>
<li>They can&rsquo;t deal well with contexts over 30K tokens or so (even the best models with supposed millions of token windows).</li>
</ol>
<p>This means the actual developer (me and you) are the ones picking specific files and functions to send into the context window, lest we confuse the model. This is arduous unless the codebase is small enough to fit entirely into the context window. That&rsquo;s exactly what I think is going on with most of the new &ldquo;vibe coded&rdquo; projects we see showing impressive results - these are just tiny POC apps that haven&rsquo;t hit more than a few thousand lines of code yet. For context, most serious enterprise apps containing the detailed logic and edge cases real use cases require are in the millions or hundreds of millions of lines of code.</p>
<ol start="2">
<li>They are biased to be &ldquo;advisors&rdquo; as well as &ldquo;doers&rdquo;</li>
</ol>
<p>This is just annoying, and I hope it gets trained out soon. Models just really <em>want</em> you to be doing everything, and to act themselves as an advisor. It makes sense with one of the main sources of code training data being from Stackoverflow and other blogs, where developers can never seem to rid themselves of a pseudo-condescending &ldquo;you should have been able to read the docs and learn this yourself&rdquo; tone. It&rsquo;s also just a pattern exhibited by people in general - more often than not, especially in the corporate world, people are trained to be the &ldquo;coaches&rdquo; rather than the &ldquo;worker bees&rdquo;. One reason why things get done so slowly in big political companies sometimes.</p>
<p>&mdash;Notes&mdash;</p>
<p>Add links to my chat with 03 about the refund feature,</p>
<p>Add links to videos about co-pilot agents as well as codex as the state of the art actual software developers</p>
<p>Talk a little bit about my experience using cursor and what a disappointment it was for a code base as unique as mine</p>
<h1 id="cursor">cursor</h1>
<p>Add notes about cursor not handling context any more easily than context caddy - and that might be a bit of a stumbling block</p>
<p>First feature that sonnet 3.7 consistently failed at was simply having the compactors add ball value accumulation of compacted balls</p>
<p>Your request has been blocked as our system has detected suspicious activity from your account.If you believe this is a mistake, please contact us at <a href="mailto:hi@cursor.com">hi@cursor.com</a>.(Request ID: 997e94bb-34ee-44c0-b0aa-15bb6822add6) LOL</p>
<p>o3&rsquo;s performance on net new &ldquo;gear&rdquo; feature for the hockenworks ball machine:</p>
<p>Gear Prompt: <a href="https://chatgpt.com/c/683755d0-fbec-8006-9c8b-c77bbe951211">https://chatgpt.com/c/683755d0-fbec-8006-9c8b-c77bbe951211</a>
Clean code point for recreation with other models - master just before &ldquo;gear&rdquo; branch was created</p>
<p>Today, you will be making a new drawable object for our physics web game. The gear will be a physical object that balls collide with, similar to the compactor, but simpler (No on collision events, just continuous rotation). When balls fall into its grooves, they will be moved around by physics. Gears will rotate at one full revolution every 30 seconds, which should be configurable in the App config.</p>
<p>Placing gears is a bit simpler than other objects, though has the same structure:</p>
<p>Desktop: One click to create a preview that then follows the mouse location, second click finishes and leave the gear centered there. Right click before the finish cancels as normal.</p>
<p>Mobile: Touchstart shows the preview , touchmove has the preview follow the touch location, and touchend finishes. However, there should be no “is Valid distance threshold” of 25 px that the gear must be outside of to place - the gear will always be placed on a touch event.</p>
<p>All normal pulse, delete, and refund effects apply. Both gears cost 750 coins.</p>
<p>The image representing the gear is called gear-30.png (it has 30 teeth), and I have vertices representing its physical shape for the matter body, which I will update an array you leave blank in your new gear.js code like this:</p>
<p>const GEAR_VERTICES = [
[0, 0],
];</p>
<p>The gear should be drawn in 2 types, using 2 toggle buttons: one that turns clockwise and one counterclockwise. You should represent these types and persist them similarly to how the launcher has multiple types.</p>
<p>The toggle button images are gear-clockwise-mode.png and gear-counterclockwise-mode.png</p>
<p>When making new Drawables, you must make all necessary changes around the codebase.</p>
<p>The types of things that you should look for and make sure to change, are:
-UI elements
-UI interactions with other elements
-How to Draw the thing
-How to do second-actions like the curve line bezier
-How to delete
-How hover, hold, and pulse works
-What is in the preview vs the finished drawn item
-Where cost and icons go in the code
-Any new variables in App config
-How data is persisted and deleted from persistence, including any new types to encode somewhere
-All interactions with other files, and make sure to call out that shared files like line-interaction and notifications and powerup-progression
-All desktop AND mobile controls for all actions
-Any new files needed, and their inclusion in baseof.html</p>
<p>As well as anything extra any specific drawable like the gear requires.</p>
<p>Present all code changes as copyable blocks, noting the function they replace or the lines of code they come immediately between.</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-07-07:/on-ai-software-development-2/</guid>

                
                    <link>http://localhost:1313/on-ai-software-development-2/</link>
                

                
                    <pubDate>Mon, 07 Jul 2025 00:00:00 UTC</pubDate>
                

                
                    <title>On AI Software Development, 2025 Edition</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I have long been of the mind that LLMs and their evolutions are truly thinking, and that they are on their way to solving all of the intellectual tasks that humans can solve today.</p>
<p>To me, it is just too uncanny that the technology that seems to have made the final jump to some degree of competence in tasks that require what is commonly understood as &ldquo;thinking&rdquo; or &ldquo;understanding&rdquo;, after a long string of attempts and architectures that fail these tasks, is a type of neural network. It would be much easier to argue away transformer models as non-thinking stochastic parrots if we had happened to have had success with any other architecture than the one that was designed to mimic our own brains and the neurons firing off to one another within them. It&rsquo;s just too weird. They are shaped like us, they sound like us in a lot of ways, and it&rsquo;s obvious they are thinking something like us too.</p>
<p>I am not saying they are as good as us yet, though, for a few small reasons and one big one.</p>
<h2 id="the-limitations">The Limitations</h2>
<p>Current frontier &ldquo;thinking&rdquo; models are not AGI in the modern definition. They can&rsquo;t do every task humans can do intellectually (IE without a body, which I will get to) for several reasons:</p>
<ol>
<li>
<p>Looping/Recursive reasoning:
This was a huge problem for early transformers that had to output in one shot, and the examples were obvious. This one has been essentially solved via thinking models like o1, and now o3, gemini and grok thinking models, and many more. That was a huge unlock and a huge boon for applications like programming where there is lots of nested recursion of logic that has to occur to find a reasonable solution.</p>
</li>
<li>
<p>Memory and context:
Context windows get larger all the time, but this limitation still is not solved. Just adding a bunch of tokens into a context window doesn&rsquo;t get you much when 2 million token models lose coherence after about the first 40,000 - which they do, and which every programmer working with anything but a tiny codebase intuitively understands. But this one too will largely be solved soon, if not through architectures that actually update their weights, it&rsquo;ll be solved through nuanced memory systems that people are actively developing on top of thinking models.</p>
</li>
<li>
<p>Size:
This is basic, but most of the models we can interact with today are still working with an order of magnitude fewer neural synapses than human brains. It could very easily be that, even with the other problems solved, we just need bigger electronic brains to match the size of our meat ones. It certainly <em>feels</em> like some of the ways LLMs fail today sort of come down to &ldquo;not enough horsepower&rdquo; types of issues.</p>
</li>
<li>
<p><strong>Vision</strong>:
And this one might sound funny to someone that is paying attention to AI in particular, because GPT-4 with vision launched something like 2 years ago now. And it has been impressive for a long time, able to do things like identify what objects are in an image, where an image is from, etc: things most humans can&rsquo;t do glancing at an image, that seem super-human.</p>
<p>But the vision itself is not “good” vision. It cannot really pick out small important details, and it still behaves in many ways like vision recognition models have for years now. Now that we have a model that has both thinking and image input and editing at every step, the o3 and o4-mini series that recently released, we can really start to see the limitations in vision. Let me take you through 2 examples that represent the 2 types of failure modes that result from these not having true image understanding, yet.</p>
<p>My thesis today is that this is the key limitation that is not going to be overcome &ldquo;by default,&rdquo; but that it will be overcome.</p>
</li>
</ol>
<h2 id="proof-the-vision-is-not-there-yet">Proof the Vision is Not There Yet</h2>
<p>Each release from the major providers steadily knocks away my intelligence tests, which I admit are mostly programming oriented, but the ones that they can never really dent are the spatial reasoning ones - where a model really has to think about images in its head or use an image provided for detailed work.</p>
<h3 id="simple-3d-modeling-with-frontier-ai-models">Simple 3D Modeling with Frontier AI Models</h3>
<p>Every major model release, <a href="/3d-modeling-with-ai">I test what models can do with OpenSCAD</a>. I won’t get technical about it here, but OpenSCAD is a CAD program (Computer Aided Design - think 3D modeling for engineers, not the artistic kind) that is defined entirely through a programming language vs the typical mouse strokes and key presses that software like SolidWorks or AutoCAD depend on.</p>
<p>This makes OpenSCAD the perfect test platform for a model that inputs and outputs text primarily. I can describe a 3D model I want, and the model can output text that renders into a 3D model.</p>
<p>As amazing as LLMs are at scripting in normal programming languages, they have never been good at OpenSCAD. See my link above for GPT-3.5 and GPT-4 trying to model an incredibly simple object. That acorn was about as complex as GPT-4 could get without really falling down.</p>
<p>Here is OpenAI&rsquo;s o3’s attempt to make a standard 2x4 Lego Brick:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="an OpenSCAD render"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/o3-lego.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">o3&#39;s model left, real Lego brick right</span>
    
</div>

<p>This was the easiest object I tested, and o3 does a decently good job. It grabbed the correct dimensions online and, using its inherent training data of what a 2x4 Lego block is, applied those dimensions into a mostly coherent object. It has one major flaw, which you can see on the underside as I have the image rotated - it drew two lines through two of the cylinders. My guess is that this is its interpretation of the supports in the middle of the actual Lego brick, that connect but don&rsquo;t run through the center cylinder.</p>
<p>Now for a harder test: a simple engineering part that&rsquo;s definitely not in its training data, because it is my own design. I printed this for a robotics project more than a decade ago, and had it sitting around in my 3D printer storage drawer.</p>
<p>It&rsquo;s a bit of a weird part - a pinion with a smooth section and an 11-tooth gear of equal diameter, and a hole in the center with a slightly raised wall. This is the kind of part that an engineer well versed in AutoCAD or SolidWorks can produce in just a few minutes, but which requires attention to detail and a conceptual model of how parts fit together.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="an OpenSCAD render"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/o3-pinion.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">o3&#39;s model left, real part right</span>
    
</div>

<p>This is where you can see how these models fall apart. o3 immediately gets that it&rsquo;s a pinion, that it has a hole in the middle, and that it has a smooth section on the bottom and a gear on top. But the execution is nowhere close to workable, from most major to least (in my opinion):</p>
<ul>
<li>There are two gears (unknown as to why or if this is intentional, o3 explained one as a &ldquo;grooved ring&rdquo; - whatever that means)</li>
<li>The gear teeth are concave - whereas the rounded sharp tooth shape is clear in the image</li>
<li>There are 10 teeth, not eleven - which seems trivial, but it&rsquo;s indicative of a real flaw that messes up all complex models I throw at AI - where LLMs make an assumption like what number of teeth is &ldquo;likely,&rdquo; rather than looking at the image in detail and counting them.</li>
<li>There is clearly an attempt at the raised wall around the top hole, but it&rsquo;s far too big.</li>
<li>The height of the smooth base section and gear sections are equal in the real part, but o3 makes the gear more than 3x thicker than the base.</li>
</ul>
<h3 id="map-reading">Map Reading</h3>
<p>Here&rsquo;s another great example of what I mean when I say that frontier models have bad vision.</p>
<p>I recently gave this question to the latest thinking image model, o3: &ldquo;Here&rsquo;s an image from Google Maps of the block I live on between the avenues of Burbank, Hazeltine, Oxnard, and Van Nuys. What is the longest continuous loop I can walk within the neighborhood without crossing my path or touching one of the avenues? This square is 1/2 mi on each side&rdquo;</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="the uploaded map"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/o3-struggle-map-new.png"   style="height: auto; max-width: 400px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">The image uploaded with this query</span>
    
</div>

<p>O3 thinks for 4 minutes about this question, zooming in to various parts of the map countless times to form the route. And then it fails on the first step, suggesting starting at Tiara and Stansbury, which do not intersect on the map. Any person looking at this image could tell that is true in just a few seconds.</p>
<p>This is what I mean when I say these things have bad vision - and this is the best model from the lab I think has the best vision. Vision is not about being able to identify millions of different objects, <a href="https://www.image-net.org/">ImageNet-style</a>. It&rsquo;s about seeing the detail and paying attention to the right thing. Here in this map, that means looking roughly at the lines representing Stansbury and Tiara, looking at where they would intersect, and seeing they do not.</p>
<p> </p>
<p>Though getting AI models to read maps and create 3D models from code may not be on everyone&rsquo;s rubric, any UX developer that has worked with a frontier AI knows what I&rsquo;m saying intuitively. This is likely just as true for any role heavily leaning on visual information. There is a difference between generating some Tailwind code that spits out a standard UI and getting to the level of complexity that the AI starts to need to look at screenshots in detail and know the relative position and orientation of components, or see small details. They just.. don&rsquo;t do that yet.</p>
<h3 id="non-frontier-ai-models">Non-Frontier AI Models</h3>
<p>A common retort to this argument might be &ldquo;Well Brian, you&rsquo;re using the wrong type of model.&rdquo;</p>
<p>But believe me, I try essentially everything I can get my hands on, and like non-LLM AI models in other domains, other than being incredibly limited in application, these models are simply not good at vision, either. Here&rsquo;s an image of a 3D model generated by Zoo CAD, a company doing text and image to 3D, which was, when I printed it back in January at least, state of the art in this domain:</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="My Flipper Zero and 3D Printed Clone"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/flipper-3d.jpg"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">My Flipper Zero (left) and its 3d-printed clone (right)</span>
    
</div>

<p>The input to the model was a picture I took of my <a href="https://flipperzero.one/">Flipper Zero hacking toy</a>. The 3D print on the right is of the 3D model it produced, with the only modification on my part being to scale it.</p>
<p>I have long awaited an easy way to &ldquo;3D scan&rdquo; parts from the real world into software. This would make so many of my DIY printing jobs around the house much easier - and it gets us one step closer to the dream of teleportation.</p>
<p>And I was impressed when I first saw this output - it was one of the best of my attempts with this AI tool. Feature-wise, it did a pretty good job of capturing the main facets of my Flipper Zero. But it&rsquo;s just too obviously not good enough: dimensions are all wrong, there is hallucinated symmetry all over the place, and small details are missed everywhere. One of the reasons I printed this model was just to get a real feel for how similar it is to the Flipper when scaled correctly, and it just becomes obvious that this is not a useful technology yet when you hold both of them in your hands.</p>
<p>My prediction is that frontier models will get there before purpose-trained models like the one that cloned my Flipper Zero. This has been the reality across most other domains of AI. Now that we have general-purpose AI models that have started to encapsulate a working, if not complete, conceptual model of the world, they are starting to outperform all of the smaller purpose-built models of the last decade.</p>
<p>And this will be good for the general capability of the AI industry: It&rsquo;s a much better outcome to have a few general-purpose models that can do fine visual work, that can be prompted and orchestrated by people working in different domains, than it is to need an AI lab or startup to train a specific model for every task. It&rsquo;s the same reason I believe humanoid robots are going to win over purpose-built ones in the long run: We can&rsquo;t predict what users will want their robots to do, and our world is built for humans to operate in it - therefore the most capable robots will be shaped generally like humans.</p>
<p>So how will frontier models get good at visual tasks, if they have such bad vision right now? I think the answer to that question also involves humanoids.</p>
<h2 id="the-humanoids">The Humanoids</h2>
<p>What I think is going on in these examples of frontier model vision failures is that we have a limitation in training data (duh!) - but that isn&rsquo;t because there aren&rsquo;t a lot of images and videos on the internet, it&rsquo;s because there is so much more information in the average image than there is in the average chunk of text, and a lot more of that information is irrelevant to any given question.</p>
<p>When I say that we have a limitation on training data, I&rsquo;m not in the typical camp of &ldquo;well, then transformer neural nets are obviously stupid because I was able to understand this thing without training on terabytes of data from the internet&rdquo;. This has always been a bad take because the average human trains on petabytes, not terabytes of data, and that data is streamed into their brains mostly in the form of images. I am also not in the camp of thinking that this means that the data &ldquo;just doesn&rsquo;t exist&rdquo; to get these models to AGI in the visual dimension. It so clearly does exist, and it exists so abundantly that a unique image stream can be sent to each of the billions of human brains, and they all learn the same principles that let them immediately identify the mistake that the cutting-edge thinking vision model made after 4 minutes of rigor.</p>
<p>Not only does the data exist: We never actually had a data problem in AI in the first place. We have an instruction problem. That doesn&rsquo;t mean model architecture or data massaging really, it means that we need to plug our models into the real world where all the data streams exist. I believe this will come first in the form of robots with cameras on them, the first of which is happening en masse via Tesla full self-driving AI, and I&rsquo;m sure those vision neural nets are quite insanely capable compared to what we see in the consumer transformer vision models. But the real leap probably comes when we get to humanoid robots walking around collecting and learning from vision data every day - and learning from actions they take in the real world.</p>
<p>If you’ve ever tried to get concrete actions to take based on a vision-transformer’s outputs, you will know it’s hard. I never posted about it, but I did a small project with a friend a year or two ago, trying to get automated QA working on web software, and we failed in a lot of different ways. I am very impressed that the big labs are starting to crack <a href="https://docs.anthropic.com/en/docs/agents-and-tools/computer-use">computer use</a> - because getting an LLM to give specific coordinates or elements to click on is the same type of challenge I was testing above. But it&rsquo;s no wonder these computer use applications are still very inaccurate.</p>
<p>Letting transformer-based agents control robots will be a much harder problem of a similar type. Not only does it require attention to detail, but now the images are in 3D, they come at you many times per second, and actions need to be produced as quickly. But my prediction is that we will brute force this, and it will work &ldquo;well enough&rdquo; for enthusiasts and niche industrial use cases to benefit from humanoid robots. And that&rsquo;s the takeoff point for true vision, as we all intuitively understand it. Releasing humanoids at scale (and cars, to some extent) are when we really unleash the datastream that&rsquo;s needed to get models that can see as well as you or I can. This is probably one reason why many AI companies and labs are pushing them so hard - they also understand the data they collect will be more valuable than the money paid for the first units.</p>
<p>Once we have a few hundred thousand humanoids roaming around early adopters&rsquo; houses, we will start to see AI models that can use OpenSCAD and Google Maps. And, conveniently, that&rsquo;s also the missing capability that will make the humanoids really useful. We have interesting years ahead of us.</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-06-16:/vision-is-the-last-hurdle-before-agi/</guid>

                
                    <link>http://localhost:1313/vision-is-the-last-hurdle-before-agi/</link>
                

                
                    <pubDate>Mon, 16 Jun 2025 00:00:00 UTC</pubDate>
                

                
                    <title>Vision is the last hurdle before AGI</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>I&rsquo;m <a href="/about-me">Brian Hockenmaier</a>, and this site is full of things I build and write about. I love making games and things with VR and AI. And I love DIY projects, especially ones involving programming, engineering and 3D modeling. Some of this has been cross or back-posted from my <a href="https://www.thingiverse.com/hockenmaier/designs">thingiverse</a>, <a href="https://github.com/hockenmaier">github</a>, <a href="https://www.linkedin.com/in/hockenmaier/">linkedin</a>, and other places, but it all lives here permanently.</p>
<p>This is an evolution of <a href="old-site/index.html">my previous site last updated in 2022, which I still keep inside this one</a> for posterity and for the AIs of the future to know more about me. I like it not because of the content as much as because it was a fully custom js and html site with no framework&hellip; and I think it&rsquo;s sort of fun and funny that it was like this.</p>
<p>All work and opinions here are my own, not my employer&rsquo;s.</p>
<h1 id="why-im-making-it">Why I&rsquo;m making it</h1>
<p>I&rsquo;m creating this website in 2025 after starting a family as well as my first full-time role in AI. It&rsquo;s an effort to clean up my website&rsquo;s focus, move several disparate collections into one place, and emphasize what I truly care about. I wanted it to be easier to add content, CMS style, and I wanted a space to occasionally post written content, too.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="the hockenworks homepage"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/hockenworks.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">This webpage, if you hadn&#39;t noticed</span>
    
</div>

<p>A big reason I&rsquo;m doing this now is that, after listening to the Dwarkesh podcast with Gwern, I was convinced I really should have more of a record for future AIs to learn about me. I really don’t have a social media presence, nor do I want one, and over the years I have had a lot of projects and writing that I have unnecessarily kept private. AGI or not, there are non-artificial intelligences that may be interested one day. Talking to you, Alice :) When I started this website, your cousin Lily kept asking where you were and didn&rsquo;t seem to get the concept that you currently occupied the same space as Kaitlin.</p>
<p>I love some of the 2010s era blogs, and though mine is not going to be nearly as longform, nearly as focused on prose, or nearly as articulate, two of the sites I&rsquo;m trying to take inspiration from are <a href="https://slatestarcodex.com/about/">Slate Star Codex</a> and <a href="https://gwern.net/about">Gwern&rsquo;s website</a> which are definitely advising on style here. Other than the fact that mine is also a game.</p>
<hr>
<h1 id="etymology-of-hockenworks">Etymology of &ldquo;hockenworks&rdquo;</h1>
<p><strong>Hockenmaier</strong> is a great name. I&rsquo;ve always loved it. Not just because it’s unique and has my favorite number of letters, but because of its meaning, at least my family’s “folk-etymology” for it.</p>
<p>You have:</p>
<blockquote>
<p><strong>Hocken</strong></p>
</blockquote>
<p>Which can roughly translate to “sitting down, squatting, settling, idling”.</p>
<p>And then you have:</p>
<blockquote>
<p><strong>Maier</strong></p>
</blockquote>
<p>Which has many different spellings, and ours has southern German roots, but all &ldquo;Meyer&rdquo; names come from the latin root &ldquo;maior&rdquo; meaning steward, administrator, or more generally &ldquo;worker&rdquo;</p>
<p>My family often puts these two ideas together as &ldquo;Lazy Worker,&rdquo; which is very on-brand for our sense of humor, but I think it&rsquo;s not just funny, but true.</p>
<p>“Lazy Worker” is perfect for someone who wants to get a lot done, especially in software engineering. We only have so many hours, and the best lives are lived restricting the number of hours spent on work that isn&rsquo;t done with people you love. So you better be efficient about it. You better be lazy. There are <a href="https://blog.codinghorror.com/how-to-be-lazy-dumb-and-successful/?utm_source=chatgpt.com">many</a> <a href="https://xkcd.com/1205/?utm_source=chatgpt.com">correct</a> <a href="https://thethreevirtues.com/">takes</a> out there on the value of being lazy when programming.</p>
<p>Now that we are starting to have AI, it&rsquo;s even better. A lazy worker like myself will not only avoid unnecessary work, but will delegate all that can be delegated to the new AI workers that are multiplying in our computers. That makes the &ldquo;steward&rdquo; connotation of &ldquo;Maier&rdquo; all the more fitting.</p>
<p>I&rsquo;m proud to be the lazy worker, and this site is all about sharing my lazy works. My <em>hockenworks</em>.</p>
<hr>
<h1 id="ball-machine---the-game">Ball Machine - The Game</h1>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="A ball machine"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/bubble4.gif"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">The Ball Machine</span>
    
</div>

<p>Most blogs and personal websites are a bit boring. I think that is because most professionals consider what they do &ldquo;for work&rdquo; a bit boring by its nature, and don&rsquo;t necessarily make a concerted effort to have fun with it.</p>
<p>I have always tried to be the opposite, and with kids coming I am trying to make a bigger effort than ever to have fun whatever I&rsquo;m doing. Which is often working, in some way or another.</p>
<p>So for my website, I wanted it to be intentionally fun. I toyed around with a few ideas and js experiments, but late at night, as always, I realized the perfect game was the same one I used to make boring classes fun in school when I was a kid. That game consisted of the book of graph paper I always kept with me, plus a pencil, a ruler, and a protractor. I was a bit obsessed with physics simulation at the time. My favorite game in church growing up, where I was often daydreaming and looking at the huge arched ceiling, was to imagine a laser coming out of my line of sight and bouncing off of every surface in the room, to see where it would end up. This graph paper game I played was similar.</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="balls everywhere"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/this-website-ball-machine-1.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">Some of my early playtests got pretty chaotic</span>
    
</div>

<p>I would start by making a &ldquo;spawn point&rdquo; usually near the top left of the page, where balls would start falling. I would draw out the path of these balls a few inches from each other along their path with &ldquo;speed lines&rdquo; to denote which way they were going, and how fast. Then I would add platforms, trampolines, loops, curves, &ldquo;booster&rdquo; acceleration zones, jumps, machines that would disassemble and reassemble balls, and so many other things - usually something new each sheet of paper - and I would end up with a Rube Goldberg machine of balls flying all around the sheet. The only goal was to fill the sheet with more ridiculous paths.</p>
<p>I started calling the sheets my &ldquo;ball machines&rdquo;. I wish I still had some of these drawings. I remember them being quite intricate.. I must have reserved English class for them.</p>
<p>So, to honor kid Brian, I am making my website a permanent ball machine. I hope you have fun with it and see all there is to unlock!</p>
<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="balls everywhere"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/waves2.gif"   style="height: auto; max-width: 300px; width: 100%"   >


    
        <span style="display: block; font-style: italic; margin-top: 0.5rem;">Even on the limited phone version, you can create some productive chaos</span>
    
</div>

<h2 id="how-its-made">How it&rsquo;s made</h2>
<p>I don&rsquo;t typically make complicated things like this with JavaScript. So when I found the perfect physics engine for the game - <a href="https://brm.io/matter-js/">matter.js</a> - I knew I would need help from our new little assistants. And though this game is a bit too structured to call it &ldquo;vibe coded&rdquo; - at times, it was close.</p>
<p>I ended up making my own tool called <a href="/context-caddy">Context Caddy</a> to help me with it. Part of the reason I leaned so hard into this is because I&rsquo;m always trying to push the limits of current AI, and I hadn&rsquo;t built a game since the GPT-4 days (I&rsquo;ll post about that soon). The new thinking models are truly a step above GPT-4 (this was mostly done with o3 and its minis) but they&rsquo;re still way too eager to write duplicate code, and they still don&rsquo;t &ldquo;get&rdquo; the structure of your project a lot of the time, especially with visual and physical things like this. Still, they were a great help here.</p>
<p>This game is made extra complicated by the fact that it runs on top of <a href="https://gohugo.io/">Hugo</a>, which is the static site generator behind the &ldquo;content&rdquo; part of this site. This probably doubled or tripled the effort of making this game. But, the balls in the &ldquo;ball machines&rdquo; of my youth would interact with my text notes and drawings, so this ball machine needed to do so as well.</p>
<p>There is quite a bit going on under the hood to make these two very distinct types of development projects work in tandem, and for both of them to work well. The Ball Machine would love to eat up all of the resources and make the site content unresponsive, and the content was quite a lot to dynamically build physical bodies and colliders around. I like the end result. But I like it a lot better on desktop, where the two can really interact, so I think you should play it on a real computer with a mouse.</p>
<h2 id="how-to-play">How to Play</h2>
<span
  style="
    float: left;
    width: 150px;
    margin: 0 1rem 1rem 0;
    display: inline-block;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="ball chute"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/ball-chute-hatch-1.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
  <span style="display: block; font-style: italic; margin-top: 0.5rem">
    This tube creates balls every time you click it
  </span>
  
</span>

<p>The ball machine on this site is a gamified version of my graph paper drawings as a kid. Each time you load a page, you&rsquo;ll see a little pneumatic delivery tube on the top right of the screen.</p>
<p>When you spawn your first ball, you&rsquo;ll see a few things appear. First - you&rsquo;ll find a goal     <span
  style="
    display: inline-block;
    width: 40px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="the goal"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/goal.png"   style="height: auto; max-width: 40px; width: 100%"   >

 
</span>
 somewhere randomly on the page. Find a way to get the balls you spawn into that goal. But there is a bit of a trick - balls start out being worth 1 coin and accumulate another coin in value every two seconds. So, the longer you can keep balls around, the more they will be worth when going into the goals, and this might get more and more challenging as your drawings take up more of the screen and balls start bouncing off of each other.</p>
<p><strong>Keep Clicking!</strong></p>
<p>It&rsquo;s <a href="https://en.wikipedia.org/wiki/Incremental_game">a clicker game</a> - start by manually clicking the pneumatic delivery tube to spawn balls, but as you accumulate coins you&rsquo;ll be able to unlock different drawables and things that will let you accumulate more coins faster. If it feels like it&rsquo;s taking a while to make coins and unlock things, try playing around more with how the balls interact with the content, and use all of the tools you can draw. The site also works across multiple pages. And if all else fails&hellip; just give it time. This is a clicker game after all, so waiting is always a strategy! There is plenty to read while you wait.</p>
<p>It works best when you&rsquo;re on desktop, working on one tab at a time.</p>
<p> </p>
<blockquote>
<p>Quick Disclaimer: This game is designed for big screens, ideally desktop computers. If you must play on a phone, try landscape mode!</p>
</blockquote>
<h3 id="controls">Controls</h3>
<p><span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/line-mode.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>

<span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="curved line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/curve-mode.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>

<span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="compactor toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/compactor-mode.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>
</p>
<p>To start drawing your ball machine, you need to <kbd>Left Click</kbd> or <kbd>Tap</kbd> one of these drawable toggles in the main UI (top left of the screen)</p>
<p>When you have a drawable tool toggled on, you won&rsquo;t be able to click other links on the site. You&rsquo;ll see this visually indicated when you choose them. Unselect the currently selected tool in order to see it</p>
<p>Every drawable item (lines, launchers, and more) uses the following mechanics:</p>
<p> </p>
<h4 id="drawing-on-desktop">Drawing on Desktop</h4>
<p><strong>Spawn Balls:</strong> <kbd>Left Click</kbd> on the pneumatic spawner tube</p>
<p><strong>Draw Objects:</strong> <kbd>Left Click</kbd> and drag to see a preview, then <kbd>Left Click </kbd> to place</p>
<ul>
<li>Some drawables have a second action, like curved lines, that is previewed after the second click and confirmed with a third click</li>
</ul>
<p><strong>Cancel Drawing</strong> After you&rsquo;ve started a line or other drawing but before you&rsquo;ve clicked again to confirm, <kbd>Right Click</kbd> to cancel it.</p>
<p><strong>Delete Objects:</strong> Hover over a drawn item and <kbd>Right Click</kbd> to delete it, getting 50% of your money back</p>
<p> </p>
<h4 id="drawing-on-mobile">Drawing on Mobile</h4>
<p><span
  style="
    color: #ff0040;
    font-family: 'Arial Black', Arial, sans-serif;
    font-size: 20px;
  "
>
   Mobile Scroll Lock Warning:
</span>
 On Mobile, scrolling the page is blocked while you&rsquo;re drawing to allow you to draw lines in any direction.</p>
<p>You will need to untoggle your selected tool before you can scroll or click links.</p>
<p>If your phone has gesture controls to reload, go back or forward, or other browser things, you should disable them if you really want to play on your phone. Or, just play on desktop!</p>
<p><strong>Spawn Balls:</strong> <kbd>Tap</kbd> on the pneumatic spawner tube</p>
<p><strong>Draw Objects:</strong> <kbd>Touch and Drag</kbd> to see a preview, then <kbd>Release</kbd> to place</p>
<ul>
<li>Some drawables have a second action, like curved lines, that is previewed and confirmed on the next touch-and-drag.</li>
</ul>
<p><strong>Cancel Drawing</strong> After you&rsquo;ve started a line or other drawing but before you&rsquo;ve released to confirm, go back to where you started and release around there to cancel it. The threshold to cancel is within 25 pixels of where you started.</p>
<p><strong>Delete Objects:</strong> <kbd>Tap and hold</kbd> an object to delete it, getting 50% of your money back. You will see it pulse before it deletes.</p>
<p> </p>
<h4 id="the-auto-clicker">The Auto-Clicker</h4>
<span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="auto clicker"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/auto-clicker.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>

<p>This is the autoclicker button that lets you pay to auto-spawn balls.</p>
<p><kbd>Left Click</kbd> or <kbd>Tap</kbd> to buy the first auto-clicker, or upgrade it.</p>
<p><kbd>Right Click</kbd> on desktop or <kbd>Tap and hold</kbd> on mobile to refund and downgrade it to the previous click frequency.</p>
<p> </p>
<h3 id="money--other-hints">Money &amp; Other Hints</h3>
<p>You&rsquo;ll quickly find ways to lengthen your Rube-Goldberg Machines and build up value before you send balls into the goal. Your money is displayed on the coin counter next to the ball spawner.</p>
<p> </p>
<p><span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="dotted line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/everything-has-a-price.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>
<strong>Everything has a price!</strong></p>
<p>If you can&rsquo;t draw an item, you probably can&rsquo;t afford it. You&rsquo;ll see your coin counter flash red in the UI when this happens.</p>
<p><span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="dotted line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/dotted-line-mode.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>
<strong>You get what you pay for&hellip;</strong></p>
<p>If you ever find yourself out of money, these dotted lines are free. They are not saved permanently like other lines and they go away after 50 balls hit them.</p>
<p> </p>
<p>❌ A couple of things to watch out for when building ball machines:</p>
<ul>
<li>Balls have to be moving at all times. If they sit still for too long, they are considered dead and will poof out of existence.</li>
<li>This applies to balls hitting the goal, too. If your balls aren&rsquo;t moving much when they hit the target, they won&rsquo;t go in.
So keep your balls moving!</li>
</ul>
<p>😵 If you have a good run going, but it descends into chaos, it can be hard to recover. That&rsquo;s what the <kbd>Erase Balls</kbd> button above the draw tools is for!</p>
<p> </p>
<p>Each post on this site will be a slightly different randomized game! Try making ball machines on multiple pages at once. Your work will be saved in realtime, and you can make money even on pages you&rsquo;re not currently playing on.</p>
<p><span
  style="
    display: inline-block;
    width: 100px;
    margin: 0 1rem 0 0;
    vertical-align: middle;
    text-align: left;
  "
>
  





























    



    



    





    



    





    



    























<img  alt="dotted line toggle"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/page-revenue.png"   style="height: auto; max-width: 200px; width: 100%"   >

 
</span>
 These counters display how much <strong>sustainable</strong> coin revenue per second you&rsquo;re making on this page, and how much other pages you&rsquo;re not currently working on are contributing. Any balls that are spawned automatically and continuously travel through your contraption to hit the goal will be averaged into the top amount. When you visit other pages, you will keep making this money - that&rsquo;s what the &ldquo;Other Pages&rdquo; revenue displays.</p>
<p>Your progress is saved to your device because your contraptions will be highly dependent on the screen size the site renders to.</p>
<p>The game works a bit differently on desktop and mobile, and the best experience is really on desktop - so try on a computer if you can! If on mobile, flip to landscape.</p>
<h3 id="the-end-of-the-game">The End of the Game</h3>
<p>Right now, the Ball Machine doesn&rsquo;t end, but you will be surprised the amount of money you can make across the whole site! Eventually, there will be other ways to spend coins on this site and potentially &ldquo;beat&rdquo; the ball machine. The late game items change the game in very interesting ways! I hope you make some fun machines on my website.</p>
<p>You&rsquo;ll know you&rsquo;ve done about all there is to do by tracking the achievements below!</p>
<h4 id="achievements">Achievements</h4>
<div id="achievements-list"></div>
<script>
document.addEventListener('DOMContentLoaded', function(){
  var container = document.getElementById('achievements-list');
  if(!container){ console.error('Achievements container missing'); return; }
  try {
    var defs = (window.App && App.Achievements && App.Achievements.defs) || [];
    var unlocked = JSON.parse(localStorage.getItem('game.achievementsUnlocked') || '{}');
    var yes = 'http:\/\/localhost:1313\/images\/achievement-yes.png';
    var no = 'http:\/\/localhost:1313\/images\/achievement-no.png';
    if(!defs.length){
      console.warn('No achievements definitions found');
    }
    defs.forEach(function(a){
      var row = document.createElement('div');
      var img = document.createElement('img');
      var got = unlocked[a.id];
      img.src = got ? yes : no;
      img.alt = got ? 'Unlocked' : 'Locked';
      img.style.width = '16px';
      img.style.height = '16px';
      img.style.marginRight = '4px';
      row.appendChild(img);
      var b = document.createElement('b');
      b.textContent = a.name;
      row.appendChild(b);
      if(got){
        row.appendChild(document.createTextNode(' – ' + a.desc));
      }
      container.appendChild(row);
    });
    if (location.hash && location.hash.includes('achievements')) {
      var anchor = document.getElementById('achievements');
      if (anchor) {
        setTimeout(function(){ anchor.scrollIntoView(); }, 50);
      }
    }
  } catch(e){
    console.error('Failed to render achievements', e);
    container.textContent = 'Error loading achievements.';
  }
});
</script>

<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<h3 id="resetting-the-game">Resetting the Game</h3>
<span
  style="
    color: #ff0040;
    font-family: 'Arial Black', Arial, sans-serif;
    font-size: 20px;
  "
>
   WARNING! Don't navigate to the below page unless you're sure you want to reset the ball machine game
</span>

<p>Resetting will erase all of your drawings on all pages and reset your goal locations, unlocks, coins and everything else.</p>
<p>If you are thinking about doing this because you want to try on another device, you don&rsquo;t need to, because progress is already saved to your device. The only reason to do this is to have a fresh start on this device.</p>
<p>Navigate <a href="/reset-ball-machine">here</a> and click reset to do that.</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-05-28:/this-website/</guid>

                
                    <link>http://localhost:1313/this-website/</link>
                

                
                    <pubDate>Wed, 28 May 2025 00:00:00 UTC</pubDate>
                

                
                    <title>This Website</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<p>Notes:</p>
<p>The times I have been most successful in my career are the times I broke the rules. Mostly soft rules, like the idea of what I was &ldquo;supposed&rdquo; to be getting paid for. The biggest time being when I built ragpile in my spare time.</p>
<p>I remember getting this advice early on in my career from a mentor - that you always need to be doing your job, plus something else. Maybe it was from Ashish?</p>
<p>I think there are many reasons that this is likely true in large organizations - but a reason it is getting more and more true, is because &ldquo;order taking&rdquo; is one of the easiest skills to learn, and becoming less and less relevant as we create AIs good at taking orders.</p>
<p>Ideas to incorporate:
The more people from groups that don&rsquo;t build are involved in a project, the slower it goes</p>
]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2025-02-04:/breaking-the-rules/</guid>

                
                    <link>http://localhost:1313/breaking-the-rules/</link>
                

                
                    <pubDate>Tue, 04 Feb 2025 00:00:00 UTC</pubDate>
                

                
                    <title>Breaking the rules</title>
                
            </item>
        
            <item>
                
                
                
                
                
                
                

                

                

                

                

                
                

                

                

                
                    <description><![CDATA[<div style="text-align: center; margin-bottom: 1rem;">
    





























    



    



    





    



    





    



    























<img  alt="this is a robot"   crossorigin="anonymous"    referrerpolicy="no-referrer"  src="http://localhost:1313/images/ai-software-dev.png"   style="height: auto; max-width: 720px; width: 100%"   >


    
</div>

<p>Lots of chatter right now about AI replacing software developers.</p>
<p>I agree - AI will take over software development. The question is: what work will be left when this happens?</p>
<p>Some considerations:</p>
<ul>
<li>Benchmarks for the best LLMs still put them solidly in the &ldquo;bad at programming&rdquo; category, scoring in the 5th percentile of human programmers on common tests. Meanwhile, LLMs score in the 80th-95th percentile for law exams and 85th–100th for psychology, statistics, and many other less technical fields. More scores available in the &ldquo;simulated exams&rdquo; section of <a href="https://openai.com/research/gpt-4">https://openai.com/research/gpt-4</a>.</li>
<li>Engineers have been using language models like tabnine and copilot as &ldquo;super-stackoverflow&rdquo; style code assistance years before chatGPT released. This means much of the velocity increase we might expect from current LLMs&rsquo; ability to write code has already been &ldquo;priced in&rdquo; to the market.</li>
<li>Many of the trends making software development more costly are growing, not shrinking: Systems are becoming more distributed. The cloud lowered infrastructure costs but made applications more complex. We&rsquo;re making more and deeper integrations among disparate systems. Auth is becoming more secure and thus complex (managed identity, MFA, etc).</li>
</ul>
<p>Github copilot chat and other LLM dev tools are speeding up the rote stuff. I’ve seen it in my own work.</p>
<p>And I really do believe new AI models will do more than just the basics, maybe in the next couple of years. Even precluding &ldquo;AGI&rdquo;, the trend we are on is that more and more work is automatable, and engineers, especially more junior ones - are going to have to shift focus away from algorithmic work that AI can do.</p>
<p>But by the time our neural nets are &ldquo;good enough&rdquo; at building software to make it significantly cheaper to build, I doubt this trend will make the news. Everything else gets automated too.</p>
<p>These are my thoughts at what seems to be the beginning of the next AI revolution in early 2024. I plan to revisit this topic and see if I&rsquo;m right in future posts.</p>]]></description>
                

                <guid isPermaLink="false">tag:localhost:1313,2024-01-24:/on-ai-software-development/</guid>

                
                    <link>http://localhost:1313/on-ai-software-development/</link>
                

                
                    <pubDate>Wed, 24 Jan 2024 00:00:00 UTC</pubDate>
                

                
                    <title>On AI Software Development</title>
                
            </item>
        
    </channel>
</rss>
